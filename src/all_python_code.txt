--- File: ./perfusion_solver.py ---
# src/perfusion_solver.py
from __future__ import annotations
import numpy as np
import networkx as nx
import logging
from typing import Dict, Tuple, Optional, List

from src import constants, config_manager, utils

logger = logging.getLogger(__name__)

def calculate_segment_resistance(length: float, radius: float, viscosity: float) -> float:
    """Calculates hydraulic resistance of a cylindrical segment using Poiseuille's law.
    R = (8 * mu * L) / (pi * r^4)
    """
    if radius < constants.EPSILON: # Avoid division by zero or extremely small radius
        return np.inf
    if length < constants.EPSILON: # Segment with negligible length
        # Return a very small resistance to ensure conductance is high but finite
        return constants.EPSILON
    return (8.0 * viscosity * length) / (constants.PI * (radius**4))

def solve_1d_poiseuille_flow(
    graph: nx.DiGraph,
    config: dict,
    root_pressure_val: Optional[float] = None,
    terminal_flows_val: Optional[Dict[str, float]] = None
) -> nx.DiGraph:
    """Solves for nodal pressures and segmental flows in a vascular graph.

    Modifies the input graph in-place by adding/updating:
    - 'pressure' attribute to nodes.
    - 'flow_solver' attribute to edges.
    """
    if graph.number_of_nodes() == 0:
        logger.warning("Flow solver: Graph is empty. Nothing to solve.")
        return graph

    logger.info(f"Starting 1D Poiseuille flow solution for graph with {graph.number_of_nodes()} nodes, {graph.number_of_edges()} edges.")

    viscosity = config_manager.get_param(config, "vascular_properties.blood_viscosity", constants.DEFAULT_BLOOD_VISCOSITY)
    if root_pressure_val is None:
        inlet_pressure = config_manager.get_param(config, "perfusion_solver.inlet_pressure", 10000.0) # Pa
    else:
        inlet_pressure = root_pressure_val

    node_list = list(graph.nodes())
    node_to_idx = {node_id: i for i, node_id in enumerate(node_list)}
    num_nodes = len(node_list)

    for node_id_init in node_list:
        graph.nodes[node_id_init]['pressure'] = np.nan
    for u_init, v_init, data_init in graph.edges(data=True):
        data_init['flow_solver'] = np.nan

    if num_nodes == 0:
        return graph

    A_matrix = np.zeros((num_nodes, num_nodes), dtype=float)
    B_vector = np.zeros(num_nodes, dtype=float)
    num_defined_pressure_bcs = 0
    num_defined_flow_sinks = 0

    logger.debug("--- Flow Solver: Assembling System Matrix A and Vector B ---")
    for i, node_id_i in enumerate(node_list):
        node_i_data = graph.nodes[node_id_i]

        if node_i_data.get('is_flow_root', False):
            A_matrix[i, :] = 0.0
            A_matrix[i, i] = 1.0
            B_vector[i] = inlet_pressure
            num_defined_pressure_bcs += 1
            logger.debug(f"  BC Set (Pressure): Node {node_id_i} (type: {node_i_data.get('type')}) is flow_root. Row {i}: A[{i},{i}]=1, B[{i}]={inlet_pressure:.2f}")
            continue

        sum_conductances_at_i = 0.0
        physical_neighbors = set(graph.predecessors(node_id_i)) | set(graph.successors(node_id_i))
        current_row_terms_log = []

        for neighbor_id_j in physical_neighbors:
            if neighbor_id_j not in node_to_idx:
                logger.error(f"  Error: Neighbor {neighbor_id_j} of {node_id_i} not in node_to_idx map. Skipping.")
                continue
            j = node_to_idx[neighbor_id_j]

            edge_data = graph.get_edge_data(node_id_i, neighbor_id_j) or graph.get_edge_data(neighbor_id_j, node_id_i)

            if edge_data:
                length = edge_data.get('length', 0.0)
                radius = edge_data.get('radius', constants.MIN_VESSEL_RADIUS_MM)
                radius = max(radius, constants.MIN_VESSEL_RADIUS_MM * 0.01) 
                if length < constants.EPSILON:
                    length = constants.EPSILON

                resistance = calculate_segment_resistance(length, radius, viscosity)
                conductance = 0.0
                if resistance < np.inf and resistance > constants.EPSILON:
                    conductance = 1.0 / resistance
                elif resistance <= constants.EPSILON: 
                    conductance = 1.0 / (constants.EPSILON * 10)
                    logger.debug(f"  Edge involving {node_id_i}-{neighbor_id_j}: R~0, using high G={conductance:.1e}")

                if conductance > 0:
                    A_matrix[i, j] -= conductance 
                    sum_conductances_at_i += conductance
                    current_row_terms_log.append(f"G_({node_id_i}-{neighbor_id_j})={conductance:.2e} (to P_{neighbor_id_j})")
            else:
                 logger.warning(f"  No edge data found between physically connected {node_id_i} and {neighbor_id_j}.")

        A_matrix[i, i] = sum_conductances_at_i 

        is_graph_terminal_for_flow = (graph.out_degree(node_id_i) == 0 and not node_i_data.get('is_flow_root', False))

        if (node_i_data.get('type') == 'synthetic_terminal' and is_graph_terminal_for_flow) or \
           node_i_data.get('is_flow_terminal', False): 
            outflow_demand = 0.0
            if terminal_flows_val and node_id_i in terminal_flows_val:
                outflow_demand = terminal_flows_val[node_id_i]
            elif 'Q_flow' in node_i_data:
                outflow_demand = node_i_data['Q_flow']
            else:
                logger.warning(f"  Terminal node {node_id_i} (type: {node_i_data.get('type')}) has no Q_flow or provided outflow. Assuming zero demand.")

            B_vector[i] -= outflow_demand 
            num_defined_flow_sinks +=1
            logger.debug(f"  BC Set (Flow Sink): Node {node_id_i}. B[{i}] -= {outflow_demand:.2e} (Total B[{i}]={B_vector[i]:.2e})")
        elif B_vector[i] == 0.0 and not is_graph_terminal_for_flow and not node_i_data.get('is_flow_root', False): 
            logger.debug(f"  Matrix Row {i} ({node_id_i}, type: {node_i_data.get('type')}): Internal node. B[{i}]=0.")
        
        logger.debug(f"  Matrix Row {i} ({node_id_i}, type: {node_i_data.get('type')}): Diag A[{i},{i}]={A_matrix[i,i]:.2e}. Off-diag terms: {', '.join(current_row_terms_log) if current_row_terms_log else 'None'}. B[{i}]={B_vector[i]:.2e}")

    logger.debug(f"--- Flow Solver: System Matrix A (shape {A_matrix.shape}):\n{A_matrix if num_nodes < 10 else 'Too large to print'}")
    logger.debug(f"--- Flow Solver: System Vector B (shape {B_vector.shape}):\n{B_vector if num_nodes < 10 else 'Too large to print'}")
    logger.info(f"Flow Solver: Total defined pressure BCs (is_flow_root): {num_defined_pressure_bcs}")
    logger.info(f"Flow Solver: Total defined flow sinks (terminals with Q_flow): {num_defined_flow_sinks}")

    if num_defined_pressure_bcs == 0 and num_nodes > 0:
        logger.error("Flow solver: No pressure boundary conditions (is_flow_root=True) defined. Cannot solve. Pressures and flows will be NaN.")
        return graph

    node_pressures_vec = np.full(num_nodes, np.nan)

    try:
        rank_A = 0
        if num_nodes > 0:
            if np.any(np.isnan(A_matrix)) or np.any(np.isinf(A_matrix)):
                logger.critical("CRITICAL DIAGNOSIS: A_matrix contains NaN/Inf values BEFORE rank calculation. Problem with conductances (NaN radii/lengths?).")
                print("CRITICAL DIAGNOSIS: A_matrix contains NaN/Inf values BEFORE rank calculation.") # Force print
            else:
                 rank_A = np.linalg.matrix_rank(A_matrix)
        logger.debug(f"Flow Solver: Matrix A Rank = {rank_A} for {num_nodes} nodes.")

        if num_nodes > 0 and rank_A < num_nodes:
            logger.error(f"Flow solver: Matrix A is singular or rank-deficient (rank {rank_A} for {num_nodes} nodes). Pressures and flows will be NaN.")
            print(f"Flow solver: Matrix A is singular or rank-deficient (rank {rank_A} for {num_nodes} nodes).") # Force print
            logger.error("Investigating cause of rank deficiency:")
            print("Investigating cause of rank deficiency:") # Force print
            
            if np.any(np.isnan(A_matrix)) or np.any(np.isinf(A_matrix)):
                logger.error("  DIAGNOSIS (NAN/INF A): A_matrix contains NaN/Inf values. Problem with input graph data (radii, lengths).")
                print("  DIAGNOSIS (NAN/INF A): A_matrix contains NaN/Inf values.")
            if np.any(np.isnan(B_vector)) or np.any(np.isinf(B_vector)):
                logger.error("  DIAGNOSIS (NAN/INF B): B_vector contains NaN/Inf values. Problem with Q_flow for terminals.")
                print("  DIAGNOSIS (NAN/INF B): B_vector contains NaN/Inf values.")

            problem_rows_found = False
            for i_diag in range(num_nodes):
                node_id_diag = node_list[i_diag]
                is_root_diag = graph.nodes[node_id_diag].get('is_flow_root', False)
                
                # Check for all-zero rows (excluding root node equations which are P_i = C)
                if not is_root_diag and np.all(np.abs(A_matrix[i_diag, :]) < constants.EPSILON):
                    problem_rows_found = True
                    logger.error(f"  DIAGNOSIS (ZERO ROW): Row {i_diag} for node '{node_id_diag}' (type: {graph.nodes[node_id_diag].get('type')}) is all zeros in A_matrix.")
                    print(f"  DIAGNOSIS (ZERO ROW): Row {i_diag} for node '{node_id_diag}' is all zeros.")
                    # ... (rest of zero row logging as before)
                
                # Check for zero diagonal for non-root nodes
                elif not is_root_diag and abs(A_matrix[i_diag, i_diag]) < constants.EPSILON:
                    problem_rows_found = True
                    logger.error(f"  DIAGNOSIS (ZERO DIAG): Row {i_diag} for node '{node_id_diag}' (type: {graph.nodes[node_id_diag].get('type')}) has A[{i_diag},{i_diag}]=0. Sum of conductances is zero.")
                    print(f"  DIAGNOSIS (ZERO DIAG): Row {i_diag} for node '{node_id_diag}' has zero diagonal.")
                    logger.error(f"    Node '{node_id_diag}' Data: {graph.nodes[node_id_diag]}")
                    logger.error(f"    Node '{node_id_diag}' Degree: {graph.degree(node_id_diag)}, In: {graph.in_degree(node_id_diag)}, Out: {graph.out_degree(node_id_diag)}")
                    for neighbor_diag_zd in list(graph.predecessors(node_id_diag)) + list(graph.successors(node_id_diag)):
                        edge_diag_zd = graph.get_edge_data(node_id_diag, neighbor_diag_zd) or graph.get_edge_data(neighbor_diag_zd, node_id_diag)
                        if edge_diag_zd:
                             logger.error(f"      Connected to '{neighbor_diag_zd}' via edge with data: {edge_diag_zd}")
            
            if not problem_rows_found:
                logger.info("  DIAGNOSIS: No rows in A_matrix were found to be all-zero or have zero diagonals (for non-roots). Problem might be more complex graph structure or multiple interacting issues.")
                print("  DIAGNOSIS: No rows in A_matrix were found to be all-zero or have zero diagonals (for non-roots).")


            logger.info("  DIAGNOSIS: Checking for graph components without pressure BCs...")
            print("  DIAGNOSIS: Checking for graph components without pressure BCs...")
            try:
                if graph.is_directed():
                    undi_graph = graph.to_undirected(as_view=True) 
                else: 
                    undi_graph = graph 

                components_found_count = 0
                floating_components_found_count = 0
                for component_nodes in nx.connected_components(undi_graph):
                    components_found_count +=1
                    has_pressure_bc_in_comp = any(graph.nodes[comp_node_id].get('is_flow_root', False) for comp_node_id in component_nodes)
                    if not has_pressure_bc_in_comp:
                        floating_components_found_count += 1
                        comp_node_list_str = list(component_nodes)
                        logger.error(f"  DIAGNOSIS (FLOATING COMP): Component {floating_components_found_count} (size {len(comp_node_list_str)}) is FLOATING (no pressure BC). Nodes: {comp_node_list_str[:10]}{'...' if len(comp_node_list_str)>10 else ''}")
                        print(f"  DIAGNOSIS (FLOATING COMP): Component {floating_components_found_count} (size {len(comp_node_list_str)}) is FLOATING. Nodes: {comp_node_list_str[:5]}...")
                        # Check if this floating component has any flow sinks
                        has_flow_sinks_in_comp = any(
                            (graph.nodes[cn_id].get('type') == 'synthetic_terminal' and graph.out_degree(cn_id) == 0) or \
                            graph.nodes[cn_id].get('is_flow_terminal', False)
                            for cn_id in component_nodes if not graph.nodes[cn_id].get('is_flow_root', False)
                        )
                        if has_flow_sinks_in_comp:
                            logger.error(f"    Floating Component {floating_components_found_count} HAS flow sinks.")
                            print(f"    Floating Component {floating_components_found_count} HAS flow sinks.")
                        else:
                            logger.error(f"    Floating Component {floating_components_found_count} HAS NO flow sinks.")
                            print(f"    Floating Component {floating_components_found_count} HAS NO flow sinks.")
                if components_found_count == 0:
                    logger.error("  DIAGNOSIS: nx.connected_components found NO components (graph might be empty or unusual).")
                    print("  DIAGNOSIS: nx.connected_components found NO components.")
                elif floating_components_found_count == 0:
                    logger.info(f"  DIAGNOSIS: All {components_found_count} graph component(s) appear to have a pressure BC.")
                    print(f"  DIAGNOSIS: All {components_found_count} graph component(s) appear to have a pressure BC.")
            except Exception as e_comp:
                logger.error(f"  DIAGNOSIS: Error during connected components check: {e_comp}")
                print(f"  DIAGNOSIS: Error during connected components check: {e_comp}")
        else: 
            node_pressures_vec = np.linalg.solve(A_matrix, B_vector)
            logger.info("Flow solver: Successfully solved for nodal pressures.")

    except np.linalg.LinAlgError as e:
        logger.error(f"Flow solver: Linear algebra error during pressure solution: {e}", exc_info=False)
        if num_nodes > 0 and not (np.any(np.isnan(A_matrix)) or np.any(np.isinf(A_matrix))):
             try:
                 # Check if A_matrix is square and finite before calling cond
                 if A_matrix.shape[0] == A_matrix.shape[1] and np.all(np.isfinite(A_matrix)):
                     logger.error(f"Matrix A Condition Number: {np.linalg.cond(A_matrix)}")
                 else:
                     logger.error("Matrix A is not square or contains non-finite values, cannot compute condition number.")
             except Exception as e_cond:
                 logger.error(f"Could not compute condition number for A: {e_cond}")

    for i, node_id in enumerate(node_list):
        graph.nodes[node_id]['pressure'] = node_pressures_vec[i]

    for u_id, v_id, data in graph.edges(data=True):
        P_u = graph.nodes[u_id]['pressure']
        P_v = graph.nodes[v_id]['pressure']

        if np.isnan(P_u) or np.isnan(P_v):
            data['flow_solver'] = np.nan
            continue

        length = data.get('length', 0.0)
        radius = data.get('radius', constants.MIN_VESSEL_RADIUS_MM)
        radius = max(radius, constants.MIN_VESSEL_RADIUS_MM * 0.01)
        if length < constants.EPSILON:
            length = constants.EPSILON

        resistance = calculate_segment_resistance(length, radius, viscosity)
        flow_on_edge = 0.0
        if resistance < np.inf and resistance > constants.EPSILON:
            flow_on_edge = (P_u - P_v) / resistance
        elif resistance <= constants.EPSILON: 
            if not np.isclose(P_u, P_v, atol=1e-3):
                 logger.warning(f"Edge {u_id}->{v_id} has R~0 ({resistance:.1e}) but P_diff {(P_u-P_v):.2e}. Flow may be very large/ill-defined.")
                 flow_on_edge = (P_u - P_v) / (constants.EPSILON * 10)
        elif resistance == np.inf:
            flow_on_edge = 0.0

        data['flow_solver'] = flow_on_edge
        if logger.isEnabledFor(logging.DEBUG):
             logger.debug(f"Edge {u_id}->{v_id}: P_u={P_u:.2f}, P_v={P_v:.2f}, L={length:.3f}, R_edge={radius:.4f}, Res={resistance:.2e}, Q_solver={flow_on_edge:.2e}")

    logger.info("Flow solver: Finished annotating graph with pressures and flows.")
    return graph
--- File: ./config_manager.py ---
# src/config_manager.py
import yaml
import os
from typing import Any, Dict
import logging

logger = logging.getLogger(__name__)

def load_config(config_path: str) -> Dict[str, Any]:
    """
    Loads a YAML configuration file.

    Args:
        config_path (str): Path to the YAML configuration file.

    Returns:
        Dict[str, Any]: A dictionary containing the configuration parameters.
    
    Raises:
        FileNotFoundError: If the config file is not found.
        yaml.YAMLError: If there's an error parsing the YAML file.
    """
    if not os.path.exists(config_path):
        logger.error(f"Configuration file not found: {config_path}")
        raise FileNotFoundError(f"Configuration file not found: {config_path}")
    
    try:
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        logger.info(f"Successfully loaded configuration from: {config_path}")
        return config
    except yaml.YAMLError as e:
        logger.error(f"Error parsing YAML configuration file {config_path}: {e}")
        raise

def get_param(config: Dict[str, Any], key_path: str, default: Any = None) -> Any:
    """
    Retrieves a parameter from the config dictionary using a dot-separated key path.
    Example: get_param(config, "simulation.gbo.max_iterations")

    Args:
        config (Dict[str, Any]): The configuration dictionary.
        key_path (str): Dot-separated path to the key (e.g., "parent.child.key").
        default (Any, optional): Default value to return if key is not found. Defaults to None.

    Returns:
        Any: The parameter value or the default value.
    """
    keys = key_path.split('.')
    value = config
    try:
        for key in keys:
            value = value[key]
        return value
    except (KeyError, TypeError):
        logger.warning(f"Parameter '{key_path}' not found in config. Using default: {default}")
        return default

def create_default_config(config_path: str = "config.yaml"):
    """
    Creates a default configuration file if it doesn't exist.
    """
    from src import constants # To access default values

    default_config_content = {
        "paths": {
            "output_dir": "output/simulation_results",
            "wm_nifti": "data/sample_brain_wm.nii.gz",
            "gm_nifti": "data/sample_brain_gm.nii.gz",
            "csf_nifti": "data/sample_brain_csf.nii.gz", # Optional
            "tumor_nifti": "data/sample_tumor.nii.gz", # Optional
            "arterial_centerlines": "data/sample_arteries.vtp" # or .txt
        },
        "simulation": {
            "random_seed": 42,
            "log_level": "INFO", # DEBUG, INFO, WARNING, ERROR
            "units": { # Define units used for consistency, e.g. 'mm' for length
                "length": "mm",
                "pressure": "Pa", # Pascal
                "flow_rate": "mm^3/s"
            }
        },
        "tissue_properties": {
            "metabolic_rates": { # in 1/s (ml_blood / s / ml_tissue)
                "gm": constants.Q_MET_GM_PER_ML,
                "wm": constants.Q_MET_WM_PER_ML,
                "tumor_rim": constants.Q_MET_TUMOR_RIM_PER_ML,
                "tumor_core": constants.Q_MET_TUMOR_CORE_PER_ML,
                "csf": constants.Q_MET_CSF_PER_ML
            },
            "permeability": { # in mm^2 (if length unit is mm)
                "gm": constants.DEFAULT_TISSUE_PERMEABILITY_GM,
                "wm": constants.DEFAULT_TISSUE_PERMEABILITY_WM,
                # Tumor permeability can be higher
                "tumor": 5e-7 # mm^2
            }
        },
        "vascular_properties": {
            "blood_viscosity": constants.DEFAULT_BLOOD_VISCOSITY, # Pa.s
            "murray_law_exponent": constants.MURRAY_LAW_EXPONENT,
            "initial_terminal_flow": constants.INITIAL_TERMINAL_FLOW_Q, # mm^3/s (if units are mm)
            "min_segment_length": 0.1, # mm
            "max_segment_length": 2.0, # mm
            "min_radius": 0.005 # mm (e.g. 5 microns)
        },
        "gbo_growth": {
            "max_iterations": 100,
            "energy_coefficient_C_met": constants.DEFAULT_C_MET_VESSEL_WALL, # W/m^3 or equivalent in chosen units
            "target_perfusion_level": 0.9, # Target fraction of demand to be met
            "branching_threshold_radius": 0.2, # mm (example: branch if terminal radius exceeds this)
            "bifurcation_angle_search_steps": 5, # Number of angles to test
            "bifurcation_length_factor": 0.5, # New segments are this factor of parent segment length (heuristic)
            "stop_criteria": {
                "max_radius_factor_measured": 1.0 # Stop if synth. radius = 1.0 * measured_terminal_radius
            }
        },
        "tumor_angiogenesis": {
            "enabled": True,
            "sprouting_vessel_min_radius": 0.1, # mm
            "growth_bias_strength": 0.5, # For biased random walk
            "max_tumor_vessels": 500,
            "segment_length_mean_tumor": 0.3, # mm
            "segment_length_std_tumor": 0.1, # mm
            "tortuosity_factor": 1.5 # How much more tortuous tumor vessels are
        },
        "perfusion_solver": {
            "enabled": True,
            "inlet_pressure": 10000, # Pa (approx 75 mmHg)
            "terminal_outlet_pressure": 2000, # Pa (approx 15 mmHg, for network solver if applicable)
            "coupling_beta": constants.DEFAULT_COUPLING_BETA, # mm^3 / (s*Pa)
            "use_flow_sinks_for_terminals": True, # Example, if we add options later
            "max_iterations_coupling": 20,
            "convergence_tolerance_coupling": 1e-4,
            "darcy_solver_max_iter": 1000,
            "darcy_solver_tolerance": 1e-6
        },
        "visualization":{
            "save_intermediate_steps": False,
            "plot_slice_axis": "axial", # axial, sagittal, coronal
            "plot_slice_index": -1 # -1 for middle slice
        }
    }
    if not os.path.exists(config_path):
        with open(config_path, 'w') as f:
            yaml.dump(default_config_content, f, sort_keys=False, indent=4)
        logger.info(f"Created default configuration file: {config_path}")
    else:
        logger.info(f"Configuration file already exists: {config_path}")

if __name__ == '__main__':
    # Example usage:
    logging.basicConfig(level=logging.INFO)
    
    # Create a dummy config.yaml if it doesn't exist in the script's directory
    script_dir = os.path.dirname(os.path.abspath(__file__))
    dummy_config_path = os.path.join(script_dir, "..", "config.yaml") # Assumes script is in src/
    
    if not os.path.exists(dummy_config_path):
        os.makedirs(os.path.dirname(dummy_config_path), exist_ok=True)
        create_default_config(dummy_config_path)

    try:
        config = load_config(dummy_config_path)
        print("Config loaded successfully.")
        print("Random seed:", get_param(config, "simulation.random_seed", 0))
        print("GM metabolic rate:", get_param(config, "tissue_properties.metabolic_rates.gm"))
        print("Non-existent param:", get_param(config, "foo.bar.baz", "default_val"))
        
        # Test output directory creation from config
        output_dir = get_param(config, "paths.output_dir", "output/default_sim")
        os.makedirs(output_dir, exist_ok=True)
        print(f"Ensured output directory exists: {output_dir}")

    except Exception as e:
        print(f"Error in example usage: {e}")
--- File: ./vascular_growth.py ---
# src/vascular_growth.py
from __future__ import annotations # Must be first line for postponed evaluation of annotations

import numpy as np
import networkx as nx
import logging
import os
from scipy.spatial import KDTree
from typing import Tuple, List, Dict, Set, Optional

from src import utils, data_structures, constants, config_manager
from src import energy_model
from src import perfusion_solver
from src import io_utils 

logger = logging.getLogger(__name__)

class GBOIterationData: 
    def __init__(self, terminal_id: str, pos: np.ndarray, radius: float, flow: float,
                 is_synthetic: bool = True, original_measured_radius: Optional[float] = None, 
                 parent_id: Optional[str] = None, parent_measured_terminal_id: Optional[str] = None): # Consistent name
        self.id: str = terminal_id
        self.pos: np.ndarray = np.array(pos, dtype=float)
        self.radius: float = float(radius)
        self.flow: float = float(flow) 
        self.parent_id: Optional[str] = parent_id
        self.parent_measured_terminal_id: Optional[str] = parent_measured_terminal_id
        self.original_measured_radius: Optional[float] = original_measured_radius # Standardized name
        self.length_from_parent: float = 0.0
        self.is_synthetic: bool = is_synthetic
        self.stop_growth: bool = False
        self.current_territory_voxel_indices_flat: List[int] = []
        self.current_territory_demand: float = 0.0
        self.actual_received_flow: float = 0.0 
        self.perfusion_ratio: float = 0.0       


def initialize_perfused_territory_and_terminals(
    config: dict,
    initial_graph: Optional[nx.DiGraph], 
    tissue_data: dict 
) -> Tuple[np.ndarray, List[GBOIterationData], int, nx.DiGraph]:
    logger.info("Initializing perfused territory and active GBO terminals...")
    perfused_tissue_mask = np.zeros(tissue_data['shape'], dtype=bool)
    active_terminals: List[GBOIterationData] = []

    initial_synthetic_radius_default = config_manager.get_param(config, "vascular_properties.min_radius", 0.005)
    k_murray_factor = config_manager.get_param(config, "vascular_properties.k_murray_scaling_factor", 0.5)
    murray_exponent = config_manager.get_param(config, "vascular_properties.murray_law_exponent", 3.0)
    default_initial_flow = config_manager.get_param(config, "vascular_properties.initial_terminal_flow", constants.INITIAL_TERMINAL_FLOW_Q)

    next_synthetic_node_id = 0

    gbo_graph = initial_graph.copy() if initial_graph and initial_graph.number_of_nodes() > 0 else data_structures.create_empty_vascular_graph()
    if initial_graph is None or initial_graph.number_of_nodes() == 0:
        logger.info("No initial VTP graph provided or it's empty. GBO will rely on config seeds or fallback.")

    if initial_graph:
        for node_id, data in initial_graph.nodes(data=True):
            if data.get('type') == 'measured_root':
                if gbo_graph.has_node(node_id):
                    gbo_graph.nodes[node_id]['is_flow_root'] = True
                    gbo_graph.nodes[node_id]['Q_flow'] = 0.0 
                    logger.info(f"Marked VTP input node {node_id} (type: measured_root) as is_flow_root=True in gbo_graph.")

    processed_from_vtp_terminals = False
    if initial_graph:
        vtp_terminals_in_anatomical_domain = []
        gbo_growth_domain_mask = tissue_data.get('gbo_growth_domain_mask') 
        affine = tissue_data.get('affine')

        if gbo_growth_domain_mask is None or affine is None:
            logger.error("GBO growth domain mask or affine missing in tissue_data. Cannot reliably sprout from VTP terminals.")
        else:
            for node_id, data in initial_graph.nodes(data=True):
                if data.get('type') == 'measured_terminal_in_anatomical_domain':
                    pos_world = data['pos']
                    pos_vox_int = np.round(utils.world_to_voxel(pos_world, affine)).astype(int)
                    if utils.is_voxel_in_bounds(pos_vox_int, gbo_growth_domain_mask.shape) and \
                       gbo_growth_domain_mask[tuple(pos_vox_int)]:
                        vtp_terminals_in_anatomical_domain.append(node_id)
                    else:
                        logger.info(f"VTP terminal {node_id} (in anatomical domain) is outside GBO growth domain (GM/WM). Not sprouting GBO from it.")
                        if gbo_graph.has_node(node_id):
                            gbo_graph.nodes[node_id]['type'] = 'measured_terminal_non_parenchymal'

        if vtp_terminals_in_anatomical_domain:
            logger.info(f"Found {len(vtp_terminals_in_anatomical_domain)} VTP terminals within GBO growth domain (GM/WM) to sprout from.")
            for measured_terminal_id in vtp_terminals_in_anatomical_domain:
                measured_data = initial_graph.nodes[measured_terminal_id] 
                measured_pos = np.array(measured_data['pos'], dtype=float)
                original_measured_radius_from_vtp = measured_data.get('radius', initial_synthetic_radius_default) 
                gbo_sprout_id = f"s_{next_synthetic_node_id}"; next_synthetic_node_id += 1
                term_gbo_data_obj = GBOIterationData(
                    terminal_id=gbo_sprout_id, pos=measured_pos,
                    radius=initial_synthetic_radius_default, 
                    flow=default_initial_flow,
                    original_measured_radius=original_measured_radius_from_vtp, # Consistent name now
                    parent_id=measured_terminal_id,
                    parent_measured_terminal_id=measured_terminal_id 
                )
                active_terminals.append(term_gbo_data_obj)
                node_attrs_for_s_node = vars(term_gbo_data_obj).copy()
                node_attrs_for_s_node['type'] = 'synthetic_terminal'; node_attrs_for_s_node['is_flow_root'] = False
                node_attrs_for_s_node['Q_flow'] = term_gbo_data_obj.flow 
                node_attrs_for_s_node.pop('current_territory_voxel_indices_flat', None)
                node_attrs_for_s_node.pop('current_territory_demand', None)
                data_structures.add_node_to_graph(gbo_graph, gbo_sprout_id, **node_attrs_for_s_node)
                if gbo_graph.has_node(measured_terminal_id):
                     gbo_graph.nodes[measured_terminal_id]['type'] = 'measured_to_synthetic_junction'
                     if 'Q_flow' in gbo_graph.nodes[measured_terminal_id]: 
                         del gbo_graph.nodes[measured_terminal_id]['Q_flow'] 
                edge_length_vtp_to_gbo = config_manager.get_param(config, "gbo_growth.vtp_sprout_connection_length", constants.EPSILON)
                data_structures.add_edge_to_graph(
                    gbo_graph, measured_terminal_id, gbo_sprout_id, 
                    length=edge_length_vtp_to_gbo, radius=initial_synthetic_radius_default, 
                    type='synthetic_sprout_from_measured'
                )
                logger.info(f"GBO Init: Sprouted synthetic_terminal '{gbo_sprout_id}' from VTP node '{measured_terminal_id}'.")
                processed_from_vtp_terminals = True
        
        if not processed_from_vtp_terminals and initial_graph.number_of_nodes() > 0 :
             if any(data.get('type') == 'measured_terminal_in_anatomical_domain' for _, data in initial_graph.nodes(data=True)):
                logger.warning("VTP terminals were found in anatomical domain, but none were within GBO growth domain. Checking config seeds.")
             else:
                logger.warning("Initial graph (VTP) provided but no 'measured_terminal_in_anatomical_domain' nodes found/processed. Checking config seeds.")

    if not processed_from_vtp_terminals:
        seed_points_config = config_manager.get_param(config, "gbo_growth.seed_points", [])
        if seed_points_config and isinstance(seed_points_config, list):
            logger.info(f"No VTP terminals processed for GBO, or none valid. Using {len(seed_points_config)} GBO seed points from configuration.")
            for seed_info in seed_points_config:
                seed_id_base = seed_info.get('id', f"cfg_seed_{next_synthetic_node_id}"); next_synthetic_node_id +=1
                seed_pos = np.array(seed_info.get('position'), dtype=float)
                config_initial_radius = float(seed_info.get('initial_radius', initial_synthetic_radius_default))
                seed_flow_for_radius = (config_initial_radius / k_murray_factor) ** murray_exponent if config_initial_radius > constants.EPSILON and k_murray_factor > constants.EPSILON else default_initial_flow
                
                term_gbo_data_obj = GBOIterationData(
                    terminal_id=seed_id_base, 
                    pos=seed_pos, 
                    radius=config_initial_radius, 
                    flow=seed_flow_for_radius,
                    original_measured_radius=config_initial_radius, 
                    parent_id=None, 
                    parent_measured_terminal_id=None 
                )
                active_terminals.append(term_gbo_data_obj)
                node_attrs_seed = vars(term_gbo_data_obj).copy()
                node_attrs_seed['is_flow_root'] = True ; node_attrs_seed['type'] = 'synthetic_root_terminal'
                node_attrs_seed['Q_flow'] = 0.0 
                node_attrs_seed['initial_config_radius'] = config_initial_radius 
                node_attrs_seed.pop('current_territory_voxel_indices_flat', None)
                node_attrs_seed.pop('current_territory_demand', None)
                data_structures.add_node_to_graph(gbo_graph, term_gbo_data_obj.id, **node_attrs_seed)
                logger.info(f"Initialized GBO seed terminal from config: {term_gbo_data_obj.id} at {np.round(seed_pos,2)} with R={config_initial_radius:.4f}. Marked as is_flow_root. Stored 'initial_config_radius'.")
        elif not processed_from_vtp_terminals:
             logger.info("No VTP terminals processed and no GBO seed points found in configuration. Checking fallback.")

    if not active_terminals: 
        logger.warning("No GBO starting points from VTP or config seeds. Attempting one fallback seed.")
        fallback_domain_mask = tissue_data.get('gbo_growth_domain_mask', tissue_data.get('domain_mask'))
        if fallback_domain_mask is not None and np.any(fallback_domain_mask):
            seed_point_world = utils.get_random_point_in_mask(fallback_domain_mask, tissue_data['affine'])
            if seed_point_world is not None:
                fallback_id = f"s_fallback_{next_synthetic_node_id}"; next_synthetic_node_id +=1
                term_gbo_data_obj = GBOIterationData(
                    terminal_id=fallback_id, 
                    pos=seed_point_world, 
                    radius=initial_synthetic_radius_default, 
                    flow=default_initial_flow,
                    original_measured_radius=None 
                )
                active_terminals.append(term_gbo_data_obj)
                node_attrs_fallback = vars(term_gbo_data_obj).copy()
                node_attrs_fallback['is_flow_root'] = True; node_attrs_fallback['type'] = 'synthetic_root_terminal'
                node_attrs_fallback['Q_flow'] = 0.0
                node_attrs_fallback.pop('current_territory_voxel_indices_flat', None); node_attrs_fallback.pop('current_territory_demand', None)
                data_structures.add_node_to_graph(gbo_graph, fallback_id, **node_attrs_fallback)
                logger.info(f"Initialized fallback GBO seed terminal {fallback_id} at {np.round(seed_point_world,2)}.")
            else: logger.error("Cannot find a valid random seed point within GBO growth domain for fallback.")
        else: logger.error("No GBO growth domain_mask available for fallback seeding.")

    if not active_terminals:
        logger.error("CRITICAL: No GBO terminals to initialize growth. Aborting GBO.")
        return perfused_tissue_mask, [], next_synthetic_node_id, gbo_graph

    if tissue_data.get('world_coords_flat') is None or tissue_data['world_coords_flat'].size == 0:
        logger.error("tissue_data['world_coords_flat'] (from GBO growth domain) is empty. Cannot initialize GBO territories.")
        for term_data in active_terminals: term_data.stop_growth = True
        return perfused_tissue_mask, active_terminals, next_synthetic_node_id, gbo_graph
        
    kdtree_gbo_domain_voxels = KDTree(tissue_data['world_coords_flat']) 
    initial_territory_radius_search = config_manager.get_param(config, "gbo_growth.initial_territory_radius", 0.2) 

    for term_gbo_obj in active_terminals: 
        nearby_flat_indices_in_gbo_domain = kdtree_gbo_domain_voxels.query_ball_point(term_gbo_obj.pos, r=initial_territory_radius_search)
        actual_demand_init = 0.0
        voxels_for_term_init_flat: List[int] = [] 
        if nearby_flat_indices_in_gbo_domain: 
            for local_kdtree_idx in nearby_flat_indices_in_gbo_domain:
                global_flat_idx = local_kdtree_idx
                v_3d_idx_tuple = tuple(tissue_data['voxel_indices_flat'][global_flat_idx]) 
                if not perfused_tissue_mask[v_3d_idx_tuple]: 
                    perfused_tissue_mask[v_3d_idx_tuple] = True
                    actual_demand_init += tissue_data['metabolic_demand_map'][v_3d_idx_tuple] 
                    voxels_for_term_init_flat.append(global_flat_idx)
        term_gbo_obj.current_territory_voxel_indices_flat = voxels_for_term_init_flat
        term_gbo_obj.current_territory_demand = actual_demand_init
        if actual_demand_init > constants.EPSILON:
            term_gbo_obj.flow = actual_demand_init
            new_r_demand_based = k_murray_factor * (term_gbo_obj.flow ** (1.0 / murray_exponent))
            if gbo_graph.nodes[term_gbo_obj.id].get('type') == 'synthetic_root_terminal' and \
               term_gbo_obj.original_measured_radius is not None: 
                 term_gbo_obj.radius = max(term_gbo_obj.original_measured_radius, new_r_demand_based, initial_synthetic_radius_default)
            else: 
                 term_gbo_obj.radius = max(initial_synthetic_radius_default, new_r_demand_based)
        else: 
            term_gbo_obj.flow = default_initial_flow 
        if gbo_graph.has_node(term_gbo_obj.id):
            gbo_node_data = gbo_graph.nodes[term_gbo_obj.id]
            if gbo_node_data.get('is_flow_root'): gbo_node_data['Q_flow'] = 0.0
            else: gbo_node_data['Q_flow'] = term_gbo_obj.flow
            gbo_node_data['radius'] = term_gbo_obj.radius
            if term_gbo_obj.current_territory_voxel_indices_flat:
                valid_indices_centroid = [idx for idx in term_gbo_obj.current_territory_voxel_indices_flat if idx < tissue_data['world_coords_flat'].shape[0]]
                if valid_indices_centroid:
                    initial_coords = tissue_data['world_coords_flat'][valid_indices_centroid]
                    if initial_coords.shape[0] > 0:
                        new_pos_centroid = np.mean(initial_coords, axis=0)
                        if utils.distance_squared(term_gbo_obj.pos, new_pos_centroid) > constants.EPSILON**2 : 
                            old_pos_log = term_gbo_obj.pos.copy()
                            term_gbo_obj.pos = new_pos_centroid 
                            gbo_node_data['pos'] = new_pos_centroid 
                            logger.debug(f"GBO Terminal {term_gbo_obj.id} (Ω_init): Moved from {np.round(old_pos_log,3)} to centroid {np.round(new_pos_centroid,3)}.")
                            if term_gbo_obj.parent_id and gbo_graph.has_edge(term_gbo_obj.parent_id, term_gbo_obj.id):
                                parent_pos = gbo_graph.nodes[term_gbo_obj.parent_id]['pos']
                                new_len = utils.distance(parent_pos, term_gbo_obj.pos)
                                gbo_graph.edges[term_gbo_obj.parent_id, term_gbo_obj.id]['length'] = new_len
                                term_gbo_obj.length_from_parent = new_len
        else: logger.error(f"GBO terminal {term_gbo_obj.id} from GBOIterationData not found in gbo_graph during territory init.")
        logger.debug(f"GBO Terminal {term_gbo_obj.id} (Ω_init final): Pos={np.round(term_gbo_obj.pos,3)}, Claimed {len(voxels_for_term_init_flat)} voxels, Demand={term_gbo_obj.current_territory_demand:.2e}, Target Flow={term_gbo_obj.flow:.2e}, Radius={term_gbo_obj.radius:.4f}")

    logger.info(f"GBO Initialization complete. Perfused {np.sum(perfused_tissue_mask)} initial voxels within GBO domain. {len(active_terminals)} active GBO terminals.")
    return perfused_tissue_mask, active_terminals, next_synthetic_node_id, gbo_graph


def find_growth_frontier_voxels(
    terminal_gbo_data: GBOIterationData,
    kdtree_unperfused_domain_voxels: Optional[KDTree],
    unperfused_global_flat_indices: np.ndarray,
    tissue_data: dict,
    config: dict
) -> np.ndarray:
    logger.debug(f"Terminal {terminal_gbo_data.id}: Entering find_growth_frontier_voxels. Pos: {np.round(terminal_gbo_data.pos,3)}, Radius: {terminal_gbo_data.radius:.4f}")
    if kdtree_unperfused_domain_voxels is None or kdtree_unperfused_domain_voxels.n == 0:
        logger.debug(f"Terminal {terminal_gbo_data.id}: KDTree of unperfused voxels is empty or None. No frontier.")
        return np.array([], dtype=int)
    radius_factor = config_manager.get_param(config, "gbo_growth.frontier_search_radius_factor", 3.0)
    fixed_radius = config_manager.get_param(config, "gbo_growth.frontier_search_radius_fixed", 0.25)
    voxel_dim = tissue_data['voxel_volume']**(1/3.0)
    search_r = max(radius_factor * terminal_gbo_data.radius, fixed_radius, voxel_dim * 1.5)
    logger.debug(f"Terminal {terminal_gbo_data.id}: Searching for frontier with effective radius {search_r:.3f}mm.")
    try:
        local_indices_in_kdtree = kdtree_unperfused_domain_voxels.query_ball_point(terminal_gbo_data.pos, r=search_r)
    except Exception as e:
        logger.error(f"Terminal {terminal_gbo_data.id}: KDTree query_ball_point failed: {e}", exc_info=True)
        return np.array([], dtype=int)
    if not local_indices_in_kdtree: return np.array([], dtype=int)
    if unperfused_global_flat_indices.shape[0] == 0:
        logger.warning(f"Terminal {terminal_gbo_data.id}: unperfused_global_flat_indices is empty.")
        return np.array([], dtype=int)
    valid_kdtree_indices = [idx for idx in local_indices_in_kdtree if idx < len(unperfused_global_flat_indices)]
    if len(valid_kdtree_indices) != len(local_indices_in_kdtree):
        logger.warning(f"Terminal {terminal_gbo_data.id}: Some KDTree indices out of bounds for unperfused_global_flat_indices.")
    if not valid_kdtree_indices: return np.array([], dtype=int)
    frontier_voxels_global_flat_indices_initial = unperfused_global_flat_indices[valid_kdtree_indices]
    max_voxels_in_Rip = config_manager.get_param(config, "gbo_growth.max_voxels_for_Rip", 50)
    final_frontier_voxels_global_flat_indices = frontier_voxels_global_flat_indices_initial
    if len(frontier_voxels_global_flat_indices_initial) > max_voxels_in_Rip:
        logger.debug(f"Terminal {terminal_gbo_data.id}: Initial frontier > max_voxels_for_Rip. Selecting closest.")
        try:
            k_val = min(max_voxels_in_Rip, kdtree_unperfused_domain_voxels.n)
            if k_val > 0 :
                _, local_indices_k_closest = kdtree_unperfused_domain_voxels.query(terminal_gbo_data.pos, k=k_val)
                if isinstance(local_indices_k_closest, (int, np.integer)): local_indices_k_closest = np.array([local_indices_k_closest])
                if len(local_indices_k_closest) > 0:
                    valid_k_closest_indices = [idx for idx in local_indices_k_closest if idx < len(unperfused_global_flat_indices)]
                    if valid_k_closest_indices: final_frontier_voxels_global_flat_indices = unperfused_global_flat_indices[valid_k_closest_indices]
                    else: final_frontier_voxels_global_flat_indices = np.array([], dtype=int)
                else: final_frontier_voxels_global_flat_indices = np.array([], dtype=int)
            else: final_frontier_voxels_global_flat_indices = np.array([], dtype=int)
        except Exception as e_kquery:
            logger.error(f"Terminal {terminal_gbo_data.id}: KDTree k-closest query failed: {e_kquery}.", exc_info=True)
    logger.info(f"Terminal {terminal_gbo_data.id} identified {len(final_frontier_voxels_global_flat_indices)} final frontier voxels (Ri,p).")
    return final_frontier_voxels_global_flat_indices

def prune_vascular_graph(
    graph: nx.DiGraph, 
    config: dict, 
    active_terminals_gbo_data: List[GBOIterationData]
) -> Tuple[nx.DiGraph, int, int]:
    prune_params = config_manager.get_param(config, "gbo_growth.pruning", {})
    min_flow_threshold = prune_params.get("min_flow_for_survival", constants.EPSILON * 10)
    min_radius_threshold = prune_params.get("min_radius_for_survival", constants.MIN_VESSEL_RADIUS_MM * 1.01) 
    preserve_path_to_active_demand_terminals = prune_params.get("preserve_path_to_active_demand_terminals", True)

    initial_nodes = graph.number_of_nodes()
    initial_edges = graph.number_of_edges()
    
    graph_to_prune = graph.copy()
    essential_nodes = set()
    root_nodes = {n for n, data in graph_to_prune.nodes(data=True) if data.get('is_flow_root', False)}
    essential_nodes.update(root_nodes)

    active_demand_terminal_nodes = set()
    for term_gbo in active_terminals_gbo_data:
        if not term_gbo.stop_growth and graph_to_prune.has_node(term_gbo.id):
            node_q_flow = graph_to_prune.nodes[term_gbo.id].get('Q_flow', 0.0)
            if term_gbo.flow > min_flow_threshold or abs(node_q_flow) > min_flow_threshold :
                active_demand_terminal_nodes.add(term_gbo.id)
    essential_nodes.update(active_demand_terminal_nodes)
    logger.debug(f"Pruning: Identified {len(root_nodes)} roots and {len(active_demand_terminal_nodes)} active/demanding terminals as initially essential.")

    if preserve_path_to_active_demand_terminals and root_nodes and active_demand_terminal_nodes:
        undirected_view = graph_to_prune.to_undirected(as_view=True)
        paths_preserved_count = 0
        for term_node in active_demand_terminal_nodes:
            path_found_for_this_terminal = False
            for r_node in root_nodes:
                if r_node in undirected_view and term_node in undirected_view:
                    try:
                        path = nx.shortest_path(undirected_view, source=r_node, target=term_node)
                        essential_nodes.update(path)
                        path_found_for_this_terminal = True
                        paths_preserved_count +=1 
                        break 
                    except nx.NetworkXNoPath:
                        continue 
                    except nx.NodeNotFound:
                        logger.warning(f"Pruning: Node {r_node} or {term_node} not found in undirected view for path preservation.")
                        continue 
            if not path_found_for_this_terminal:
                logger.warning(f"Pruning: Active terminal {term_node} could not find a path to ANY root. It might become isolated if not already part of another essential structure.")
        logger.debug(f"Pruning: Attempted to preserve paths for {len(active_demand_terminal_nodes)} active terminals. Successful path preservations (root-terminal pairs): {paths_preserved_count}.")


    max_pruning_passes = 5 
    for pass_num in range(max_pruning_passes):
        nodes_before_pass = graph_to_prune.number_of_nodes()
        edges_before_pass = graph_to_prune.number_of_edges()
        
        edges_to_remove_this_pass = []
        for u, v, data in graph_to_prune.edges(data=True):
            flow_val = data.get('flow_solver', 0.0)
            radius_val = data.get('radius', 0.0)
            can_prune_edge = True
            
            if u in essential_nodes and v in essential_nodes:
                if abs(flow_val) >= (min_flow_threshold / 10.0) and radius_val >= (min_radius_threshold / 1.5) : 
                    can_prune_edge = False
            
            if (abs(flow_val) < min_flow_threshold and radius_val < min_radius_threshold) and can_prune_edge:
                edges_to_remove_this_pass.append((u,v))

        if not edges_to_remove_this_pass:
            logger.debug(f"Pruning pass {pass_num+1}: No more edges meet flow/radius removal criteria.")
            break 

        for u_rem, v_rem in edges_to_remove_this_pass: 
            if graph_to_prune.has_edge(u_rem,v_rem):
                graph_to_prune.remove_edge(u_rem,v_rem)
        logger.debug(f"Pruning pass {pass_num+1}: Removed {len(edges_to_remove_this_pass)} low-flow/radius edges.")

        nodes_to_remove_this_pass = []
        for node_id_check in list(graph_to_prune.nodes()): 
            if node_id_check in essential_nodes: continue 

            if graph_to_prune.degree(node_id_check) == 0: 
                nodes_to_remove_this_pass.append(node_id_check)
        
        if nodes_to_remove_this_pass:
            for node_id_rem_iso in nodes_to_remove_this_pass: 
                 if graph_to_prune.has_node(node_id_rem_iso): 
                    graph_to_prune.remove_node(node_id_rem_iso)
            logger.debug(f"Pruning pass {pass_num+1}: Removed {len(nodes_to_remove_this_pass)} isolated non-essential nodes.")

        if graph_to_prune.number_of_nodes() == nodes_before_pass and \
           graph_to_prune.number_of_edges() == edges_before_pass:
            logger.debug(f"Pruning pass {pass_num+1}: No change in graph size. Pruning converged.")
            break
    else: 
        if pass_num == max_pruning_passes -1 :
            logger.warning(f"Pruning finished after {max_pruning_passes} passes without full convergence.")

    if graph_to_prune.number_of_nodes() > 0 and root_nodes:
        undirected_final_view = graph_to_prune.to_undirected(as_view=True)
        nodes_to_finally_keep = set()
        for r_node_final in root_nodes: 
            if r_node_final in undirected_final_view: 
                try: 
                    component_with_root = nx.node_connected_component(undirected_final_view, r_node_final)
                    nodes_to_finally_keep.update(component_with_root)
                except nx.NodeNotFound: 
                    logger.warning(f"Root node {r_node_final} not found in graph during final connectivity component search, though it was expected.")
            else:
                logger.warning(f"Root node {r_node_final} was removed or disconnected during pruning passes. This might be an issue.")
        
        nodes_to_remove_final_disconnect = []
        if not nodes_to_finally_keep and graph_to_prune.number_of_nodes() > 0 : 
            logger.error("Pruning Error: All root nodes are gone or no nodes are connected to any root! Graph will likely be empty or fully disconnected from roots.")
            nodes_to_remove_final_disconnect = list(graph_to_prune.nodes()) 
        elif nodes_to_finally_keep:
            nodes_to_remove_final_disconnect = list(set(graph_to_prune.nodes()) - nodes_to_finally_keep)
        
        if nodes_to_remove_final_disconnect:
            graph_to_prune.remove_nodes_from(nodes_to_remove_final_disconnect)
            logger.info(f"Final pruning step: Removed {len(nodes_to_remove_final_disconnect)} nodes not connected to any root.")
    elif not root_nodes and graph_to_prune.number_of_nodes() > 0:
        logger.error("Pruning: No root nodes in the graph to begin with or after pruning. Cannot ensure connectivity. All non-isolated nodes will be kept.")

    num_nodes_pruned = initial_nodes - graph_to_prune.number_of_nodes()
    num_edges_pruned = initial_edges - graph_to_prune.number_of_edges()
    return graph_to_prune, num_nodes_pruned, num_edges_pruned


def grow_healthy_vasculature(config: dict,
                             tissue_data: dict,
                             initial_graph: Optional[nx.DiGraph],
                             output_dir: str) -> Optional[nx.DiGraph]:
    logger.info("Starting GBO healthy vascular growth with perfusion-sensitive behavior...")

    perfused_tissue_mask, current_active_terminals, next_node_id, gbo_graph = \
        initialize_perfused_territory_and_terminals(config, initial_graph, tissue_data)

    if not current_active_terminals:
        logger.error("GBO Aborted: No active GBO terminals after initialization.")
        return gbo_graph

    max_iterations = config_manager.get_param(config, "gbo_growth.max_iterations", 100)
    min_radius = config_manager.get_param(config, "vascular_properties.min_radius", constants.MIN_VESSEL_RADIUS_MM)
    k_murray = config_manager.get_param(config, "vascular_properties.k_murray_scaling_factor", 0.5)
    murray_exp = config_manager.get_param(config, "vascular_properties.murray_law_exponent", 3.0)
    branch_radius_factor_thresh = config_manager.get_param(config, "gbo_growth.branch_radius_increase_threshold", 1.1)
    max_flow_single_term = config_manager.get_param(config, "gbo_growth.max_flow_single_terminal", 0.005)
    min_iters_no_growth_stop = config_manager.get_param(config, "gbo_growth.min_iterations_before_no_growth_stop", 10)
    min_demand_rip_bif_factor = config_manager.get_param(config, "gbo_growth.min_frontier_demand_factor_for_bifurcation", 0.3)
    default_initial_flow = config_manager.get_param(config, "vascular_properties.initial_terminal_flow", constants.INITIAL_TERMINAL_FLOW_Q)
    flow_solver_interval = config_manager.get_param(config, "gbo_growth.flow_solver_interval", 1)
    max_segment_length_gbo = config_manager.get_param(config, "vascular_properties.max_segment_length", 2.0)
    
    blender_snapshot_interval = config_manager.get_param(config, "visualization.blender_snapshot_interval", 0)


    perf_driven_config = config_manager.get_param(config, "gbo_growth.perfusion_driven_behavior", {})
    perf_driven_enabled = perf_driven_config.get("enabled", False) 
    min_territory_perfusion_ratio = perf_driven_config.get("min_territory_perfusion_ratio", 0.7)
    sub_branch_if_hypoxic = perf_driven_config.get("sub_branching_if_hypoxic", False)
    min_r_hypoxic_sub_branch = perf_driven_config.get("min_radius_for_hypoxic_sub_branching", 0.05)

    total_voxels_in_domain = np.sum(tissue_data.get('domain_mask', np.array([])))
    if total_voxels_in_domain == 0: logger.warning("Healthy GBO: Domain mask is empty.")

    map_3d_to_flat_idx = -np.ones(tissue_data['shape'], dtype=np.int64)
    if tissue_data.get('voxel_indices_flat') is not None and tissue_data['voxel_indices_flat'].size > 0:
        valid_indices = tissue_data['voxel_indices_flat']
        valid_mask = (valid_indices[:,0] < tissue_data['shape'][0]) & (valid_indices[:,1] < tissue_data['shape'][1]) & \
                     (valid_indices[:,2] < tissue_data['shape'][2]) & (valid_indices[:,0] >= 0) & \
                     (valid_indices[:,1] >= 0) & (valid_indices[:,2] >= 0)
        valid_indices = valid_indices[valid_mask]
        if valid_indices.size > 0:
            map_3d_to_flat_idx[valid_indices[:,0], valid_indices[:,1], valid_indices[:,2]] = np.arange(valid_indices.shape[0])

    for iteration in range(max_iterations):
        current_iteration_num = iteration + 1 
        logger.info(f"--- GBO Iteration {current_iteration_num} / {max_iterations} ---")
        
        terminals_for_growth_attempt = [t for t in current_active_terminals if not t.stop_growth]
        if not terminals_for_growth_attempt: logger.info("GBO: No active terminals for growth."); break

        current_perfused_count = np.sum(perfused_tissue_mask)
        perf_percentage = (current_perfused_count / total_voxels_in_domain * 100) if total_voxels_in_domain > 0 else 0
        logger.info(f"Active terminals: {len(terminals_for_growth_attempt)}. Perfused voxels: {current_perfused_count}/{total_voxels_in_domain} ({perf_percentage:.1f}%)")

        unperfused_mask_3d = tissue_data.get('domain_mask', np.zeros(tissue_data['shape'], dtype=bool)) & (~perfused_tissue_mask)
        unperfused_voxels_3d_indices = np.array(np.where(unperfused_mask_3d)).T
        kdtree_unperfused: Optional[KDTree] = None
        unperfused_kdtree_global_flat_indices: np.ndarray = np.array([], dtype=int)
        if unperfused_voxels_3d_indices.shape[0] > 0:
            unperfused_voxels_world_coords_for_kdt_build = utils.voxel_to_world(unperfused_voxels_3d_indices, tissue_data['affine'])
            temp_flat_indices = map_3d_to_flat_idx[unperfused_voxels_3d_indices[:,0], unperfused_voxels_3d_indices[:,1], unperfused_voxels_3d_indices[:,2]]
            valid_for_kdtree_mask = (temp_flat_indices != -1)
            if np.any(valid_for_kdtree_mask):
                unperfused_kdtree_global_flat_indices = temp_flat_indices[valid_for_kdtree_mask]
                unperfused_voxels_world_coords_for_kdt_build = unperfused_voxels_world_coords_for_kdt_build[valid_for_kdtree_mask]
                if unperfused_voxels_world_coords_for_kdt_build.shape[0] > 0:
                    kdtree_unperfused = KDTree(unperfused_voxels_world_coords_for_kdt_build)
            else: logger.debug("No unperfused voxels mapped to valid flat indices for KDTree.")
        if kdtree_unperfused is None or kdtree_unperfused.n == 0: logger.info("GBO: No unperfused domain voxels for KDTree this iteration.")

        next_iter_terminals_manager: List[GBOIterationData] = []
        newly_perfused_in_iter_mask = np.zeros_like(perfused_tissue_mask)

        for term_p_gbo_data in terminals_for_growth_attempt:
            logger.debug(f"Processing GBO terminal {term_p_gbo_data.id}. Pos: {np.round(term_p_gbo_data.pos,3)}, R: {term_p_gbo_data.radius:.4f}, Target Q: {term_p_gbo_data.flow:.2e}, Actual Q: {term_p_gbo_data.actual_received_flow:.2e}, PerfRatio: {term_p_gbo_data.perfusion_ratio:.2f}")
            can_seek_new_frontier = True
            if perf_driven_enabled and iteration > 0: 
                if term_p_gbo_data.perfusion_ratio < min_territory_perfusion_ratio:
                    can_seek_new_frontier = False
                    logger.debug(f"Terminal {term_p_gbo_data.id} INSUFFICIENTLY PERFUSED. Not seeking new frontier.")
                    if sub_branch_if_hypoxic and term_p_gbo_data.radius >= min_r_hypoxic_sub_branch and \
                       len(term_p_gbo_data.current_territory_voxel_indices_flat) >= 2 :
                        logger.debug(f"Terminal {term_p_gbo_data.id} attempting hypoxic sub-branching.")
                        hypoxic_bif_result = energy_model.find_optimal_bifurcation_for_combined_territory(term_p_gbo_data, np.array(term_p_gbo_data.current_territory_voxel_indices_flat, dtype=int), tissue_data, config, k_murray, murray_exp)
                        if hypoxic_bif_result:
                            c1_pos, c1_rad, c1_flow, c2_pos, c2_rad, c2_flow, _ = hypoxic_bif_result
                            parent_node_gbo_graph_data = gbo_graph.nodes[term_p_gbo_data.id]
                            parent_is_flow_root = parent_node_gbo_graph_data.get('is_flow_root', False)
                            new_parent_q = c1_flow + c2_flow
                            new_parent_r = max(min_radius, k_murray * (new_parent_q ** (1.0 / murray_exp)))
                            parent_node_gbo_graph_data.update(type='synthetic_bifurcation', radius=new_parent_r, Q_flow=new_parent_q if not parent_is_flow_root else 0.0, is_flow_root=parent_is_flow_root)
                            for _, (child_pos, child_rad, child_flow_val) in enumerate([(c1_pos, c1_rad, c1_flow), (c2_pos, c2_rad, c2_flow)]):
                                child_id = f"s_{next_node_id}"; next_node_id += 1
                                child_gbo_obj = GBOIterationData(child_id, child_pos, child_rad, child_flow_val, parent_id=term_p_gbo_data.id, parent_measured_terminal_id=term_p_gbo_data.parent_measured_terminal_id, original_measured_radius=term_p_gbo_data.original_measured_radius)
                                child_gbo_obj.length_from_parent = utils.distance(parent_node_gbo_graph_data['pos'], child_pos)
                                next_iter_terminals_manager.append(child_gbo_obj)
                                child_attrs = vars(child_gbo_obj).copy(); child_attrs['type'] = 'synthetic_terminal'; child_attrs['is_flow_root'] = False; child_attrs['Q_flow'] = child_gbo_obj.flow
                                child_attrs.pop('current_territory_voxel_indices_flat', None); child_attrs.pop('current_territory_demand', None)
                                data_structures.add_node_to_graph(gbo_graph, child_id, **child_attrs)
                                data_structures.add_edge_to_graph(gbo_graph, term_p_gbo_data.id, child_id, length=child_gbo_obj.length_from_parent, radius=new_parent_r, type='synthetic_segment')
                            term_p_gbo_data.stop_growth = True 
                            logger.info(f"Terminal {term_p_gbo_data.id} sub-branched due to low perfusion. Children flows: {c1_flow:.2e}, {c2_flow:.2e}.")
                            continue 
                        else: logger.debug(f"Terminal {term_p_gbo_data.id}: Hypoxic sub-branching failed.")
                    next_iter_terminals_manager.append(term_p_gbo_data); continue 

            unique_frontier_global_flat_indices = np.array([], dtype=int); demand_Rip = 0.0
            if can_seek_new_frontier:
                local_indices_in_kdt = find_growth_frontier_voxels(term_p_gbo_data, kdtree_unperfused, np.arange(kdtree_unperfused.n if kdtree_unperfused else 0), tissue_data, config)
                if kdtree_unperfused is not None and kdtree_unperfused.n > 0 and local_indices_in_kdt.size > 0:
                    current_frontier_global_flat_indices = unperfused_kdtree_global_flat_indices[local_indices_in_kdt]
                    unique_frontier_global_flat_indices = np.unique(current_frontier_global_flat_indices)
                    if unique_frontier_global_flat_indices.size > 0:
                        demand_map_3d_indices_frontier = tissue_data['voxel_indices_flat'][unique_frontier_global_flat_indices]
                        demand_of_frontier_voxels = tissue_data['metabolic_demand_map'][demand_map_3d_indices_frontier[:,0], demand_map_3d_indices_frontier[:,1], demand_map_3d_indices_frontier[:,2]]
                        demand_Rip = np.sum(demand_of_frontier_voxels)
            
            if demand_Rip < constants.EPSILON and can_seek_new_frontier : 
                logger.debug(f"Terminal {term_p_gbo_data.id} found no new frontier demand.")
                next_iter_terminals_manager.append(term_p_gbo_data); continue
            
            potential_total_flow_if_extended = term_p_gbo_data.flow + demand_Rip 
            potential_radius_if_extended = k_murray * (potential_total_flow_if_extended ** (1.0 / murray_exp))
            attempt_branching = False
            if term_p_gbo_data.radius > constants.EPSILON and potential_radius_if_extended > term_p_gbo_data.radius * branch_radius_factor_thresh : attempt_branching = True
            if potential_total_flow_if_extended > max_flow_single_term: attempt_branching = True
            if demand_Rip > term_p_gbo_data.flow * min_demand_rip_bif_factor and term_p_gbo_data.flow > constants.EPSILON : attempt_branching = True
            
            if attempt_branching and unique_frontier_global_flat_indices.size > 0: 
                old_territory_indices_flat = np.array(term_p_gbo_data.current_territory_voxel_indices_flat, dtype=int)
                combined_territory_indices_flat = np.unique(np.concatenate((old_territory_indices_flat, unique_frontier_global_flat_indices))) if old_territory_indices_flat.size > 0 else unique_frontier_global_flat_indices
                if len(combined_territory_indices_flat) < 2: attempt_branching = False
                else: 
                    bifurcation_result = energy_model.find_optimal_bifurcation_for_combined_territory(term_p_gbo_data, combined_territory_indices_flat, tissue_data, config, k_murray, murray_exp)
                    if bifurcation_result:
                        c1_pos, c1_rad, c1_total_flow, c2_pos, c2_rad, c2_total_flow, _ = bifurcation_result
                        new_parent_total_flow = c1_total_flow + c2_total_flow
                        new_parent_radius = max(min_radius, k_murray * (new_parent_total_flow ** (1.0 / murray_exp)))
                        parent_node_gbo_graph_data = gbo_graph.nodes[term_p_gbo_data.id]
                        parent_is_flow_root = parent_node_gbo_graph_data.get('is_flow_root', False)
                        parent_node_gbo_graph_data.update(type='synthetic_bifurcation', radius=new_parent_radius, Q_flow=new_parent_total_flow if not parent_is_flow_root else 0.0, is_flow_root=parent_is_flow_root)
                        for _, (child_pos, child_rad, child_flow_val) in enumerate([(c1_pos, c1_rad, c1_total_flow), (c2_pos, c2_rad, c2_total_flow)]):
                            child_id = f"s_{next_node_id}"; next_node_id += 1
                            child_gbo_obj = GBOIterationData(child_id, child_pos, child_rad, child_flow_val, parent_id=term_p_gbo_data.id, parent_measured_terminal_id=term_p_gbo_data.parent_measured_terminal_id, original_measured_radius=term_p_gbo_data.original_measured_radius)
                            child_gbo_obj.length_from_parent = utils.distance(parent_node_gbo_graph_data['pos'], child_pos)
                            next_iter_terminals_manager.append(child_gbo_obj)
                            child_attrs = vars(child_gbo_obj).copy(); child_attrs['type'] = 'synthetic_terminal'; child_attrs['is_flow_root'] = False; child_attrs['Q_flow'] = child_gbo_obj.flow
                            child_attrs.pop('current_territory_voxel_indices_flat', None); child_attrs.pop('current_territory_demand', None)
                            data_structures.add_node_to_graph(gbo_graph, child_id, **child_attrs)
                            data_structures.add_edge_to_graph(gbo_graph, term_p_gbo_data.id, child_id, length=child_gbo_obj.length_from_parent, radius=new_parent_radius, type='synthetic_segment')
                        for v_idx_flat in unique_frontier_global_flat_indices: newly_perfused_in_iter_mask[tuple(tissue_data['voxel_indices_flat'][v_idx_flat])] = True
                        term_p_gbo_data.stop_growth = True 
                        logger.info(f"Terminal {term_p_gbo_data.id} branched. Children flows: {c1_total_flow:.2e}, {c2_total_flow:.2e}.")
                    else: attempt_branching = False 
            
            if not attempt_branching and demand_Rip > constants.EPSILON: 
                old_pos_ext = term_p_gbo_data.pos.copy()
                logger.debug(f"Terminal {term_p_gbo_data.id} extending for Ri,p (demand {demand_Rip:.2e}).")
                term_p_gbo_data.flow += demand_Rip 
                term_p_gbo_data.radius = max(min_radius, k_murray * (term_p_gbo_data.flow ** (1.0 / murray_exp)))
                if unique_frontier_global_flat_indices.size > 0:
                    current_territory_coords_list = []
                    if term_p_gbo_data.current_territory_voxel_indices_flat:
                         valid_curr_idx_ext = [idx for idx in term_p_gbo_data.current_territory_voxel_indices_flat if idx < tissue_data['world_coords_flat'].shape[0]]
                         if valid_curr_idx_ext: current_territory_coords_list.append(tissue_data['world_coords_flat'][valid_curr_idx_ext])
                    newly_acquired_coords = tissue_data['world_coords_flat'][unique_frontier_global_flat_indices]
                    current_territory_coords_list.append(newly_acquired_coords)
                    all_supplied_coords = np.vstack(current_territory_coords_list)
                    if all_supplied_coords.shape[0] > 0:
                        new_target_pos = np.mean(all_supplied_coords, axis=0)
                        extension_vector = new_target_pos - old_pos_ext
                        extension_length = np.linalg.norm(extension_vector)
                        if extension_length > constants.EPSILON:
                            move_dist = min(extension_length, max_segment_length_gbo)
                            term_p_gbo_data.pos = old_pos_ext + extension_vector * (move_dist / extension_length)
                            if term_p_gbo_data.parent_id and gbo_graph.has_edge(term_p_gbo_data.parent_id, term_p_gbo_data.id):
                                parent_pos = gbo_graph.nodes[term_p_gbo_data.parent_id]['pos']
                                new_len = utils.distance(parent_pos, term_p_gbo_data.pos)
                                gbo_graph.edges[term_p_gbo_data.parent_id, term_p_gbo_data.id]['length'] = new_len
                                if gbo_graph.has_node(term_p_gbo_data.parent_id): gbo_graph.edges[term_p_gbo_data.parent_id, term_p_gbo_data.id]['radius'] = gbo_graph.nodes[term_p_gbo_data.parent_id]['radius']
                                term_p_gbo_data.length_from_parent = new_len
                if gbo_graph.has_node(term_p_gbo_data.id): gbo_graph.nodes[term_p_gbo_data.id].update(pos=term_p_gbo_data.pos, Q_flow=term_p_gbo_data.flow if not gbo_graph.nodes[term_p_gbo_data.id].get('is_flow_root') else 0.0, radius=term_p_gbo_data.radius)
                for v_idx_flat in unique_frontier_global_flat_indices: newly_perfused_in_iter_mask[tuple(tissue_data['voxel_indices_flat'][v_idx_flat])] = True
                term_p_gbo_data.current_territory_voxel_indices_flat.extend(list(unique_frontier_global_flat_indices))
                next_iter_terminals_manager.append(term_p_gbo_data)
            elif not attempt_branching and demand_Rip == 0.0 and can_seek_new_frontier: 
                next_iter_terminals_manager.append(term_p_gbo_data) 
            elif not attempt_branching and not can_seek_new_frontier : 
                 next_iter_terminals_manager.append(term_p_gbo_data)


        current_active_terminals = next_iter_terminals_manager
        perfused_tissue_mask = perfused_tissue_mask | newly_perfused_in_iter_mask
        num_newly_perfused_this_iter = np.sum(newly_perfused_in_iter_mask)
        logger.info(f"Perfused {num_newly_perfused_this_iter} new voxels in GBO growth/branching phase.")
        
        if current_active_terminals and np.any(perfused_tissue_mask):
            live_terminals_for_adaptation = [t for t in current_active_terminals if not t.stop_growth]
            if live_terminals_for_adaptation:
                perfused_3d_indices_vor = np.array(np.where(perfused_tissue_mask)).T
                if perfused_3d_indices_vor.shape[0] > 0:
                    perfused_global_flat_indices_vor = map_3d_to_flat_idx[perfused_3d_indices_vor[:,0], perfused_3d_indices_vor[:,1], perfused_3d_indices_vor[:,2]]
                    valid_flat_mask_for_perf_vor = perfused_global_flat_indices_vor != -1
                    perfused_global_flat_indices_vor = perfused_global_flat_indices_vor[valid_flat_mask_for_perf_vor]
                    if perfused_global_flat_indices_vor.size > 0 :
                        perfused_world_coords_for_voronoi = tissue_data['world_coords_flat'][perfused_global_flat_indices_vor]
                        term_positions_vor = np.array([t.pos for t in live_terminals_for_adaptation])
                        term_flows_capacity_vor = np.array([t.radius**murray_exp if t.radius > constants.EPSILON else default_initial_flow for t in live_terminals_for_adaptation])
                        assigned_local_term_indices = np.full(perfused_world_coords_for_voronoi.shape[0], -1, dtype=int)
                        for i_pvox, p_vox_wc in enumerate(perfused_world_coords_for_voronoi):
                            distances_sq = np.sum((term_positions_vor - p_vox_wc)**2, axis=1)
                            weighted_distances = distances_sq / (term_flows_capacity_vor + constants.EPSILON) 
                            assigned_local_term_indices[i_pvox] = np.argmin(weighted_distances)
                        for t_data_vor in live_terminals_for_adaptation: t_data_vor.current_territory_voxel_indices_flat, t_data_vor.current_territory_demand = [], 0.0
                        for i_pvox, local_term_idx in enumerate(assigned_local_term_indices):
                            if local_term_idx != -1 and local_term_idx < len(live_terminals_for_adaptation):
                                term_obj_vor = live_terminals_for_adaptation[local_term_idx]
                                global_flat_v_idx_vor = perfused_global_flat_indices_vor[i_pvox]
                                term_obj_vor.current_territory_voxel_indices_flat.append(global_flat_v_idx_vor)
                                term_obj_vor.current_territory_demand += tissue_data['metabolic_demand_map'][tuple(tissue_data['voxel_indices_flat'][global_flat_v_idx_vor])]
                        for t_data_vor in live_terminals_for_adaptation: 
                            t_data_vor.flow = t_data_vor.current_territory_demand if t_data_vor.current_territory_demand > constants.EPSILON else default_initial_flow
                            if not ((current_iteration_num % flow_solver_interval == 0) or iteration == max_iterations - 1): 
                                new_r_vor = k_murray * (t_data_vor.flow ** (1.0 / murray_exp))
                                t_data_vor.radius = max(min_radius, new_r_vor)
                                if gbo_graph.has_node(t_data_vor.id): 
                                    node_to_update = gbo_graph.nodes[t_data_vor.id]
                                    node_to_update['radius'] = t_data_vor.radius
                                    if not node_to_update.get('is_flow_root'): node_to_update['Q_flow'] = t_data_vor.flow
                            t_data_vor.actual_received_flow = 0.0 
                            t_data_vor.perfusion_ratio = 0.0
                            logger.debug(f"Term {t_data_vor.id} (Voronoi Refined): Target Q_demand={t_data_vor.flow:.2e}, Current R={t_data_vor.radius:.4f}")
                    logger.info("Completed Voronoi refinement.")

                run_flow_solver_this_iteration = ((current_iteration_num % flow_solver_interval == 0) or (iteration == max_iterations - 1 and iteration >= 0))
                if run_flow_solver_this_iteration and gbo_graph.number_of_nodes() > 0 :
                    logger.info(f"Running 1D network flow solver for GBO iteration {current_iteration_num}...")
                    for term_obj_flow_set in live_terminals_for_adaptation: 
                        if gbo_graph.has_node(term_obj_flow_set.id):
                            node_data_fs = gbo_graph.nodes[term_obj_flow_set.id]
                            if not node_data_fs.get('is_flow_root', False): node_data_fs['Q_flow'] = term_obj_flow_set.flow
                            else: node_data_fs['Q_flow'] = 0.0
                    temp_graph_for_solver = gbo_graph.copy()
                    gbo_graph_with_flow = perfusion_solver.solve_1d_poiseuille_flow(temp_graph_for_solver, config, None, None)
                    if gbo_graph_with_flow:
                        gbo_graph = gbo_graph_with_flow; logger.info("Flow solution obtained. Starting global radius adaptation...")
                        nodes_to_adapt_gbo = [n for n, data_gbo_adapt in gbo_graph.nodes(data=True) if data_gbo_adapt.get('type','').startswith('synthetic_') or data_gbo_adapt.get('type') == 'measured_to_synthetic_junction']
                        for node_id_adapt in nodes_to_adapt_gbo:
                            node_data_adapt = gbo_graph.nodes[node_id_adapt]; actual_node_flow = 0.0
                            original_radius_before_adapt = node_data_adapt.get('radius', min_radius); node_type_for_adapt = node_data_adapt.get('type')
                            is_sink_node = gbo_graph.out_degree(node_id_adapt) == 0 and gbo_graph.in_degree(node_id_adapt) > 0
                            is_source_like_node = gbo_graph.out_degree(node_id_adapt) > 0
                            if is_sink_node: 
                                for _, _, edge_data_in in gbo_graph.in_edges(node_id_adapt, data=True):
                                    solved_in_flow = edge_data_in.get('flow_solver',0.0) 
                                    if solved_in_flow is not None and np.isfinite(solved_in_flow): actual_node_flow += abs(solved_in_flow)
                            elif is_source_like_node: 
                                for _, _, edge_data_out in gbo_graph.out_edges(node_id_adapt, data=True):
                                    solved_out_flow = edge_data_out.get('flow_solver',0.0) 
                                    if solved_out_flow is not None and np.isfinite(solved_out_flow): actual_node_flow += abs(solved_out_flow)
                            if is_sink_node:
                                for term_obj_sync in live_terminals_for_adaptation:
                                    if term_obj_sync.id == node_id_adapt:
                                        term_obj_sync.actual_received_flow = actual_node_flow
                                        if term_obj_sync.flow > constants.EPSILON : 
                                            term_obj_sync.perfusion_ratio = actual_node_flow / term_obj_sync.flow
                                        else: term_obj_sync.perfusion_ratio = 1.0 if actual_node_flow < constants.EPSILON else 0.0 
                                        logger.debug(f"Terminal {term_obj_sync.id} after solve: TargetQ={term_obj_sync.flow:.2e}, ActualQ={term_obj_sync.actual_received_flow:.2e}, PerfRatio={term_obj_sync.perfusion_ratio:.2f}")
                                        break
                            
                            max_allowable_r_for_node = node_data_adapt.get('initial_config_radius') 
                            
                            if node_data_adapt.get('is_flow_root', False) and \
                               node_data_adapt.get('type') != 'synthetic_bifurcation' and \
                               max_allowable_r_for_node is None: 
                                logger.debug(f"GlobalAdapt GBO: Node {node_id_adapt} is a non-bifurcating, non-config-seed root. Radius not adapted by flow.")
                                continue
                            
                            if abs(actual_node_flow) > constants.EPSILON:
                                new_radius_adapted = k_murray * (abs(actual_node_flow) ** (1.0 / murray_exp))
                                new_radius_adapted = max(min_radius, new_radius_adapted)
                                if max_allowable_r_for_node is not None:
                                    if new_radius_adapted > max_allowable_r_for_node:
                                        logger.debug(f"Node {node_id_adapt} (orig_config_seed) radius {new_radius_adapted:.4f} capped to initial_config_radius {max_allowable_r_for_node:.4f}")
                                        new_radius_adapted = max_allowable_r_for_node 
                                    new_radius_adapted = max(min_radius, new_radius_adapted)
                                if not np.isclose(original_radius_before_adapt, new_radius_adapted, rtol=1e-2, atol=1e-5): 
                                    logger.info(f"GlobalAdapt GBO: Node {node_id_adapt} ({node_type_for_adapt}, IsRoot:{node_data_adapt.get('is_flow_root',False)}) R: {original_radius_before_adapt:.4f} -> {new_radius_adapted:.4f} (Q_sum={actual_node_flow:.2e})")
                                node_data_adapt['radius'] = new_radius_adapted
                            elif original_radius_before_adapt > min_radius + constants.EPSILON : 
                                new_radius_adapted = min_radius
                                if max_allowable_r_for_node is not None:
                                    new_radius_adapted = min(new_radius_adapted, max_allowable_r_for_node) 
                                logger.info(f"GlobalAdapt GBO: Node {node_id_adapt} ({node_type_for_adapt}, IsRoot:{node_data_adapt.get('is_flow_root',False)}) Q_sum near zero. Shrinking R from {original_radius_before_adapt:.4f} to {new_radius_adapted:.4f}.")
                                node_data_adapt['radius'] = new_radius_adapted
                        
                        for term_obj_sync in live_terminals_for_adaptation: 
                            if gbo_graph.has_node(term_obj_sync.id): term_obj_sync.radius = gbo_graph.nodes[term_obj_sync.id]['radius']
                        logger.info("Global radius adaptation for GBO tree complete.")
                    else: logger.error("Flow solver did not return a graph. Skipping GBO radius adaptation.")
                else: logger.info(f"Skipping GBO flow solver and global radius adaptation for iteration {current_iteration_num}.")

        if config_manager.get_param(config, "gbo_growth.pruning.enabled", True) and \
           (current_iteration_num % config_manager.get_param(config, "gbo_growth.pruning.interval", 5) == 0 or \
            iteration == max_iterations - 1):
            logger.info(f"--- GBO Iteration {current_iteration_num}: Pruning Phase ---")
            gbo_graph, num_nodes_pruned, num_edges_pruned = prune_vascular_graph(gbo_graph, config, current_active_terminals)
            logger.info(f"Pruning removed {num_nodes_pruned} nodes and {num_edges_pruned} edges.")
            updated_active_terminals_after_prune = []
            if gbo_graph.number_of_nodes() > 0: 
                root_nodes_for_check = {n for n, data in gbo_graph.nodes(data=True) if data.get('is_flow_root', False)}
                graph_for_path_check = None
                if root_nodes_for_check : graph_for_path_check = gbo_graph.to_undirected(as_view=True)
                for term_obj in current_active_terminals: 
                    if not gbo_graph.has_node(term_obj.id): logger.debug(f"Terminal GBO object {term_obj.id} pruned."); continue 
                    is_connected_to_any_root = False 
                    if root_nodes_for_check and graph_for_path_check is not None: 
                        for root_node_id in root_nodes_for_check:
                            if root_node_id in graph_for_path_check and term_obj.id in graph_for_path_check:
                                if nx.has_path(graph_for_path_check, source=root_node_id, target=term_obj.id):
                                    is_connected_to_any_root = True; break
                    elif not root_nodes_for_check : is_connected_to_any_root = False 
                    else: is_connected_to_any_root = False; logger.warning(f"Terminal {term_obj.id}: Path check graph for post-pruning not available.")
                    if is_connected_to_any_root: updated_active_terminals_after_prune.append(term_obj)
                    else:
                        logger.warning(f"Terminal {term_obj.id} disconnected from ALL roots after pruning. Stopping growth.")
                        term_obj.stop_growth = True; updated_active_terminals_after_prune.append(term_obj)
            else: logger.warning("Graph is empty after pruning.")
            current_active_terminals = updated_active_terminals_after_prune 
            logger.info(f"Active GBO terminals after pruning: {len(current_active_terminals)}")

        logger.info("Updating stop flags for GBO terminals...")
        active_terminals_still_growing = 0
        for term_data_stop_check in current_active_terminals: 
            if term_data_stop_check.stop_growth:
                if gbo_graph.has_node(term_data_stop_check.id): gbo_graph.nodes[term_data_stop_check.id]['stop_growth'] = True
                continue
            if term_data_stop_check.radius < (min_radius + constants.EPSILON) : 
                term_data_stop_check.stop_growth = True
                logger.info(f"Terminal {term_data_stop_check.id} stopped: minRadius (R={term_data_stop_check.radius:.4f})")
            if not term_data_stop_check.stop_growth and term_data_stop_check.original_measured_radius is not None:
                stop_radius_factor_measured = config_manager.get_param(config, "gbo_growth.stop_criteria.radius_match_factor_measured", 0.95)
                target_stop_radius = term_data_stop_check.original_measured_radius * np.clip(stop_radius_factor_measured, 0.1, 2.0)
                logger.debug(f"Stop check for {term_data_stop_check.id}: Current R={term_data_stop_check.radius:.4f}, OriginalLimitR={term_data_stop_check.original_measured_radius:.4f}, TargetStopR={target_stop_radius:.4f} (Factor: {stop_radius_factor_measured:.2f})")
                if term_data_stop_check.radius >= target_stop_radius:
                    term_data_stop_check.stop_growth = True
                    parent_identifier = term_data_stop_check.parent_measured_terminal_id if term_data_stop_check.parent_measured_terminal_id else "ConfigSeed"
                    logger.info(f"Terminal {term_data_stop_check.id} (derived from {parent_identifier}) stopped: GBO R {term_data_stop_check.radius:.4f} >= target {target_stop_radius:.4f}.")
            if not term_data_stop_check.stop_growth and (not term_data_stop_check.current_territory_voxel_indices_flat and term_data_stop_check.current_territory_demand < constants.EPSILON):
                term_data_stop_check.stop_growth = True
                logger.info(f"Terminal {term_data_stop_check.id} stopped: no territory/demand.")
            if gbo_graph.has_node(term_data_stop_check.id): gbo_graph.nodes[term_data_stop_check.id]['stop_growth'] = term_data_stop_check.stop_growth
            if not term_data_stop_check.stop_growth: active_terminals_still_growing += 1
        logger.info(f"End of GBO iteration {current_iteration_num}: {active_terminals_still_growing} GBO terminals still active.")

        stop_due_to_target_perfusion = False
        if total_voxels_in_domain > 0: stop_due_to_target_perfusion = (np.sum(perfused_tissue_mask) >= total_voxels_in_domain * config_manager.get_param(config, "gbo_growth.target_domain_perfusion_fraction", 0.99))
        stop_due_to_no_active_terminals = (active_terminals_still_growing == 0 and iteration > 0) 
        stop_due_to_no_new_growth = (num_newly_perfused_this_iter == 0 and iteration >= min_iters_no_growth_stop)

        if config_manager.get_param(config, "visualization.save_intermediate_steps", False):
            interval = config_manager.get_param(config, "visualization.intermediate_step_interval", 1)
            if (current_iteration_num % interval == 0) or (iteration == max_iterations - 1) or stop_due_to_no_new_growth or stop_due_to_target_perfusion or stop_due_to_no_active_terminals:
                logger.info(f"Saving intermediate GBO results for iteration {current_iteration_num}...")
                io_utils.save_vascular_tree_vtp(gbo_graph, os.path.join(output_dir, f"gbo_graph_iter_{current_iteration_num}.vtp"))
                if np.any(perfused_tissue_mask): io_utils.save_nifti_image(perfused_tissue_mask.astype(np.uint8), tissue_data['affine'], os.path.join(output_dir, f"gbo_perfused_mask_iter_{current_iteration_num}.nii.gz"))
        
        if blender_snapshot_interval > 0 and (current_iteration_num % blender_snapshot_interval == 0 or iteration == max_iterations -1):
            logger.info(f"--- SAVING SNAPSHOT FOR BLENDER (Iteration {current_iteration_num}) ---")
            snapshot_dir = os.path.join(output_dir, f"blender_snapshot_iter_{current_iteration_num}"); os.makedirs(snapshot_dir, exist_ok=True)
            io_utils.save_vascular_tree_vtp(gbo_graph, os.path.join(snapshot_dir, f"vascular_tree_iter_{current_iteration_num}.vtp"))
            affine_matrix = tissue_data.get('affine')
            if affine_matrix is not None:
                if np.any(perfused_tissue_mask):
                    try: io_utils.save_nifti_image(perfused_tissue_mask.astype(np.uint8), affine_matrix, os.path.join(snapshot_dir, f"perfused_mask_iter_{current_iteration_num}.nii.gz"))
                    except Exception as e_save_snap: logger.error(f"Error saving snapshot perfused_mask: {e_save_snap}")
                else: logger.debug(f"Snapshot: Perfused mask is empty, not saving.")
                save_domain_with_each_snapshot = config_manager.get_param(config, "visualization.save_domain_with_each_blender_snapshot", False)
                if current_iteration_num == blender_snapshot_interval or save_domain_with_each_snapshot or iteration == max_iterations -1:
                    domain_for_context = tissue_data.get('gbo_growth_domain_mask', tissue_data.get('anatomical_domain_mask'))
                    if domain_for_context is not None and np.any(domain_for_context):
                        try: io_utils.save_nifti_image( domain_for_context.astype(np.uint8), affine_matrix, os.path.join(snapshot_dir, f"overall_domain_context_iter_{current_iteration_num}.nii.gz"))
                        except Exception as e_save_snap_dom: logger.error(f"Error saving snapshot overall_domain_context: {e_save_snap_dom}")
            else: logger.error("Snapshot: Affine matrix missing in tissue_data. Cannot save NIfTI masks for Blender.")
            logger.info(f"--- BLENDER SNAPSHOT SAVED to {snapshot_dir} ---")

        if stop_due_to_target_perfusion: logger.info(f"GBO Stopping after iter {current_iteration_num}: Target perfusion reached."); break
        if stop_due_to_no_active_terminals: logger.info(f"GBO Stopping after iter {current_iteration_num}: No active GBO terminals."); break
        if stop_due_to_no_new_growth: logger.info(f"GBO Stopping after iter {current_iteration_num}: No new growth."); break
            
    logger.info(f"GBO healthy vascular growth finished. Final GBO tree component(s) added to graph. Total graph: {gbo_graph.number_of_nodes()} nodes, {gbo_graph.number_of_edges()} edges.")
    return gbo_graph
--- File: ./constants.py ---
# src/constants.py
import numpy as np

# Physical Constants
PI = np.pi
# Blood viscosity (e.g., in Pa.s). Typical human blood viscosity is 3-4 cP (0.003-0.004 Pa.s).
# Ensure consistency with pressure (Pa) and length (m or mm) units.
# If length in mm, pressure in Pa, Q in mm^3/s, then viscosity in Pa.s.
# Example: 0.0035 Pa.s
DEFAULT_BLOOD_VISCOSITY = 3.5e-3  # Pa.s

# Default metabolic rates
# These are example values. Units should be carefully considered for flow calculation.
# Let's assume units of: ml_blood / s / ml_tissue (volume flow rate per unit volume of tissue)
# Conversion from common literature values (e.g., ml_blood / min / 100g_tissue):
# Assume tissue density ~ 1 g/ml. So 100g_tissue ~ 100ml_tissue.
# Example: GM 60 ml/min/100g = 60 ml/min/100ml = 1 ml/min/ml_tissue = (1/60) ml/s/ml_tissue ~= 0.0167 s^-1
Q_MET_GM_PER_ML = 0.0167  # 1/s (equivalent to ml_blood / s / ml_tissue)
Q_MET_WM_PER_ML = 0.0056  # 1/s (approx 20-25 ml/min/100g)
Q_MET_TUMOR_RIM_PER_ML = 0.0334 # 1/s (e.g., 2x GM)
Q_MET_TUMOR_CORE_PER_ML = 0.0083 # 1/s (can be lower due to necrosis)
Q_MET_CSF_PER_ML = 0.0 # No metabolic demand for CSF

# GBO Parameters
MURRAY_LAW_EXPONENT = 3.0 # For r_parent^gamma = sum(r_child_i^gamma)
# C_met for metabolic maintenance cost: E_metabolic = C_met * PI * r^2 * L
# Units must be consistent with E_flow. E_flow is in Joules if Q is m^3/s, P in Pa, L in m, r in m.
# E_flow = (Pressure_drop * Q) * time_implicit = ( (8 * mu * L * Q) / (PI * r^4) ) * Q
# So E_flow has units of Power (Energy/time). For the sum, it's more like total power dissipation.
# E_metabolic should also be in units of Power.
# C_met * PI * r^2 * L => C_met units = Power / Length^3 = Power / Volume
# (e.g., W/m^3). This represents volumetric metabolic power density of vessel wall.
DEFAULT_C_MET_VESSEL_WALL = 1.0e5 # W/m^3 (Placeholder value, needs calibration from literature)

# Initial small flow for new terminals to seed Voronoi calculation (e.g., mm^3/s or m^3/s)
# Must be > 0. Let's use mm^3/s if coordinates are in mm.
INITIAL_TERMINAL_FLOW_Q = 1e-6 # mm^3/s (if using mm)

# Perfusion Model Parameters
# Tissue permeability K (e.g., in mm^2 or m^2). This is for Darcy's Law: v = -(K/mu) * grad(P)
# For brain tissue, K is very low. Values can range from 10^-12 to 10^-18 m^2.
# Let's use mm, so if K is in mm^2:
DEFAULT_TISSUE_PERMEABILITY_GM = 1e-7 # mm^2 (Placeholder, highly dependent on tissue type)
DEFAULT_TISSUE_PERMEABILITY_WM = 5e-8  # mm^2 (Placeholder)
# Coupling coefficient beta for Q_terminal = beta * (P_vessel_terminal - P_tissue_at_terminal)
# Units: (mm^3/s) / Pa if P is in Pa and Q in mm^3/s.
DEFAULT_COUPLING_BETA = 1e-7 # mm^3 / (s * Pa) (Placeholder)

# Simulation control
DEFAULT_VOXEL_SIZE_MM = 1.0 # Default isotropic voxel size in mm, if not from NIfTI

# Small epsilon for numerical stability
EPSILON = 1e-9


MIN_VESSEL_RADIUS_MM = 0.005 # example, 5 microns in mm
INITIAL_TERMINAL_FLOW_Q = 1e-6 # mm^3/s
--- File: ./energy_model.py ---
# src/energy_model.py
import numpy as np
import networkx as nx # Not directly used in functions yet, but good for context if needed later
import logging
from typing import Tuple, List, Optional # For type hinting

# Attempt to import sklearn for KMeans, but make it optional
try:
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    KMeans = None # Placeholder if not available

from src import constants, config_manager, utils

logger = logging.getLogger(__name__)

def calculate_segment_flow_energy(length: float, radius: float, flow: float, viscosity: float) -> float:
    """ 
    Calculates viscous energy dissipation (power) for a vessel segment.
    E_flow = (8 * mu * L * Q^2) / (pi * r^4) 
    Units: If mu (Pa.s), L (m), Q (m^3/s), r (m), then E_flow is in Watts (J/s).
           If mu (Pa.s), L (mm), Q (mm^3/s), r (mm):
           Pa.s * mm * (mm^3/s)^2 / mm^4 = (N/m^2).s * (1e-3 m) * (1e-9 m^3/s)^2 / (1e-12 m^4)
                                       = N.s/m^2 * 1e-3 m * 1e-18 m^6/s^2 / 1e-12 m^4
                                       = 1e-9 N.m/s = 1e-9 W.
           To get milliWatts (mW), multiply by 1000: 1e-6 mW.
           Users must ensure consistency or apply conversion factors.
    """
    if radius < constants.EPSILON: # Avoid division by zero
        # If there's flow through a zero-radius vessel, cost is infinite
        return np.inf if abs(flow) > constants.EPSILON else 0.0
    if abs(flow) < constants.EPSILON: # If flow is effectively zero, energy dissipation is zero
        return 0.0
    
    # For extremely small radii with non-zero flow, energy can become excessively large.
    # This is physically plausible (high resistance) but can cause numerical issues.
    if radius < 1e-7 and abs(flow) > constants.EPSILON: # e.g., radius < 0.1 micron
        logger.debug(f"Very small radius ({radius:.2e}) with non-zero flow ({flow:.2e}). Flow energy may be extreme.")

    return (8.0 * viscosity * length * (flow**2)) / (constants.PI * (radius**4))

def calculate_segment_metabolic_energy(length: float, radius: float, c_met_coeff: float) -> float:
    """ 
    Calculates metabolic maintenance cost (power) for a vessel segment.
    E_metabolic = C_met_coeff * pi * r^2 * L 
    Units: If C_met_coeff (W/m^3), r (m), L (m), then E_metabolic is in Watts.
           If C_met_coeff (mW/mm^3), r (mm), L (mm), then E_metabolic is in milliWatts.
           The config value for c_met_coeff should be in units consistent with E_flow.
    """
    if radius < constants.EPSILON or length < constants.EPSILON:
        return 0.0
    return c_met_coeff * constants.PI * (radius**2) * length

def calculate_bifurcation_loss(
    parent_pos: np.ndarray, # Position of the bifurcation point itself
    child1_pos: np.ndarray, child1_radius: float, child1_flow: float,
    child2_pos: np.ndarray, child2_radius: float, child2_flow: float,
    config: dict
) -> float:
    """
    Calculates the total loss (E_flow + E_metabolic) for the two new child segments
    originating from parent_pos. The flows are specific to these new child segments.
    """
    viscosity = config_manager.get_param(config, "vascular_properties.blood_viscosity", constants.DEFAULT_BLOOD_VISCOSITY)
    c_met = config_manager.get_param(config, "gbo_growth.energy_coefficient_C_met_vessel_wall", constants.DEFAULT_C_MET_VESSEL_WALL)

    l_c1 = utils.distance(parent_pos, child1_pos)
    l_c2 = utils.distance(parent_pos, child2_pos)

    # Calculate energy for child 1 segment
    if l_c1 < constants.EPSILON or child1_radius < constants.EPSILON:
        e_flow_c1 = np.inf if abs(child1_flow) > constants.EPSILON else 0.0
        e_met_c1 = 0.0
    else:
        e_flow_c1 = calculate_segment_flow_energy(l_c1, child1_radius, child1_flow, viscosity)
        e_met_c1 = calculate_segment_metabolic_energy(l_c1, child1_radius, c_met)

    # Calculate energy for child 2 segment
    if l_c2 < constants.EPSILON or child2_radius < constants.EPSILON:
        e_flow_c2 = np.inf if abs(child2_flow) > constants.EPSILON else 0.0
        e_met_c2 = 0.0
    else:
        e_flow_c2 = calculate_segment_flow_energy(l_c2, child2_radius, child2_flow, viscosity)
        e_met_c2 = calculate_segment_metabolic_energy(l_c2, child2_radius, c_met)
    
    total_loss = e_flow_c1 + e_met_c1 + e_flow_c2 + e_met_c2
    
    # logger.debug(f"Bifurcation candidate: L1={l_c1:.2f}, R1={child1_radius:.4f}, Q1={child1_flow:.2e} -> E_f1={e_flow_c1:.2e}, E_m1={e_met_c1:.2e}")
    # logger.debug(f"                     L2={l_c2:.2f}, R2={child2_radius:.4f}, Q2={child2_flow:.2e} -> E_f2={e_flow_c2:.2e}, E_m2={e_met_c2:.2e}")
    # logger.debug(f"                     Total Loss = {total_loss:.3e}")
    return total_loss



def find_optimal_bifurcation_for_combined_territory(
    parent_terminal_gbo_data: object, # GBOIterationData for the terminal that will bifurcate
    # Combined territory: parent's old territory + new frontier region
    combined_territory_voxel_indices_flat: np.ndarray, 
    tissue_data: dict,
    config: dict,
    k_murray_factor: float,
    murray_exponent: float
) -> Optional[Tuple[np.ndarray, float, float, np.ndarray, float, float, float]]:
    """
    Searches for an optimal bifurcation for the parent_terminal to supply a 
    COMBINED territory (its old territory + a new growth region).
    The children C1 and C2 will share the total demand of this combined_territory.
    
    Args:
        parent_terminal_gbo_data: GBOIterationData of the branching terminal.
        combined_territory_voxel_indices_flat: Flat indices of ALL voxels 
                                               (old territory + new frontier) to be supplied.
        tissue_data: Full tissue data dict.
        config: Simulation config.
        k_murray_factor, murray_exponent: For radius calculation.

    Returns:
        Tuple (child1_pos, child1_radius, child1_total_flow, 
               child2_pos, child2_radius, child2_total_flow, min_loss_for_new_segments) 
        or None if no suitable bifurcation found.
        The child flows are their respective total target flows.
    """
    parent_id = parent_terminal_gbo_data.id
    parent_pos = parent_terminal_gbo_data.pos # This is the bifurcation point
    logger.debug(f"Finding optimal bifurcation for {parent_id} at {np.round(parent_pos,3)} to supply combined "
                 f"territory of {len(combined_territory_voxel_indices_flat)} voxels.")

    if len(combined_territory_voxel_indices_flat) == 0:
        logger.debug(f"Terminal {parent_id}: Combined target territory is empty. No bifurcation.")
        return None

    # Get world coordinates and demand for ALL voxels in the combined territory
    combined_voxels_world_coords = tissue_data['world_coords_flat'][combined_territory_voxel_indices_flat]
    
    demand_map_3d_indices = tissue_data['voxel_indices_flat'][combined_territory_voxel_indices_flat]
    demand_per_combined_voxel_qmet = tissue_data['metabolic_demand_map'][
        demand_map_3d_indices[:,0],
        demand_map_3d_indices[:,1],
        demand_map_3d_indices[:,2]
    ]
    demand_of_combined_voxels_flow = demand_per_combined_voxel_qmet * tissue_data['voxel_volume']
    total_demand_of_combined_territory = np.sum(demand_of_combined_voxels_flow)

    if total_demand_of_combined_territory < constants.EPSILON:
        logger.debug(f"Terminal {parent_id}: Total demand in combined territory is negligible. No bifurcation.")
        return None

    num_candidate_location_sets = config_manager.get_param(config, "gbo_growth.bifurcation_candidate_points", 10)
    min_seg_len = config_manager.get_param(config, "vascular_properties.min_segment_length", 0.1)
    min_radius = config_manager.get_param(config, "vascular_properties.min_radius", constants.MIN_VESSEL_RADIUS_MM)

    best_bifurcation_params = None
    min_loss_found = np.inf

    if len(combined_voxels_world_coords) < 2:
        logger.debug(f"Terminal {parent_id}: Combined territory too small ({len(combined_voxels_world_coords)} voxels) "
                     "for meaningful bifurcation. Consider extension.")
        return None # Bifurcation needs to split demand between two children

    # Candidate child locations should be within or near the combined_territory
    # (KMeans or random sampling on combined_voxels_world_coords)
    for i in range(num_candidate_location_sets):
        c1_pos_candidate, c2_pos_candidate = None, None
        # --- 1. Generate candidate child locations (c1_pos, c2_pos) based on combined_territory ---
        # (Using KMeans as before, but on combined_voxels_world_coords)
        if SKLEARN_AVAILABLE and KMeans is not None:
            try:
                n_clust = min(2, len(combined_voxels_world_coords))
                if n_clust < 2: # Should be caught by len(combined_voxels_world_coords) < 2 above
                    continue 
                kmeans = KMeans(n_clusters=n_clust, random_state=i, n_init='auto').fit(combined_voxels_world_coords)
                c1_pos_candidate = kmeans.cluster_centers_[0]
                c2_pos_candidate = kmeans.cluster_centers_[1]
            except Exception as e_km:
                logger.warning(f"KMeans failed for combined territory (iter {i}): {e_km}. Fallback.")
                indices = np.random.choice(len(combined_voxels_world_coords), 2, replace=False)
                c1_pos_candidate = combined_voxels_world_coords[indices[0]]
                c2_pos_candidate = combined_voxels_world_coords[indices[1]]
        else:
            if i == 0 and not SKLEARN_AVAILABLE : logger.warning("Sklearn KMeans not available for child placement.")
            indices = np.random.choice(len(combined_voxels_world_coords), 2, replace=False)
            c1_pos_candidate = combined_voxels_world_coords[indices[0]]
            c2_pos_candidate = combined_voxels_world_coords[indices[1]]

        if utils.distance(parent_pos, c1_pos_candidate) < min_seg_len or \
           utils.distance(parent_pos, c2_pos_candidate) < min_seg_len or \
           utils.distance(c1_pos_candidate, c2_pos_candidate) < min_seg_len:
            continue

        # --- 2. Assign ALL voxels in combined_territory to c1 or c2 ---
        # This determines Q_C1_total and Q_C2_total for the candidate children.
        q_c1_total_candidate = 0.0
        q_c2_total_candidate = 0.0
        
        for idx_in_combined, voxel_wc in enumerate(combined_voxels_world_coords):
            dist_sq_to_c1 = utils.distance_squared(voxel_wc, c1_pos_candidate)
            dist_sq_to_c2 = utils.distance_squared(voxel_wc, c2_pos_candidate)
            if dist_sq_to_c1 <= dist_sq_to_c2:
                q_c1_total_candidate += demand_of_combined_voxels_flow[idx_in_combined]
            else:
                q_c2_total_candidate += demand_of_combined_voxels_flow[idx_in_combined]
        
        if q_c1_total_candidate < constants.EPSILON or q_c2_total_candidate < constants.EPSILON:
            # This means one child would get (almost) no flow from the entire combined territory.
            # This might be a poor bifurcation unless the other child takes nearly all.
            # Forcing both to have substantial flow might be too restrictive.
            # Let it proceed if total demand is met.
            if abs(q_c1_total_candidate + q_c2_total_candidate - total_demand_of_combined_territory) > constants.EPSILON * total_demand_of_combined_territory:
                 logger.warning(f"Demand conservation issue in child assignment: sum_child_Q={q_c1_total_candidate+q_c2_total_candidate:.2e}, total_demand={total_demand_of_combined_territory:.2e}")
                 continue # Skip if total demand not conserved by split

        # --- 3. Calculate radii for c1, c2 based on their TOTAL flows ---
        r_c1_candidate = k_murray_factor * (q_c1_total_candidate ** (1.0 / murray_exponent)) if q_c1_total_candidate > constants.EPSILON else min_radius
        r_c2_candidate = k_murray_factor * (q_c2_total_candidate ** (1.0 / murray_exponent)) if q_c2_total_candidate > constants.EPSILON else min_radius
        r_c1_candidate = max(min_radius, r_c1_candidate)
        r_c2_candidate = max(min_radius, r_c2_candidate)

        # --- 4. Calculate loss for this candidate bifurcation (for the two new child segments) ---
        # Flows used here are q_c1_total_candidate and q_c2_total_candidate
        current_loss = calculate_bifurcation_loss(
            parent_pos, # Bifurcation point
            c1_pos_candidate, r_c1_candidate, q_c1_total_candidate,
            c2_pos_candidate, r_c2_candidate, q_c2_total_candidate,
            config
        )

        if current_loss < min_loss_found:
            min_loss_found = current_loss
            best_bifurcation_params = (c1_pos_candidate.copy(), r_c1_candidate, q_c1_total_candidate,
                                       c2_pos_candidate.copy(), r_c2_candidate, q_c2_total_candidate,
                                       min_loss_found)

    if best_bifurcation_params:
        logger.info(f"Optimal bifurcation for {parent_id} (supplying combined territory) chosen (Loss {best_bifurcation_params[6]:.3e}): "
                    f"C1 (R={best_bifurcation_params[1]:.4f}, Q_total={best_bifurcation_params[2]:.2e}), "
                    f"C2 (R={best_bifurcation_params[4]:.4f}, Q_total={best_bifurcation_params[5]:.2e})")
        return best_bifurcation_params
    else:
        logger.debug(f"No suitable bifurcation found for terminal {parent_id} to supply combined territory.")
        return None

# The __main__ test block in energy_model.py would need to be updated to call this new function
# and provide mock data for a "combined_territory".


def find_optimal_bifurcation_for_new_region(
    parent_terminal_gbo_data: object, 
    new_growth_region_voxel_indices_flat: np.ndarray, 
    tissue_data: dict,
    config: dict,
    k_murray_factor: float,
    murray_exponent: float
) -> Optional[Tuple[np.ndarray, float, float, np.ndarray, float, float, float]]:
    """
    Searches for an optimal bifurcation for the parent_terminal to supply a *new growth region (Ri,p)*.
    (Full implementation as previously provided)
    """
    parent_id = parent_terminal_gbo_data.id
    parent_pos = parent_terminal_gbo_data.pos
    logger.debug(f"Finding optimal bifurcation for terminal {parent_id} at {parent_pos} to supply a new "
                 f"growth region of {len(new_growth_region_voxel_indices_flat)} voxels.")

    if len(new_growth_region_voxel_indices_flat) == 0:
        logger.debug(f"Terminal {parent_id}: New growth region is empty. No bifurcation.")
        return None

    new_growth_voxels_world_coords = tissue_data['world_coords_flat'][new_growth_region_voxel_indices_flat]
    
    demand_map_3d_indices = tissue_data['voxel_indices_flat'][new_growth_region_voxel_indices_flat]
    demand_per_new_growth_voxel = tissue_data['metabolic_demand_map'][
        demand_map_3d_indices[:,0],
        demand_map_3d_indices[:,1],
        demand_map_3d_indices[:,2]
    ] # This is q_met per voxel, not q_met * dV yet
    
    # Multiply by voxel volume to get demand (flow rate)
    demand_of_new_growth_voxels = demand_per_new_growth_voxel * tissue_data['voxel_volume']
    total_demand_of_new_region = np.sum(demand_of_new_growth_voxels)

    if total_demand_of_new_region < constants.EPSILON:
        logger.debug(f"Terminal {parent_id}: Total demand in the new growth region is negligible. No bifurcation.")
        return None

    num_candidate_location_sets = config_manager.get_param(config, "gbo_growth.bifurcation_candidate_points", 10)
    min_seg_len = config_manager.get_param(config, "vascular_properties.min_segment_length", 0.1)
    min_radius = config_manager.get_param(config, "vascular_properties.min_radius", constants.MIN_VESSEL_RADIUS_MM)

    best_bifurcation_params = None
    min_loss_found = np.inf

    if len(new_growth_voxels_world_coords) < 2 and len(new_growth_voxels_world_coords) > 0: # Handle single voxel new region
         logger.debug(f"New growth region for {parent_id} has only {len(new_growth_voxels_world_coords)} voxel(s). Treating as extension.")
         # This case should ideally be handled by "extension" logic in vascular_growth.py
         # For now, find_optimal_bifurcation will attempt to make one child supply it.
    elif len(new_growth_voxels_world_coords) == 0: # Should be caught earlier
        return None


    for i in range(num_candidate_location_sets):
        c1_pos_candidate, c2_pos_candidate = None, None
        if len(new_growth_voxels_world_coords) >= 2:
            if SKLEARN_AVAILABLE and KMeans is not None:
                try:
                    # Ensure n_clusters is not more than n_samples
                    n_clust = min(2, len(new_growth_voxels_world_coords))
                    if n_clust < 2 : # Not enough for two distinct clusters
                        idx = np.random.choice(len(new_growth_voxels_world_coords), 1)[0]
                        c1_pos_candidate = new_growth_voxels_world_coords[idx]
                        # Create a dummy c2 for calculation, it will get ~0 flow from new region
                        c2_pos_candidate = c1_pos_candidate + utils.normalize_vector(np.random.rand(3)-0.5) * min_seg_len
                    else:
                        kmeans = KMeans(n_clusters=n_clust, random_state=i, n_init='auto').fit(new_growth_voxels_world_coords)
                        c1_pos_candidate = kmeans.cluster_centers_[0]
                        c2_pos_candidate = kmeans.cluster_centers_[1] if n_clust == 2 else kmeans.cluster_centers_[0] + utils.normalize_vector(np.random.rand(3)-0.5) * min_seg_len

                except Exception as e_km: # Catch any Kmeans error
                    logger.warning(f"KMeans clustering failed for bifurcation candidates (iter {i}): {e_km}. Falling back to random points.")
                    # Fallback to random points from the new growth region
                    indices = np.random.choice(len(new_growth_voxels_world_coords), 2, replace=len(new_growth_voxels_world_coords) < 2)
                    c1_pos_candidate = new_growth_voxels_world_coords[indices[0]]
                    c2_pos_candidate = new_growth_voxels_world_coords[indices[1]]

            else: # SKLEARN_AVAILABLE is False or KMeans is None (ImportError)
                if i == 0 : logger.warning("Scikit-learn not found. Using random points for bifurcation candidates.")
                indices = np.random.choice(len(new_growth_voxels_world_coords), 2, replace=len(new_growth_voxels_world_coords) < 2)
                c1_pos_candidate = new_growth_voxels_world_coords[indices[0]]
                c2_pos_candidate = new_growth_voxels_world_coords[indices[1]]
        
        elif len(new_growth_voxels_world_coords) == 1:
            c1_pos_candidate = new_growth_voxels_world_coords[0]
            c2_pos_candidate = c1_pos_candidate + utils.normalize_vector(np.random.rand(3)-0.5) * min_seg_len # Dummy c2

        if c1_pos_candidate is None or c2_pos_candidate is None : continue # Should not happen with fallbacks

        if utils.distance(parent_pos, c1_pos_candidate) < min_seg_len or \
           utils.distance(parent_pos, c2_pos_candidate) < min_seg_len or \
           (utils.distance(c1_pos_candidate, c2_pos_candidate) < min_seg_len and not np.allclose(c1_pos_candidate, c2_pos_candidate)):
            continue

        q_c1_candidate_from_new = 0.0
        q_c2_candidate_from_new = 0.0
        
        for idx_in_new_region, voxel_wc in enumerate(new_growth_voxels_world_coords):
            dist_sq_to_c1 = utils.distance_squared(voxel_wc, c1_pos_candidate)
            dist_sq_to_c2 = utils.distance_squared(voxel_wc, c2_pos_candidate)
            if dist_sq_to_c1 <= dist_sq_to_c2:
                q_c1_candidate_from_new += demand_of_new_growth_voxels[idx_in_new_region]
            else:
                q_c2_candidate_from_new += demand_of_new_growth_voxels[idx_in_new_region]
        
        # Ensure flow is not split into practically zero for both if there's demand
        if (q_c1_candidate_from_new < constants.EPSILON and q_c2_candidate_from_new < constants.EPSILON and total_demand_of_new_region > constants.EPSILON):
            # This might happen if c1_pos and c2_pos are poorly chosen relative to demand distribution.
            # For example, if both are far from all demand points.
            # Or if total_demand_of_new_region is tiny.
            # logger.debug(f"Candidate pair {i} results in zero flow for both children from new region. Skipping.")
            continue

        r_c1_candidate = k_murray_factor * (q_c1_candidate_from_new ** (1.0 / murray_exponent)) if q_c1_candidate_from_new > constants.EPSILON else min_radius
        r_c2_candidate = k_murray_factor * (q_c2_candidate_from_new ** (1.0 / murray_exponent)) if q_c2_candidate_from_new > constants.EPSILON else min_radius
        r_c1_candidate = max(min_radius, r_c1_candidate)
        r_c2_candidate = max(min_radius, r_c2_candidate)

        current_loss = calculate_bifurcation_loss(
            parent_pos,
            c1_pos_candidate, r_c1_candidate, q_c1_candidate_from_new,
            c2_pos_candidate, r_c2_candidate, q_c2_candidate_from_new,
            config
        )

        if current_loss < min_loss_found:
            min_loss_found = current_loss
            best_bifurcation_params = (c1_pos_candidate.copy(), r_c1_candidate, q_c1_candidate_from_new,
                                       c2_pos_candidate.copy(), r_c2_candidate, q_c2_candidate_from_new,
                                       min_loss_found)

    if best_bifurcation_params:
        logger.info(f"Optimal bifurcation for {parent_id} to supply new region chosen (Loss {best_bifurcation_params[6]:.3e}): "
                    f"C1 (R={best_bifurcation_params[1]:.4f}, Q_new={best_bifurcation_params[2]:.2e}), "
                    f"C2 (R={best_bifurcation_params[4]:.4f}, Q_new={best_bifurcation_params[5]:.2e})")
        return best_bifurcation_params
    else:
        logger.debug(f"No suitable (lower loss or valid) bifurcation found for terminal {parent_id} to supply new region.")
        return None

if __name__ == '__main__':
    logging.basicConfig(level=logging.DEBUG) # Changed to DEBUG for more verbose test output
    
    # Mock config
    test_config = {
        "vascular_properties": {
            "blood_viscosity": 0.0035, 
            "min_segment_length": 0.01, 
            "min_radius": 0.005, 
            "k_murray_scaling_factor": 0.5, 
            "murray_law_exponent": 3.0
        },
        "gbo_growth": {
            # C_met unit: e.g. mW/mm^3 (if E_flow target unit is mW)
            # If E_flow from calculate_segment_flow_energy is in 10^-9 W (nanoWatts) when inputs are mm, Pa.s, mm^3/s
            # And we want E_met to be in same units: C_met * mm^2 * mm = C_met * mm^3
            # So C_met should be in (10^-9 W) / mm^3.
            # If paper uses C_met for W/m^3, and we use mm:
            # C_met_paper (W/m^3) * (1m/1000mm)^3 = C_met_paper * 1e-9 (W/mm^3)
            # Let's use a value that makes E_met somewhat comparable to E_flow for typical values.
            # Example from before: L=1, R=0.1, Q=0.01 -> E_flow ~ 1.1e-7 (in 10^-9 W units, so 1.1e-16 W actual)
            # E_met = C_met * pi * (0.1)^2 * 1. If C_met = 1e-5 (in 10^-9W/mm^3 units), E_met ~ 3e-7.
            "energy_coefficient_C_met_vessel_wall": 1.0e-5, # (Units: 10^-9 W / mm^3 or equivalent)
            "bifurcation_candidate_points": 50, # Increased for better testing
        }
    }
    
    # Ensure constants are properly defined or mocked for standalone execution
    class MockConstants:
        PI = np.pi
        EPSILON = 1e-10 # Slightly smaller epsilon
        DEFAULT_BLOOD_VISCOSITY = 0.0035
        # This default C_MET_VESSEL_WALL in constants.py is likely in W/m^3.
        # The config value above is what's used by the functions.
        DEFAULT_C_MET_VESSEL_WALL = 1.0e5 
        MIN_VESSEL_RADIUS_MM = 0.005
    
    # Overwrite constants only if they are not the actual imported ones (e.g. running file directly)
    if 'constants' not in globals() or not hasattr(constants, 'MIN_VESSEL_RADIUS_MM'):
        constants = MockConstants()
        print("Using MockConstants for standalone test.")


    # Test calculate_segment_flow_energy
    # Using L (mm), R (mm), Q (mm^3/s), mu (Pa.s)
    # Expected output units: 10^-9 W (nanoWatts) or Pa.mm^3/s
    l, r_test, q_test, mu_test = 1.0, 0.1, 0.01, test_config["vascular_properties"]["blood_viscosity"]
    e_flow = calculate_segment_flow_energy(l, r_test, q_test, mu_test)
    
    # c_met_val from config is assumed to be in (10^-9 W)/mm^3 to match E_flow units
    c_met_val = test_config["gbo_growth"]["energy_coefficient_C_met_vessel_wall"] 
    e_met = calculate_segment_metabolic_energy(l, r_test, c_met_val)
    logger.info(f"Test segment: L={l}mm, R={r_test}mm, Q={q_test}mm^3/s, mu={mu_test}Pa.s")
    logger.info(f"Calculated E_flow = {e_flow:.3e} (expected units: Pa.mm^3/s or 10^-9 W)")
    logger.info(f"Calculated E_met (with C_met={c_met_val:.1e}) = {e_met:.3e} (expected units: same as E_flow)")
    # Expected E_flow = (8 * 0.0035 * 1 * 0.01^2) / (pi * 0.1^4) = (2.8e-6) / (pi * 1e-4) approx 2.8e-6 / 3.14e-4 = 0.0089 Pa.mm^3/s
    # My previous manual calc was off. Let's recheck:
    # (8 * 0.0035 * 1.0 * (0.01**2)) / (np.pi * (0.1**4)) = 0.008912676...
    # E_met = 1e-5 * np.pi * (0.1**2) * 1.0 = 3.14159e-7
    # These values seem reasonable relative to each other if C_met is chosen appropriately.

    # Mock parent terminal for find_optimal_bifurcation_for_new_region
    class MockGBOIterationData: # Simplified for this test
        def __init__(self, id, pos, radius, flow): # Removed territory_demand as it's not used by this func
            self.id = id
            self.pos = np.array(pos)
            self.radius = radius
            self.flow = flow # This is flow to *existing* territory, not used by find_optimal_bifurcation_for_new_region

    parent_term = MockGBOIterationData(
        id="p_test_0", 
        pos=np.array([0.,0.,0.]), 
        radius=0.2, 
        flow=0.00 # Flow to existing territory, not directly used for optimizing *new* region supply
    )

    # Mock tissue_data for the new growth region
    num_new_growth_voxels = 50
    # These are flat indices relative to the global tissue_data arrays
    # For the test, let's assume these are the first 'num_new_growth_voxels' in a hypothetical global list
    mock_new_growth_indices_flat = np.arange(num_new_growth_voxels) 
    
    # World coords for these specific new growth voxels
    # Place them in a cluster, e.g., around [1,1,0]
    mock_new_growth_world_coords = np.random.rand(num_new_growth_voxels, 3) * 0.5 + np.array([1.0, 1.0, 0.0])
    
    # For tissue_data, we need the *full* set of domain voxels
    # For this test, we can make tissue_data['world_coords_flat'] just be these new growth voxels
    # And correspondingly for voxel_indices_flat and metabolic_demand_map
    
    mock_tissue_voxel_indices_3d = np.zeros((num_new_growth_voxels, 3), dtype=int)
    for i in range(num_new_growth_voxels): # Dummy 3D indices
        mock_tissue_voxel_indices_3d[i] = [i // 10, i % 10, 0] 

    # Demand for these new growth voxels (q_met, not q_met * dV yet)
    mock_demand_q_met_for_new_voxels = np.random.uniform(low=0.01, high=0.02, size=num_new_growth_voxels) # 1/s (q_met)
    
    # Assume a voxel volume for calculating total demand from q_met
    mock_voxel_vol = 0.001 # mm^3 (e.g., 0.1mm x 0.1mm x 0.1mm)

    # Create the metabolic_demand_map (3D) that would contain these values
    # For simplicity, make it just large enough for our dummy 3D indices
    max_indices = np.max(mock_tissue_voxel_indices_3d, axis=0)
    mock_full_metabolic_demand_map_3d = np.zeros((max_indices[0]+1, max_indices[1]+1, max_indices[2]+1))
    mock_full_metabolic_demand_map_3d[mock_tissue_voxel_indices_3d[:,0],
                                      mock_tissue_voxel_indices_3d[:,1],
                                      mock_tissue_voxel_indices_3d[:,2]] = mock_demand_q_met_for_new_voxels
    
    mock_tissue_data = {
        'world_coords_flat': mock_new_growth_world_coords, # Only contains the new growth voxels for this test
        'voxel_indices_flat': mock_tissue_voxel_indices_3d, # Corresponding 3D indices
        'metabolic_demand_map': mock_full_metabolic_demand_map_3d, # Full 3D q_met map
        'voxel_volume': mock_voxel_vol
    }
    
    bifurcation_result = find_optimal_bifurcation_for_combined_territory(
        parent_term,
        mock_new_growth_indices_flat, # These are indices into the arrays in mock_tissue_data
        mock_tissue_data,
        test_config,
        k_murray_factor=test_config["vascular_properties"]["k_murray_scaling_factor"],
        murray_exponent=test_config["vascular_properties"]["murray_law_exponent"]
    )

    if bifurcation_result:
        c1p, c1r, c1q_new, c2p, c2r, c2q_new, loss = bifurcation_result
        logger.info(f"Optimal Bifurcation Found for {parent_term.id} to supply new region:")
        logger.info(f"  Child 1: Pos={np.round(c1p,3)}, Radius={c1r:.4f}, Flow_new={c1q_new:.3e}")
        logger.info(f"  Child 2: Pos={np.round(c2p,3)}, Radius={c2r:.4f}, Flow_new={c2q_new:.3e}")
        logger.info(f"  Minimized Loss (for new segments): {loss:.3e}")
        # Verify total new flow captured
        total_new_demand_calc = np.sum(mock_demand_q_met_for_new_voxels * mock_voxel_vol)
        logger.info(f"  Sum of child flows from new region: {(c1q_new + c2q_new):.3e}")
        logger.info(f"  Total demand of new region: {total_new_demand_calc:.3e}")
        assert np.isclose(c1q_new + c2q_new, total_new_demand_calc), "Child flows do not sum to total new demand"
    else:
        logger.info(f"No optimal bifurcation found for {parent_term.id} in this test.")
--- File: ./__init__.py ---

--- File: ./visualization.py ---
# src/visualization.py
from __future__ import annotations # Must be first line

import logging
import os
import numpy as np
import networkx as nx
from typing import Optional, Dict, List, Tuple
import pandas as pd

try:
    import pyvista as pv
    PYVISTA_AVAILABLE = True
except ImportError:
    PYVISTA_AVAILABLE = False
    pv = None

try:
    import matplotlib.pyplot as plt
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    plt = None

from src import io_utils, config_manager, utils, constants

logger = logging.getLogger(__name__)

# --- Plotting helper for distributions ---
def _plot_histogram(data: List[float], title: str, xlabel: str, output_path: str, bins: int = 30, density: bool = False):
    if not MATPLOTLIB_AVAILABLE:
        logger.warning(f"Matplotlib not available. Skipping histogram plot: {title}")
        return
    if not data:
        logger.warning(f"No data to plot for histogram: {title}")
        return
    valid_data = [x for x in data if np.isfinite(x)]
    if not valid_data:
        logger.warning(f"No finite data to plot for histogram (all NaN/Inf): {title}")
        return

    plt.figure(figsize=(8, 6))
    plt.hist(valid_data, bins=bins, color='skyblue', edgecolor='black', density=density)
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel("Frequency" if not density else "Density")
    plt.grid(axis='y', alpha=0.75)
    try:
        plt.savefig(output_path)
        logger.info(f"Saved histogram '{title}' to {output_path}")
    except Exception as e:
        logger.error(f"Error saving histogram '{title}' to {output_path}: {e}")
    finally:
        plt.close()

# --- Functions for Quantitative Analysis ---
def analyze_radii_distribution(graph: nx.DiGraph, output_dir: str, filename_prefix: str = "final_"):
    if graph is None or graph.number_of_nodes() == 0:
        logger.warning("Radii analysis: Graph is empty or None.")
        return
    radii = [data['radius'] for _, data in graph.nodes(data=True)
             if 'radius' in data and data.get('is_synthetic', True) and np.isfinite(data['radius'])]
    if not radii: logger.info("No synthetic nodes with valid radii found for distribution analysis."); return
    df_radii = pd.DataFrame(radii, columns=['radius_mm'])
    csv_path = os.path.join(output_dir, f"{filename_prefix}radii_data.csv")
    df_radii.to_csv(csv_path, index=False); logger.info(f"Saved raw radii data to {csv_path}")
    plot_path = os.path.join(output_dir, f"{filename_prefix}radii_distribution.png")
    _plot_histogram(radii, "Distribution of Vessel Radii (Synthetic Nodes)", "Radius (mm)", plot_path)

def analyze_segment_lengths(graph: nx.DiGraph, output_dir: str, filename_prefix: str = "final_"):
    if graph is None or graph.number_of_edges() == 0:
        logger.warning("Segment length analysis: Graph is empty or has no edges.")
        return
    lengths = []
    for u, v, data in graph.edges(data=True):
        if u in graph.nodes and v in graph.nodes and 'length' in data and \
           (graph.nodes[u].get('is_synthetic', True) or graph.nodes[v].get('is_synthetic', True)) and \
           np.isfinite(data['length']):
            lengths.append(data['length'])

    if not lengths: logger.info("No synthetic segments with valid lengths found for distribution analysis."); return
    df_lengths = pd.DataFrame(lengths, columns=['length_mm'])
    csv_path = os.path.join(output_dir, f"{filename_prefix}segment_lengths_data.csv")
    df_lengths.to_csv(csv_path, index=False); logger.info(f"Saved raw segment length data to {csv_path}")
    plot_path = os.path.join(output_dir, f"{filename_prefix}segment_lengths_distribution.png")
    _plot_histogram(lengths, "Distribution of Segment Lengths", "Length (mm)", plot_path)


def analyze_bifurcation_geometry(graph: nx.DiGraph, output_dir: str, murray_exponent: float = 3.0, filename_prefix: str = "final_"):
    if graph is None or graph.number_of_nodes() == 0:
        logger.warning("Bifurcation geometry analysis: Graph is empty or None.")
        return

    murray_parent_powers: List[float] = []
    murray_children_sum_powers: List[float] = []
    area_ratios_alpha: List[float] = []
    daughter_asymmetry_ratios: List[float] = []
    branching_angles_c1_c2: List[float] = []
    bifurcation_data_for_csv: List[Dict] = []

    logger.info(f"--- Starting Bifurcation Geometry Analysis (Murray Exp: {murray_exponent}) ---")
    bifurcation_nodes_processed = 0

    for node_id, data in graph.nodes(data=True):
        node_type = data.get('type', '')
        is_potential_bifurcation = (node_type == 'synthetic_bifurcation') or \
                                   (node_type == 'synthetic_root_terminal' and data.get('is_flow_root', False))

        if is_potential_bifurcation and graph.out_degree(node_id) == 2:
            bifurcation_nodes_processed += 1
            parent_pos = data.get('pos')
            children_ids = list(graph.successors(node_id))

            r_p_node = data.get('radius')
            q_p_node = data.get('Q_flow') 

            if len(children_ids) != 2 or \
               children_ids[0] not in graph.nodes or \
               children_ids[1] not in graph.nodes:
                logger.debug(f"Bif. Geom. Test: Node {node_id} has invalid children setup. Skipping.")
                continue

            data_c1 = graph.nodes[children_ids[0]]
            data_c2 = graph.nodes[children_ids[1]]
            child1_pos = data_c1.get('pos')
            child2_pos = data_c2.get('pos')
            r_c1_node = data_c1.get('radius')
            r_c2_node = data_c2.get('radius')
            q_c1_node = data_c1.get('Q_flow')
            q_c2_node = data_c2.get('Q_flow')

            if not (r_p_node and np.isfinite(r_p_node) and r_p_node >= constants.EPSILON and
                    r_c1_node and np.isfinite(r_c1_node) and r_c1_node >= constants.EPSILON and
                    r_c2_node and np.isfinite(r_c2_node) and r_c2_node >= constants.EPSILON):
                logger.debug(f"Bif. Geom. Test: Node {node_id} or children have invalid radii. Skipping.")
                continue

            p_power = r_p_node**murray_exponent
            c_sum_power = r_c1_node**murray_exponent + r_c2_node**murray_exponent
            murray_parent_powers.append(p_power)
            murray_children_sum_powers.append(c_sum_power)

            alpha = (r_c1_node**2 + r_c2_node**2) / (r_p_node**2)
            area_ratios_alpha.append(alpha)

            asymmetry_ratio = min(r_c1_node, r_c2_node) / max(r_c1_node, r_c2_node) if max(r_c1_node, r_c2_node) > constants.EPSILON else 1.0
            daughter_asymmetry_ratios.append(asymmetry_ratio)
            
            angle_deg_val = np.nan # Initialize for CSV
            if parent_pos is not None and child1_pos is not None and child2_pos is not None:
                vec1 = child1_pos - parent_pos
                vec2 = child2_pos - parent_pos
                norm_vec1 = np.linalg.norm(vec1)
                norm_vec2 = np.linalg.norm(vec2)
                if norm_vec1 > constants.EPSILON and norm_vec2 > constants.EPSILON:
                    cosine_angle = np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)
                    angle_rad = np.arccos(np.clip(cosine_angle, -1.0, 1.0))
                    angle_deg_val = np.degrees(angle_rad)
                    if np.isfinite(angle_deg_val):
                        branching_angles_c1_c2.append(angle_deg_val)

            bifurcation_data_for_csv.append({
                'b_id': node_id,
                f'rP^{murray_exponent:.1f}': p_power, f'sum_rC^{murray_exponent:.1f}': c_sum_power,
                'area_ratio_alpha': alpha, 'daughter_asymmetry_ratio': asymmetry_ratio,
                'angle_deg': angle_deg_val,
                'rP': r_p_node, 'rC1': r_c1_node, 'rC2': r_c2_node,
                'qP_graph': q_p_node, 'qC1_graph': q_c1_node, 'qC2_graph': q_c2_node
            })

    logger.info(f"Bifurcation Geometry Analysis: Processed {bifurcation_nodes_processed} potential bifurcation nodes.")

    if bifurcation_data_for_csv:
        df_bif_geom = pd.DataFrame(bifurcation_data_for_csv)
        csv_path = os.path.join(output_dir, f"{filename_prefix}bifurcation_geometry_data.csv")
        df_bif_geom.to_csv(csv_path, index=False)
        logger.info(f"Saved bifurcation geometry data to {csv_path}")
    else:
        logger.info("No valid bifurcation data collected for CSV. Skipping plots.")
        return

    if MATPLOTLIB_AVAILABLE and murray_parent_powers:
        plt.figure(figsize=(7, 7))
        plt.scatter(murray_children_sum_powers, murray_parent_powers, alpha=0.6, edgecolors='k', s=40, label="Bifurcations")
        max_val_plot = 0.0
        valid_parent_powers = [p for p in murray_parent_powers if np.isfinite(p)]
        valid_children_sum_powers = [c for c in murray_children_sum_powers if np.isfinite(c)]
        if valid_parent_powers and valid_children_sum_powers:
             max_val_plot = max(max(valid_parent_powers, default=0.0), max(valid_children_sum_powers, default=0.0)) * 1.1
        if max_val_plot < constants.EPSILON : max_val_plot = 1.0

        plt.plot([0, max_val_plot], [0, max_val_plot], 'r--', label=f'Ideal Murray (y=x, exp={murray_exponent:.1f})')
        plt.xlabel(f"Sum of Children Radii^{murray_exponent:.1f} (r$_1^{murray_exponent:.1f}$ + r$_2^{murray_exponent:.1f}$)")
        plt.ylabel(f"Parent Radius^{murray_exponent:.1f} (r$_0^{murray_exponent:.1f}$)")
        plt.title("Murray's Law Compliance Test")
        plt.legend()
        plt.grid(True)
        plt.xlim([0, max_val_plot]); plt.ylim([0, max_val_plot])
        plot_path = os.path.join(output_dir, f"{filename_prefix}murray_law_compliance.png")
        try: plt.savefig(plot_path); logger.info(f"Saved Murray's Law plot to {plot_path}");
        except Exception as e: logger.error(f"Error saving Murray's Law plot: {e}")
        finally: plt.close()
    else: logger.info("Skipping Murray's Law plot (Matplotlib unavailable or no data).")

    _plot_histogram(area_ratios_alpha, "Distribution of Bifurcation Area Ratios (α)", "Area Ratio α = (r₁²+r₂²)/r₀²",
                    os.path.join(output_dir, f"{filename_prefix}area_ratios_distribution.png"), bins=20)
    _plot_histogram(daughter_asymmetry_ratios, "Distribution of Daughter Radius Asymmetry Ratios", "Asymmetry Ratio min(r₁,r₂)/max(r₁,r₂)",
                    os.path.join(output_dir, f"{filename_prefix}daughter_asymmetry_distribution.png"), bins=20)
    _plot_histogram(branching_angles_c1_c2, "Distribution of Branching Angles (Child-Child)", "Angle (degrees)",
                    os.path.join(output_dir, f"{filename_prefix}branching_angles_distribution.png"), bins=18)


def analyze_degree_distribution(graph: nx.DiGraph, output_dir: str, filename_prefix: str = "final_"):
    if graph is None or graph.number_of_nodes() == 0:
        logger.warning("Degree distribution analysis: Graph is empty or None.")
        return
    if not MATPLOTLIB_AVAILABLE:
        logger.warning("Matplotlib not available. Skipping degree distribution plots.")
        return

    degrees = [d for n, d in graph.degree()]
    in_degrees = [d for n, d in graph.in_degree()]
    out_degrees = [d for n, d in graph.out_degree()]

    df_degrees = pd.DataFrame({
        'node_id': list(graph.nodes()),
        'total_degree': degrees,
        'in_degree': in_degrees,
        'out_degree': out_degrees
    })
    csv_path = os.path.join(output_dir, f"{filename_prefix}degree_data.csv")
    df_degrees.to_csv(csv_path, index=False)
    logger.info(f"Saved node degree data to {csv_path}")

    max_bins_degree = 10 # Default max bins for degree plots
    if degrees: max_bins_degree = max(1, max(degrees))
    _plot_histogram(degrees, "Total Node Degree Distribution", "Degree",
                    os.path.join(output_dir, f"{filename_prefix}total_degree_distribution.png"),
                    bins=min(max_bins_degree, 50)) # Cap bins for very high degrees
    if in_degrees: max_bins_degree = max(1, max(in_degrees))
    _plot_histogram(in_degrees, "Node In-Degree Distribution", "In-Degree",
                    os.path.join(output_dir, f"{filename_prefix}in_degree_distribution.png"),
                    bins=min(max_bins_degree, 50))
    if out_degrees: max_bins_degree = max(1, max(out_degrees))
    _plot_histogram(out_degrees, "Node Out-Degree Distribution", "Out-Degree",
                    os.path.join(output_dir, f"{filename_prefix}out_degree_distribution.png"),
                    bins=min(max_bins_degree, 50))

def analyze_network_connectivity(graph: nx.DiGraph, output_dir: str, filename_prefix: str = "final_"):
    if graph is None or graph.number_of_nodes() == 0:
        logger.warning("Network connectivity analysis: Graph is empty or None.")
        return
    undirected_graph = graph.to_undirected()
    num_components = nx.number_connected_components(undirected_graph)
    logger.info(f"Network Connectivity: Number of connected components (undirected) = {num_components}")
    if num_components > 1:
        logger.warning(f"Network has {num_components} disconnected components. Expected 1 for a fully connected structure from seeds.")

def analyze_volumetric_densities(graph: nx.DiGraph, tissue_data: dict, output_dir: str, filename_prefix: str = "final_"):
    if graph is None or graph.number_of_nodes() == 0:
        logger.warning("Volumetric density analysis: Graph is empty or None.")
        return
    if 'domain_mask' not in tissue_data or 'voxel_volume' not in tissue_data:
        logger.warning("Volumetric density analysis: Missing 'domain_mask' or 'voxel_volume' in tissue_data.")
        return

    domain_mask = tissue_data['domain_mask']
    voxel_volume = tissue_data['voxel_volume'] 

    if domain_mask is None or voxel_volume <= 0:
        logger.warning("Volumetric density analysis: Invalid domain_mask or voxel_volume.")
        return

    domain_volume_mm3 = np.sum(domain_mask) * voxel_volume
    if domain_volume_mm3 < constants.EPSILON:
        logger.warning("Volumetric density analysis: Domain volume is zero. Cannot calculate densities.")
        return

    total_vessel_length_mm = sum(data['length'] for u, v, data in graph.edges(data=True) if 'length' in data and np.isfinite(data['length']))
    num_bifurcation_nodes = sum(1 for node_id, data in graph.nodes(data=True) if data.get('type') == 'synthetic_bifurcation')

    vessel_length_density_mm_per_mm3 = total_vessel_length_mm / domain_volume_mm3
    branchpoint_density_per_mm3 = num_bifurcation_nodes / domain_volume_mm3

    logger.info(f"--- Volumetric Densities (Domain Volume: {domain_volume_mm3:.2e} mm^3) ---")
    logger.info(f"  Total vessel length: {total_vessel_length_mm:.2e} mm")
    logger.info(f"  Vessel length density: {vessel_length_density_mm_per_mm3:.2e} mm/mm^3")
    logger.info(f"  Number of bifurcation points: {num_bifurcation_nodes}")
    logger.info(f"  Branchpoint density: {branchpoint_density_per_mm3:.2e} #/mm^3")

    density_data = {
        'domain_volume_mm3': domain_volume_mm3,
        'total_vessel_length_mm': total_vessel_length_mm,
        'vessel_length_density_mm_per_mm3': vessel_length_density_mm_per_mm3,
        'num_bifurcation_nodes': num_bifurcation_nodes,
        'branchpoint_density_per_mm3': branchpoint_density_per_mm3
    }
    df_density = pd.DataFrame([density_data])
    csv_path = os.path.join(output_dir, f"{filename_prefix}volumetric_density_data.csv")
    df_density.to_csv(csv_path, index=False)
    logger.info(f"Saved volumetric density data to {csv_path}")


def plot_vascular_tree_pyvista(
    graph: Optional[nx.DiGraph],
    title: str = "Vascular Tree",
    output_screenshot_path: Optional[str] = None,
    tissue_masks: Optional[Dict[str, Tuple[np.ndarray, np.ndarray]]] = None,
    # REMOVED: gbo_seed_points_world: Optional[List[Tuple[np.ndarray, float, str]]] = None, 
    initial_tumor_seed_info: Optional[Dict] = None,
    color_by_scalar: Optional[str] = 'radius', 
    scalar_bar_title_override: Optional[str] = None,
    custom_cmap: Optional[str] = None,
    config_for_viz_params: Optional[dict] = None 
    ):
    if not PYVISTA_AVAILABLE: logger.warning("PyVista not available. Skipping 3D PyVista plot."); return

    cfg = config_for_viz_params if config_for_viz_params else {}
    bg_color = config_manager.get_param(cfg, "visualization.pyvista_background_color", "white")
    default_cmap_radius = config_manager.get_param(cfg, "visualization.pyvista_cmap_radius", "viridis")
    # seed_color = config_manager.get_param(cfg, "visualization.seed_point_color", "red") # No longer used here directly
    # seed_radius_scale = config_manager.get_param(cfg, "visualization.seed_marker_radius_scale", 5.0) # No longer used here
    tumor_seed_color = config_manager.get_param(cfg, "visualization.tumor_seed_marker_color", "magenta")

    plotter = pv.Plotter(off_screen=output_screenshot_path is not None, window_size=[1200,900])
    plotter.background_color = bg_color
    plotter.add_title(title, font_size=16)

    spacing_for_markers = np.array([1.0, 1.0, 1.0]) 

    if tissue_masks:
        mask_colors_default = {
            "GM": "lightblue", "WM": "lightyellow", 
            "domain_mask": config_manager.get_param(cfg, "visualization.domain_mask_color", "lightgray"),
            "CSF": "lightcyan",
            "Tumor_Max_Extent": config_manager.get_param(cfg, "visualization.tumor_max_extent_mask_color", "salmon"),
            "Tumor": config_manager.get_param(cfg, "visualization.active_tumor_mask_color", "darkred")
        }
        mask_opacities_default = {
            "GM": 0.2, "WM": 0.2, 
            "domain_mask": config_manager.get_param(cfg, "visualization.domain_mask_opacity", 0.1),
            "CSF": 0.1,
            "Tumor_Max_Extent": 0.15,
            "Tumor": 0.3 
        }

        for mask_name, mask_data_tuple in tissue_masks.items():
            if not isinstance(mask_data_tuple, tuple) or len(mask_data_tuple) != 2: continue
            mask_data, affine = mask_data_tuple
            if mask_data is None or not np.any(mask_data) or affine is None: continue
            logger.info(f"Plotting context mask '{mask_name}': Shape={mask_data.shape}, Sum={np.sum(mask_data)}")
            try:
                dims = np.array(mask_data.shape)
                current_spacing = np.abs(np.diag(affine)[:3])
                origin = affine[:3, 3]
                if np.all(current_spacing > constants.EPSILON): 
                    spacing_for_markers = current_spacing
                grid = pv.ImageData(dimensions=dims, spacing=current_spacing, origin=origin)
                grid.point_data[mask_name] = mask_data.flatten(order="F").astype(float)
                contour = grid.contour([0.5], scalars=mask_name, rng=[0,1])
                if contour.n_points > 0:
                    color = mask_colors_default.get(mask_name, "grey")
                    opacity = mask_opacities_default.get(mask_name, 0.1)
                    plotter.add_mesh(contour, color=color, opacity=opacity, style='surface')
                else: logger.warning(f"No contour generated for mask '{mask_name}'.")
            except Exception as e_mask: logger.error(f"Error plotting mask '{mask_name}': {e_mask}", exc_info=True)
    else:
        logger.info("No tissue masks provided for this plot.")

    # REMOVED GBO SEED POINTS PLOTTING FROM HERE
    # It's in visualize_initial_setup

    if initial_tumor_seed_info:
        center_w = initial_tumor_seed_info.get('center_world')
        radius_w = initial_tumor_seed_info.get('radius_world')
        if center_w is not None and radius_w is not None and radius_w > 0:
            logger.info(f"Plotting initial tumor seed sphere at {np.round(center_w,2)} with radius {radius_w:.3f}")
            plotter.add_mesh(pv.Sphere(center=center_w, radius=radius_w), color=tumor_seed_color, opacity=0.5)
            plotter.add_point_labels(center_w + np.array([0,0,radius_w*1.5]), ["Initial Tumor Seed"], font_size=10, text_color=tumor_seed_color)

    tree_mesh_bounds_logged = False
    if graph is not None and graph.number_of_nodes() > 0:
        points, lines, node_to_idx, idx_counter = [], [], {}, 0
        point_data_arrays: Dict[str, List[float]] = {'radius': [], 'pressure': []}
        edge_data_arrays: Dict[str, List[float]] = {'flow_solver': []}
        min_voxel_dim = np.min(spacing_for_markers) if np.any(spacing_for_markers > 0) else 0.01
        min_plot_radius = max(constants.MIN_VESSEL_RADIUS_MM * 0.1, min_voxel_dim * 0.05, 1e-4)

        for node_id, data in graph.nodes(data=True):
            if 'pos' in data and np.all(np.isfinite(data['pos'])):
                points.append(data['pos'])
                point_data_arrays['radius'].append(max(data.get('radius', min_plot_radius), min_plot_radius) if np.isfinite(data.get('radius', min_plot_radius)) else min_plot_radius)
                point_data_arrays['pressure'].append(data.get('pressure', np.nan))
                node_to_idx[node_id] = idx_counter; idx_counter += 1
        if not points: logger.warning("No valid nodes with positions in graph for tree plotting.")
        else:
            points_np = np.array(points)
            for u, v, data in graph.edges(data=True):
                if u in node_to_idx and v in node_to_idx:
                    lines.extend([2, node_to_idx[u], node_to_idx[v]])
                    edge_data_arrays['flow_solver'].append(data.get('flow_solver', np.nan))
            tree_mesh = pv.PolyData()
            if points_np.shape[0] > 0:
                tree_mesh.points = points_np
                for key, arr in point_data_arrays.items():
                    if arr and len(arr) == tree_mesh.n_points: tree_mesh.point_data[key] = np.array(arr)
                logger.info(f"Vascular tree mesh for plot: {tree_mesh.n_points} points. Bounds: {tree_mesh.bounds}")
                tree_mesh_bounds_logged = True
                if lines:
                    tree_mesh.lines = np.array(lines)
                    if tree_mesh.n_cells > 0:
                        for key, arr in edge_data_arrays.items():
                             if arr and len(arr) == tree_mesh.n_cells: tree_mesh.cell_data[key] = np.array(arr)
                        active_scalars_on_points = color_by_scalar in tree_mesh.point_data and np.any(np.isfinite(tree_mesh.point_data[color_by_scalar]))
                        active_scalars_on_cells = color_by_scalar in tree_mesh.cell_data and np.any(np.isfinite(tree_mesh.cell_data[color_by_scalar]))
                        sargs = {'title': scalar_bar_title_override if scalar_bar_title_override else color_by_scalar.replace("_"," ").title(), 'color':'black', 'vertical':True, 'position_y': 0.05, 'position_x': 0.85, 'height': 0.3, 'n_labels': 5}
                        current_cmap_actual = custom_cmap if custom_cmap else (default_cmap_radius if color_by_scalar == 'radius' else 'coolwarm')
                        preference = 'point' if active_scalars_on_points else ('cell' if active_scalars_on_cells else None)
                        if preference:
                            plotter.add_mesh(tree_mesh, scalars=color_by_scalar, line_width=3, cmap=current_cmap_actual, render_lines_as_tubes=True, scalar_bar_args=sargs, preference=preference)
                        else:
                            if 'radius' in tree_mesh.point_data and np.any(np.isfinite(tree_mesh.point_data['radius'])):
                                plotter.add_mesh(tree_mesh, scalars='radius', line_width=3, cmap=default_cmap_radius, render_lines_as_tubes=True, scalar_bar_args={'title': 'Radius (mm)', **sargs})
                            else: plotter.add_mesh(tree_mesh, color="darkgrey", line_width=2, render_lines_as_tubes=True)
    if not tree_mesh_bounds_logged: logger.info("No vascular graph provided or it was empty.")

    plotter.camera_position = 'iso'
    plotter.enable_parallel_projection()
    plotter.add_axes(interactive=True)
    if output_screenshot_path: plotter.show(auto_close=True, screenshot=output_screenshot_path)
    else: plotter.show()


def visualize_initial_setup(
    config: dict, output_dir: str, tissue_data: dict, 
    initial_arterial_graph: Optional[nx.DiGraph]
    ):
    logger.info("Generating visualization of initial simulation setup...")
    
    masks_to_plot: Dict[str, Tuple[np.ndarray, np.ndarray]] = {}
    mask_keys_to_plot = ['domain_mask', 'GM', 'WM', 'CSF', 'Tumor_Max_Extent']
    for key in mask_keys_to_plot:
        if tissue_data.get(key) is not None and np.any(tissue_data[key]) and tissue_data.get('affine') is not None:
            masks_to_plot[key] = (tissue_data[key], tissue_data['affine'])
            logger.info(f"Added '{key}' to initial setup plot.")

    # GBO seeds specific visualization logic - this should be kept in visualize_initial_setup
    gbo_seeds_viz_data: List[Tuple[np.ndarray, float, str]] = []
    if not initial_arterial_graph or initial_arterial_graph.number_of_nodes() == 0:
        config_gbo_seeds = config_manager.get_param(config, "gbo_growth.seed_points", [])
        if config_gbo_seeds and isinstance(config_gbo_seeds, list):
            for i, seed_info in enumerate(config_gbo_seeds):
                if isinstance(seed_info, dict) and 'position' in seed_info:
                    gbo_seeds_viz_data.append((np.array(seed_info['position']),
                                               float(seed_info.get('initial_radius',0.1)),
                                               seed_info.get('id',f"GBO_Seed_{i}")))

    initial_tumor_seed_plot_info: Optional[Dict] = None
    tumor_seed_config = config_manager.get_param(config, "tumor_angiogenesis.initial_tumor_seed", {})
    if tissue_data.get('Tumor_Max_Extent') is not None and np.any(tissue_data['Tumor_Max_Extent']):
        center_ijk = tumor_seed_config.get('center_voxel_ijk_relative_to_image_grid')
        radius_vox = tumor_seed_config.get('radius_voxels')
        if center_ijk and radius_vox and tissue_data.get('affine') is not None:
            center_world = utils.voxel_to_world(np.array(center_ijk), tissue_data['affine'])[0]
            avg_voxel_spacing = np.mean(np.abs(np.diag(tissue_data['affine'])[:3]))
            radius_world = radius_vox * avg_voxel_spacing
            initial_tumor_seed_plot_info = {'center_world': center_world, 'radius_world': radius_world}

    plot_title = "Initial Simulation Setup: Masks, Arterial Tree/Seeds, Tumor Seed"
    screenshot_path = os.path.join(output_dir, "initial_setup_visualization.png")

    if PYVISTA_AVAILABLE:
        # Corrected call to plot_vascular_tree_pyvista for visualize_initial_setup
        # It *does* use gbo_seed_points_world
        plot_vascular_tree_pyvista(
            graph=initial_arterial_graph, 
            title=plot_title,
            output_screenshot_path=screenshot_path,
            tissue_masks=masks_to_plot,
            gbo_seed_points_world=gbo_seeds_viz_data, # THIS FUNCTION USES IT
            initial_tumor_seed_info=initial_tumor_seed_plot_info,
            color_by_scalar='radius', 
            config_for_viz_params=config 
        )
    else:
        logger.warning("PyVista not available, skipping initial setup 3D plot.")


def generate_final_visualizations(
    config: dict, output_dir: str, tissue_data: dict, vascular_graph: Optional[nx.DiGraph],
    perfusion_map: Optional[np.ndarray] = None, pressure_map_tissue: Optional[np.ndarray] = None,
    plot_context_masks: bool = True 
    ):
    logger.info("Generating final visualizations and quantitative analyses...")
    
    masks_to_plot_for_pyvista: Optional[Dict[str, Tuple[np.ndarray, np.ndarray]]]
    if plot_context_masks:
        masks_to_plot_for_pyvista = {}
        mask_keys = ['domain_mask', 'GM', 'WM', 'CSF', 'Tumor'] 
        for key in mask_keys:
            if tissue_data.get(key) is not None and np.any(tissue_data[key]) and tissue_data.get('affine') is not None:
                masks_to_plot_for_pyvista[key] = (tissue_data[key], tissue_data['affine'])
        if not masks_to_plot_for_pyvista: 
            logger.info("No valid masks found in tissue_data to plot for context.")
            masks_to_plot_for_pyvista = None 
    else:
        logger.info("Context mask plotting is disabled for this visualization call.")
        masks_to_plot_for_pyvista = None

    if vascular_graph and vascular_graph.number_of_nodes() > 0:
        final_tree_vtp_path = os.path.join(output_dir, "final_plot_vascular_tree.vtp")
        io_utils.save_vascular_tree_vtp(vascular_graph, final_tree_vtp_path,
                                        radius_attr='radius', pressure_attr='pressure', flow_attr='flow_solver')
        logger.info(f"Final vascular tree saved for analysis: {final_tree_vtp_path}")

        analyze_radii_distribution(vascular_graph, output_dir)
        analyze_segment_lengths(vascular_graph, output_dir)
        analyze_bifurcation_geometry(vascular_graph, output_dir,
                                     murray_exponent=config_manager.get_param(config, "vascular_properties.murray_law_exponent", 3.0))
        analyze_degree_distribution(vascular_graph, output_dir)
        analyze_network_connectivity(vascular_graph, output_dir)
        analyze_volumetric_densities(vascular_graph, tissue_data, output_dir)

        pv_plot_title_radius = f"Vasculature (Radius, {vascular_graph.number_of_nodes()}N, {vascular_graph.number_of_edges()}E)"
        pv_screenshot_path_radius = os.path.join(output_dir, f"final_vascular_tree_radius_3D{'' if plot_context_masks else '_no_context'}.png")
        if PYVISTA_AVAILABLE:
            plot_vascular_tree_pyvista( # REMOVED seed_points_world
                graph=vascular_graph, title=pv_plot_title_radius, output_screenshot_path=pv_screenshot_path_radius,
                tissue_masks=masks_to_plot_for_pyvista, 
                initial_tumor_seed_info=None, # Tumor seed less relevant for final unless specifically requested
                color_by_scalar='radius', 
                custom_cmap=config_manager.get_param(config, "visualization.pyvista_cmap_radius", "viridis"),
                config_for_viz_params=config
            )

            if any('flow_solver' in data for _,_,data in vascular_graph.edges(data=True) if 'flow_solver' in data and np.any(np.isfinite(data['flow_solver']))):
                pv_plot_title_flow = f"Vasculature (Edge Flow, {vascular_graph.number_of_nodes()}N, {vascular_graph.number_of_edges()}E)"
                pv_screenshot_path_flow = os.path.join(output_dir, f"final_vascular_tree_flow_3D{'' if plot_context_masks else '_no_context'}.png")
                plot_vascular_tree_pyvista( # REMOVED seed_points_world
                    graph=vascular_graph, title=pv_plot_title_flow, output_screenshot_path=pv_screenshot_path_flow,
                    tissue_masks=masks_to_plot_for_pyvista, 
                    initial_tumor_seed_info=None,
                    color_by_scalar='flow_solver', custom_cmap='coolwarm', scalar_bar_title_override="Flow (mm³/s)",
                    config_for_viz_params=config
                )
            else: logger.info("Skipping flow plot: No valid 'flow_solver' data on edges.")

            if any('pressure' in data for _,data in vascular_graph.nodes(data=True) if 'pressure' in data and np.any(np.isfinite(data['pressure']))):
                pv_plot_title_pressure = f"Vasculature (Node Pressure, {vascular_graph.number_of_nodes()}N, {vascular_graph.number_of_edges()}E)"
                pv_screenshot_path_pressure = os.path.join(output_dir, f"final_vascular_tree_pressure_3D{'' if plot_context_masks else '_no_context'}.png")
                plot_vascular_tree_pyvista( # REMOVED seed_points_world
                    graph=vascular_graph, title=pv_plot_title_pressure, output_screenshot_path=pv_screenshot_path_pressure,
                    tissue_masks=masks_to_plot_for_pyvista, 
                    initial_tumor_seed_info=None,
                    color_by_scalar='pressure', custom_cmap='coolwarm', scalar_bar_title_override="Pressure (Pa)",
                    config_for_viz_params=config
                )
            else: logger.info("Skipping pressure plot: No valid 'pressure' data on nodes.")
        else: logger.warning("PyVista not available, skipping 3D plots.")
    else: 
        logger.warning("Vascular graph is empty or None. Skipping VTP save and quantitative analyses.")
        if PYVISTA_AVAILABLE:
            plot_vascular_tree_pyvista(None, title=f"Tissue Context (No Vasculature){' (No Context Masks)' if not plot_context_masks else ''}",
                                       output_screenshot_path=os.path.join(output_dir, f"context_only_plot{'' if plot_context_masks else '_no_context'}.png"),
                                       tissue_masks=masks_to_plot_for_pyvista, 
                                       initial_tumor_seed_info=None, # No GBO seeds here
                                       config_for_viz_params=config
                                       )
    logger.info("Final visualizations and analyses generation complete.")
--- File: ./angiogenesis.py ---
# src/angiogenesis.py
from __future__ import annotations # Must be first line

import numpy as np
import networkx as nx
import logging
import os
from scipy.spatial import KDTree
from scipy.ndimage import binary_erosion, binary_dilation, gaussian_filter
from typing import Tuple, List, Dict, Optional, Set, Callable

from src import utils, data_structures, constants, config_manager, io_utils
from src.vascular_growth import GBOIterationData

logger = logging.getLogger(__name__)

DEFAULT_RIM_THICKNESS_VOXELS = 3
DEFAULT_VEGF_PRODUCTION_RIM = 1.0
DEFAULT_MIN_TUMOR_TERMINAL_DEMAND = 1e-5

# --- Tumor Morphology and State Update Functions ---
# (initialize_active_tumor_from_seed, update_tumor_rim_and_core,
#  update_metabolic_demand_for_tumor, update_vegf_field_rim_driven,
#  grow_tumor_mass_within_defined_segmentation, coopt_and_modify_vessels,
#  find_angiogenic_sprouting_candidates - These functions remain the same as the previous complete version)
# For brevity, I will assume these functions are present as in the previous complete response.
# If you need them explicitly here, let me know. I'll paste them from the previous version.

# --- PASTE THE FOLLOWING FUNCTIONS FROM THE PREVIOUS RESPONSE HERE ---
# initialize_active_tumor_from_seed
# update_tumor_rim_and_core
# update_metabolic_demand_for_tumor
# update_vegf_field_rim_driven
# grow_tumor_mass_within_defined_segmentation
# coopt_and_modify_vessels
# find_angiogenic_sprouting_candidates
# --- END OF PASTED FUNCTIONS ---

# --- Angiogenesis Core Functions (Sprouting, Growth, Co-option) ---
# (Functions like find_angiogenic_sprouting_candidates, coopt_and_modify_vessels are assumed to be here
#  from the previous "complete" version provided)

# --- PASTE find_angiogenic_sprouting_candidates and coopt_and_modify_vessels here from previous response ---
def initialize_active_tumor_from_seed(tissue_data: dict, config: dict) -> bool:
    """
    Initializes a small 'active' tumor (tissue_data['Tumor'])
    within the bounds of a pre-defined 'Tumor_Max_Extent'.
    If specific seed coordinates are not provided in config, it attempts to find a seed automatically.
    """
    tumor_max_extent_array = tissue_data.get('Tumor_Max_Extent')
    if tumor_max_extent_array is None or not np.any(tumor_max_extent_array):
        logger.error("Cannot initialize seed: 'Tumor_Max_Extent' not found, is None, or is empty in tissue_data.")
        if 'shape' in tissue_data and tissue_data['shape'] is not None:
            tissue_data['Tumor'] = np.zeros(tissue_data['shape'], dtype=bool)
        return False

    tumor_seed_config = config_manager.get_param(config, "tumor_angiogenesis.initial_tumor_seed", {})
    seed_strategy = tumor_seed_config.get("strategy", "auto_center") # New: "auto_center", "auto_random", "manual"
    radius_vox = tumor_seed_config.get('radius_voxels', 3)
    shape = tissue_data['shape']
    center_vox_ijk = None

    if seed_strategy == "manual":
        center_vox_ijk_manual = tumor_seed_config.get('center_voxel_ijk_relative_to_image_grid')
        if not center_vox_ijk_manual or not isinstance(center_vox_ijk_manual, list) or len(center_vox_ijk_manual) != 3:
            logger.error("Tumor seed strategy is 'manual' but 'center_voxel_ijk_relative_to_image_grid' not properly defined. Aborting seed.")
            tissue_data['Tumor'] = np.zeros(shape, dtype=bool)
            return False
        center_vox_ijk = np.array(center_vox_ijk_manual)
        if not utils.is_voxel_in_bounds(center_vox_ijk, shape):
             logger.error(f"Manual tumor seed center {center_vox_ijk} is outside image dimensions {shape}.")
             tissue_data['Tumor'] = np.zeros(shape, dtype=bool)
             return False
    elif seed_strategy == "auto_center":
        from scipy.ndimage import center_of_mass
        if np.any(tumor_max_extent_array):
            # Calculate the center of mass of the Tumor_Max_Extent mask
            # Ensure it's integer coordinates and within bounds
            com_float = center_of_mass(tumor_max_extent_array)
            center_vox_ijk = np.round(com_float).astype(int)
            # Clip to ensure it's within array bounds strictly (for safety with radius)
            for d in range(3):
                center_vox_ijk[d] = np.clip(center_vox_ijk[d], radius_vox, shape[d] - 1 - radius_vox)
            logger.info(f"Automatic seed strategy 'auto_center': calculated COM {com_float}, using seed center {center_vox_ijk}.")
        else: # Should have been caught by the first check, but for safety
            logger.error("'auto_center' seed strategy failed: Tumor_Max_Extent is empty.")
            tissue_data['Tumor'] = np.zeros(shape, dtype=bool)
            return False
    elif seed_strategy == "auto_random":
        true_indices = np.array(np.where(tumor_max_extent_array)).T
        if true_indices.shape[0] > 0:
            random_idx = np.random.choice(true_indices.shape[0])
            center_vox_ijk = true_indices[random_idx]
            logger.info(f"Automatic seed strategy 'auto_random': selected random seed center {center_vox_ijk}.")
        else: # Should have been caught, but for safety
            logger.error("'auto_random' seed strategy failed: Tumor_Max_Extent is empty.")
            tissue_data['Tumor'] = np.zeros(shape, dtype=bool)
            return False
    else:
        logger.error(f"Unknown tumor seed strategy: {seed_strategy}. Choose 'manual', 'auto_center', or 'auto_random'.")
        tissue_data['Tumor'] = np.zeros(shape, dtype=bool)
        return False

    # Create a spherical seed mask at the determined center
    coords = np.ogrid[:shape[0], :shape[1], :shape[2]]
    distance_sq = ((coords[0] - center_vox_ijk[0])**2 +
                   (coords[1] - center_vox_ijk[1])**2 +
                   (coords[2] - center_vox_ijk[2])**2)
    initial_seed_mask = distance_sq <= radius_vox**2

    # Active tumor is the seed AND where it overlaps with the max extent
    tissue_data['Tumor'] = initial_seed_mask & tumor_max_extent_array

    if not np.any(tissue_data['Tumor']):
        logger.warning(f"Initial tumor seed (strategy: {seed_strategy}) at {center_vox_ijk} with radius {radius_vox} "
                       f"resulted in an empty active tumor region within Tumor_Max_Extent. "
                       f"This might happen if Tumor_Max_Extent is very thin or small at the chosen seed location, "
                       f"or if the seed radius is too small to capture any 'True' voxels of Tumor_Max_Extent.")
        # tissue_data['Tumor'] is already an all-False array of the right shape here
        return False

    logger.info(f"Initialized active tumor seed (strategy: {seed_strategy}) within Tumor_Max_Extent: "
                f"center_vox={center_vox_ijk}, radius_vox={radius_vox}, "
                f"num_active_tumor_voxels={np.sum(tissue_data['Tumor'])}")
    return True

def update_tumor_rim_and_core(tissue_data: dict, config: dict):
    """Identifies tumor rim and core based on current active tissue_data['Tumor'] mask."""
    active_tumor_mask_local = tissue_data.get('Tumor') # Get the array first
    if active_tumor_mask_local is None or not np.any(active_tumor_mask_local): # Check if None or all False
        # Ensure these keys exist even if tumor is empty, to prevent KeyErrors later
        if 'shape' in tissue_data and tissue_data['shape'] is not None:
            tissue_data['tumor_rim_mask'] = np.zeros(tissue_data['shape'], dtype=bool)
            tissue_data['tumor_core_mask'] = np.zeros(tissue_data['shape'], dtype=bool)
        else:
            logger.error("Cannot initialize empty rim/core masks as tissue_data['shape'] is missing.")
        return

    # Now we know active_tumor_mask_local is a valid NumPy array with at least one True value
    active_tumor_mask_bool = active_tumor_mask_local.astype(bool) # Ensure boolean for morphology operations
    params = config_manager.get_param(config, "tumor_angiogenesis.tumor_morphology", {})
    rim_thickness = params.get("rim_thickness_voxels", DEFAULT_RIM_THICKNESS_VOXELS)

    if rim_thickness <= 0: # No rim, all core (or all rim if tumor is very small and erosion makes it disappear)
        # If no rim thickness, the whole active tumor is considered rim for VEGF production,
        # and there's no distinct core by erosion.
        # Or, another interpretation: all is core. Let's assume all is rim for VEGF.
        eroded_core = np.zeros_like(active_tumor_mask_bool)
        # If tumor is smaller than rim_thickness, erosion might make it disappear.
        # In such a case, consider the whole tumor as rim.
        if np.sum(active_tumor_mask_bool) > 0 and np.sum(binary_erosion(active_tumor_mask_bool, iterations=rim_thickness, border_value=0)) == 0:
             # If erosion results in nothing, but tumor exists, the whole thing is effectively rim
             tissue_data['tumor_rim_mask'] = active_tumor_mask_bool.copy()
             tissue_data['tumor_core_mask'] = np.zeros_like(active_tumor_mask_bool)
        else:
             eroded_core = binary_erosion(active_tumor_mask_bool, iterations=rim_thickness, border_value=0)
             tissue_data['tumor_core_mask'] = eroded_core
             tissue_data['tumor_rim_mask'] = active_tumor_mask_bool & (~eroded_core)

    else: # rim_thickness > 0
        eroded_core = binary_erosion(active_tumor_mask_bool, iterations=rim_thickness, border_value=0)
        tissue_data['tumor_core_mask'] = eroded_core
        tissue_data['tumor_rim_mask'] = active_tumor_mask_bool & (~eroded_core)
    
    logger.debug(f"Updated tumor rim ({np.sum(tissue_data.get('tumor_rim_mask', np.array([])))} vox) and core ({np.sum(tissue_data.get('tumor_core_mask', np.array([])))} vox).")

def update_metabolic_demand_for_tumor(tissue_data: dict, config: dict):
    """Updates metabolic_demand_map based on tumor rim and core."""
    active_tumor_mask_local = tissue_data.get('Tumor') # Get the array first
    if active_tumor_mask_local is None or not np.any(active_tumor_mask_local): # Check if None or all False
        # No active tumor, so no specific tumor metabolic demand to set.
        # The metabolic_demand_map should reflect healthy tissue or be zero in these areas.
        logger.debug("No active tumor present; skipping tumor-specific metabolic demand update.")
        return

    # Ensure metabolic_demand_map exists and has the correct shape
    if 'metabolic_demand_map' not in tissue_data or \
       tissue_data.get('metabolic_demand_map') is None or \
       tissue_data['metabolic_demand_map'].shape != tissue_data['shape']:
        # If it's missing or wrong shape, it should have been initialized correctly in load_initial_data
        # or after the first tumor growth step. For safety, ensure it's there.
        if 'shape' in tissue_data and tissue_data['shape'] is not None:
            tissue_data['metabolic_demand_map'] = np.zeros(tissue_data['shape'], dtype=float)
            logger.warning("Re-initialized metabolic_demand_map during tumor demand update due to mismatch or absence.")
        else:
            logger.error("Cannot update metabolic demand for tumor: tissue_data['shape'] is missing.")
            return


    rates = config_manager.get_param(config, "tissue_properties.metabolic_rates", {})
    q_met_rim = rates.get("tumor_rim", constants.Q_MET_TUMOR_RIM_PER_ML)
    q_met_core = rates.get("tumor_core", constants.Q_MET_TUMOR_CORE_PER_ML)
    voxel_vol = tissue_data['voxel_volume']

    # metabolic_demand_map should already exist and be initialized (e.g. with healthy demands)
    # We are now OVERWRITING the demand in tumor regions.

    if tissue_data.get('tumor_rim_mask') is not None and np.any(tissue_data['tumor_rim_mask']):
        tissue_data['metabolic_demand_map'][tissue_data['tumor_rim_mask']] = q_met_rim * voxel_vol
    
    if tissue_data.get('tumor_core_mask') is not None and np.any(tissue_data['tumor_core_mask']):
        tissue_data['metabolic_demand_map'][tissue_data['tumor_core_mask']] = q_met_core * voxel_vol
    
    # What about active tumor voxels that are neither rim nor core (e.g., if rim_thickness is 0 or tumor is tiny)?
    # The current update_tumor_rim_and_core logic tries to ensure rim+core covers the active tumor.
    # If there are any 'Tumor' voxels not covered by rim or core (shouldn't happen with current logic),
    # their metabolic rate would remain unchanged (i.e., healthy rate).
    # This is generally fine, as rim/core should define the tumor's metabolic activity.

    logger.debug("Updated metabolic demand map for active tumor regions (rim/core).")

def update_vegf_field_rim_driven(tissue_data: dict, config: dict) -> bool:
    """VEGF produced primarily by the tumor rim. Updates tissue_data['VEGF_field']."""
    tumor_rim_mask_local = tissue_data.get('tumor_rim_mask') # Get the array first
    if tumor_rim_mask_local is None or not np.any(tumor_rim_mask_local): # Check if None or all False
        logger.debug("No tumor rim to produce VEGF. Setting VEGF field to zero.")
        # Ensure VEGF_field exists even if empty
        if 'shape' in tissue_data and tissue_data['shape'] is not None:
            tissue_data['VEGF_field'] = np.zeros(tissue_data['shape'], dtype=float)
        else:
            logger.error("Cannot initialize empty 'VEGF_field' as tissue_data['shape'] is missing.")
        return True # Or False if this state is considered an error for VEGF generation

    # Now we know tumor_rim_mask_local is a valid NumPy array with at least one True value
    vegf_config = config_manager.get_param(config, "tumor_angiogenesis.vegf_settings", {})
    vegf_prod_rim = vegf_config.get("production_rate_rim", DEFAULT_VEGF_PRODUCTION_RIM)
    
    vegf_field = np.zeros(tissue_data['shape'], dtype=float) # Initialize with correct shape
    vegf_field[tumor_rim_mask_local] = vegf_prod_rim # Use the fetched local variable
    
    # Optional: Core contribution (if you add this logic back)
    # vegf_prod_core = vegf_config.get("production_rate_core", DEFAULT_VEGF_PRODUCTION_CORE)
    # tumor_core_mask_local = tissue_data.get('tumor_core_mask')
    # if tumor_core_mask_local is not None and np.any(tumor_core_mask_local):
    #     vegf_field[tumor_core_mask_local] += vegf_prod_core # Additive or max?

    if vegf_config.get("apply_diffusion_blur", True):
        sigma = vegf_config.get("diffusion_blur_sigma", 2.5)
        if sigma > 0 and np.any(vegf_field): # Only blur if there's something to blur
            try:
                vegf_field = gaussian_filter(vegf_field, sigma=sigma)
                logger.debug(f"Applied Gaussian blur (sigma={sigma}) to VEGF field.")
            except Exception as e: # Catch potential errors from gaussian_filter if field is weird
                logger.warning(f"Could not apply Gaussian blur to VEGF field: {e}")
    
    tissue_data['VEGF_field'] = vegf_field
    logger.info(f"Updated rim-driven VEGF field. Max VEGF: {np.max(vegf_field) if np.any(vegf_field) else 0:.2e}")
    return True

def grow_tumor_mass_within_defined_segmentation(tissue_data: dict, config: dict) -> bool:
    tumor_growth_params = config_manager.get_param(config, "tumor_angiogenesis.tumor_growth", {})
    expansion_voxels_per_step = tumor_growth_params.get("expansion_voxels_per_step", 100)
    
    # Get masks
    current_active_tumor_mask = tissue_data.get('Tumor')
    tumor_max_extent_mask = tissue_data.get('Tumor_Max_Extent')
    active_tumor_rim_mask = tissue_data.get('tumor_rim_mask') # This is calculated based on 'Tumor'

    # Check for None before np.any or other operations
    if current_active_tumor_mask is None or \
       tumor_max_extent_mask is None or \
       active_tumor_rim_mask is None: # active_tumor_rim_mask could be None if 'Tumor' was None when it was calculated
        logger.error("grow_tumor_mass: One or more required masks (Tumor, Tumor_Max_Extent, tumor_rim_mask) is None.")
        return False

    if np.all(current_active_tumor_mask == tumor_max_extent_mask): # This is fine, compares two arrays
        logger.info("Tumor Growth: Active tumor has filled 'Tumor_Max_Extent'.")
        return False
    
    # Determine source for dilation based on rim or whole active tumor
    source_for_dilation = active_tumor_rim_mask if np.any(active_tumor_rim_mask) else current_active_tumor_mask
    if not np.any(source_for_dilation): # Correctly checks if the chosen source is empty
        logger.info("Tumor Growth: Source for dilation (rim or active tumor) is empty. Cannot grow.")
        return False # Added this return

    # Ensure domain_mask is also valid before using it in the bitwise AND
    domain_mask_for_growth = tissue_data.get('domain_mask')
    if domain_mask_for_growth is None:
        logger.error("grow_tumor_mass: 'domain_mask' is None. Cannot determine growth candidates.")
        return False

    growth_candidates_mask = binary_dilation(source_for_dilation) & \
                             (~current_active_tumor_mask) & \
                             tumor_max_extent_mask & \
                             domain_mask_for_growth # Use the fetched domain_mask

    candidate_voxel_indices = np.array(np.where(growth_candidates_mask)).T
    if candidate_voxel_indices.shape[0] == 0:
        logger.info("Tumor Growth: No suitable healthy voxels for expansion within constraints.")
        return False
        
    num_to_convert = min(expansion_voxels_per_step, candidate_voxel_indices.shape[0])
    if num_to_convert > 0:
        chosen_indices_idx = np.random.choice(candidate_voxel_indices.shape[0], num_to_convert, replace=False)
        voxels_to_add = candidate_voxel_indices[chosen_indices_idx]
        
        new_active_tumor_mask = current_active_tumor_mask.copy()
        gm_mask = tissue_data.get('GM') # Fetch GM and WM once
        wm_mask = tissue_data.get('WM')

        for vox_idx_tuple in map(tuple, voxels_to_add):
            new_active_tumor_mask[vox_idx_tuple] = True
            if gm_mask is not None and utils.is_voxel_in_bounds(vox_idx_tuple, gm_mask.shape) and gm_mask[vox_idx_tuple]: # Check bounds for safety
                gm_mask[vox_idx_tuple] = False
            if wm_mask is not None and utils.is_voxel_in_bounds(vox_idx_tuple, wm_mask.shape) and wm_mask[vox_idx_tuple]: # Check bounds for safety
                wm_mask[vox_idx_tuple] = False
        
        tissue_data['Tumor'] = new_active_tumor_mask
        # Update GM and WM in tissue_data if they were modified
        if gm_mask is not None: tissue_data['GM'] = gm_mask
        if wm_mask is not None: tissue_data['WM'] = wm_mask

        logger.info(f"Tumor Growth: Expanded by {num_to_convert} vox. Active: {np.sum(new_active_tumor_mask)}, Max: {np.sum(tumor_max_extent_mask)}")
        return True
    return False

def coopt_and_modify_vessels(graph: nx.DiGraph, tissue_data: dict, config: dict):
    active_tumor_mask_local = tissue_data.get('Tumor') # Get the array
    if active_tumor_mask_local is None or not np.any(active_tumor_mask_local): # Corrected check
        logger.debug("Co-option: No active tumor to co-opt vessels from.")
        return

    affine = tissue_data.get('affine')
    if affine is None:
        logger.error("Co-option: Affine matrix not found in tissue_data. Cannot perform co-option.")
        return

    cooption_params = config_manager.get_param(config, "tumor_angiogenesis.cooption", {})
    radius_dilation_factor_mean = cooption_params.get("radius_dilation_factor_mean", 1.1)
    radius_dilation_factor_std = cooption_params.get("radius_dilation_factor_std", 0.05)
    permeability_Lp_tumor_factor = cooption_params.get("permeability_Lp_factor_tumor", 10.0)
    
    nodes_coopted_this_step: Set[str] = set()
    for node_id, data in graph.nodes(data=True):
        if data.get('is_tumor_vessel', False): continue
        
        node_pos = data.get('pos')
        if node_pos is None: continue # Skip nodes without position

        pos_vox_int = np.round(utils.world_to_voxel(node_pos, affine)).astype(int)
        if utils.is_voxel_in_bounds(pos_vox_int, active_tumor_mask_local.shape) and \
           active_tumor_mask_local[tuple(pos_vox_int)]:
            nodes_coopted_this_step.add(node_id)
            
    if not nodes_coopted_this_step:
        logger.debug("Co-option: No new healthy vessels found within active tumor for co-option this step.")
        return

    for node_id in nodes_coopted_this_step:
        node_data = graph.nodes[node_id] # Get node data once
        node_data['is_tumor_vessel'] = True
        node_data['vessel_origin_type'] = 'coopted_healthy'
        
        original_radius = node_data.get('radius', constants.MIN_VESSEL_RADIUS_MM) # Use default if radius missing
        dilation = max(0.5, np.random.normal(radius_dilation_factor_mean, radius_dilation_factor_std))
        new_radius = max(constants.MIN_VESSEL_RADIUS_MM, original_radius * dilation)
        node_data['radius'] = new_radius
        # logger.debug(f"Co-opted node {node_id}. Type: {node_data.get('type')}->coopted_healthy. R: {original_radius:.4f}->{new_radius:.4f}") # Already logged in main loop

        # Mark connected edges and update their radii if they originate from this node
        for u, v, edge_data in graph.out_edges(node_id, data=True): # Edges where this node is the source
            edge_data['is_tumor_vessel'] = True
            edge_data['radius'] = new_radius # Edge takes radius of its (now co-opted) source node
            edge_data['permeability_Lp_factor'] = permeability_Lp_tumor_factor
        for u, v, edge_data in graph.in_edges(node_id, data=True): # Edges where this node is the target
            edge_data['is_tumor_vessel'] = True # The segment is now within tumor influence
            edge_data['permeability_Lp_factor'] = permeability_Lp_tumor_factor
            # Radius of incoming edge is determined by its source node (u), which might also get co-opted

    logger.info(f"Co-opted and modified {len(nodes_coopted_this_step)} nodes and their adjacent edges.")

def find_angiogenic_sprouting_candidates(graph: nx.DiGraph, tissue_data: dict, config: dict) -> List[Tuple[str, str, np.ndarray, np.ndarray]]:
    candidates = []
    vegf_field_local = tissue_data.get('VEGF_field') # Get the array
    if vegf_field_local is None or not np.any(vegf_field_local): # Corrected check
        logger.debug("Sprouting candidates: No VEGF field or VEGF field is all zero.")
        return candidates

    affine = tissue_data.get('affine')
    if affine is None:
        logger.error("Sprouting candidates: Affine matrix not found in tissue_data.")
        return candidates

    sprouting_params = config_manager.get_param(config, "tumor_angiogenesis.sprouting", {})
    min_vegf = sprouting_params.get("min_vegf_concentration", 0.2)
    min_parent_r = sprouting_params.get("min_parent_vessel_radius_mm", 0.02)
    
    grad_ax0, grad_ax1, grad_ax2 = np.gradient(vegf_field_local) # Use local copy

    for u, v, edge_data in graph.edges(data=True):
        node_u_data = graph.nodes[u]
        node_v_data = graph.nodes[v] # Get v data too for position

        parent_radius = node_u_data.get('radius', 0) # Use default 0 if radius missing
        if parent_radius < min_parent_r: 
            continue
        
        pos_u = node_u_data.get('pos')
        pos_v = node_v_data.get('pos')
        if pos_u is None or pos_v is None: continue # Skip if positions are missing

        sprout_origin = (pos_u + pos_v) / 2.0
        sprout_vox_int = np.round(utils.world_to_voxel(sprout_origin, affine)).astype(int)

        if not utils.is_voxel_in_bounds(sprout_vox_int, vegf_field_local.shape): 
            continue
            
        if vegf_field_local[tuple(sprout_vox_int)] >= min_vegf:
            g_ax0 = grad_ax0[tuple(sprout_vox_int)]
            g_ax1 = grad_ax1[tuple(sprout_vox_int)]
            g_ax2 = grad_ax2[tuple(sprout_vox_int)]
            sprout_dir_vox = np.array([g_ax0, g_ax1, g_ax2])
            
            # Transform gradient to world space direction
            # affine[:3,:3] is the rotation/scaling part
            sprout_dir_world = utils.normalize_vector(affine[:3,:3] @ sprout_dir_vox) 

            if np.linalg.norm(sprout_dir_world) > constants.EPSILON:
                candidates.append((u, v, sprout_origin, sprout_dir_world))
    
    max_sprouts = sprouting_params.get("max_new_sprouts_per_iteration", 5)
    if len(candidates) > max_sprouts:
        indices = np.random.choice(len(candidates), max_sprouts, replace=False)
        selected_candidates = [candidates[i] for i in indices]
        logger.info(f"Selected {len(selected_candidates)} sprouts from {len(candidates)} original candidates.")
        return selected_candidates
    elif candidates: 
        logger.info(f"Found {len(candidates)} sprouting candidates.")
    else:
        logger.debug("No sprouting candidates found this step.")
    return candidates


def attempt_anastomosis_tip_to_segment(
    term_gbo: GBOIterationData,
    graph: nx.DiGraph, # The main angiogenic graph
    vessel_kdtree: KDTree, # KDTree of (positions of midpoints of all non-parent segments)
    segment_midpoints_data: List[Dict], # List of {'pos': mid_pos, 'u': seg_u, 'v': seg_v, 'radius': seg_radius}
    config: dict,
    next_synthetic_node_id_ref: List[int] # Pass as list to modify in place
) -> bool:
    """
    Attempts to anastomose the given angiogenic terminal (term_gbo) to a nearby existing segment.
    Modifies graph and term_gbo if successful.
    Returns True if anastomosis occurred, False otherwise.
    """
    anastomosis_params = config_manager.get_param(config, "tumor_angiogenesis.anastomosis", {})
    search_radius = term_gbo.radius * anastomosis_params.get("search_radius_factor", 3.0)
    min_angle_deg = anastomosis_params.get("min_fusion_angle_deg", 120.0) # Angle between tip's last segment and segment to target
    max_dist_to_midpoint_factor = anastomosis_params.get("max_dist_to_midpoint_factor", 1.5) # Tip must be close to midpoint

    if vessel_kdtree is None or not segment_midpoints_data: return False

    nearby_indices = vessel_kdtree.query_ball_point(term_gbo.pos, r=search_radius)
    if not nearby_indices: return False

    parent_of_tip_pos = graph.nodes[term_gbo.parent_id]['pos']
    tip_growth_vector = term_gbo.pos - parent_of_tip_pos # Vector of the last segment of the tip

    best_target_seg_info = None
    min_dist_sq = float('inf')

    for idx in nearby_indices:
        target_seg = segment_midpoints_data[idx]
        target_midpoint = target_seg['pos']
        target_u, target_v = target_seg['u'], target_seg['v']

        # Avoid self-anastomosis or anastomosis with immediate parent segment from bifurcation
        if term_gbo.parent_id == target_u or term_gbo.parent_id == target_v: continue
        # Avoid if target is the segment the tip just grew from (if parent_id was a midpoint)
        # This check needs to be more robust if parent_id can be a segment point.
        # For now, assume parent_id is a node.

        dist_sq = utils.distance_squared(term_gbo.pos, target_midpoint)
        if dist_sq < min_dist_sq and dist_sq < (term_gbo.radius * max_dist_to_midpoint_factor)**2 :
            # Check angle: vector from tip to target_midpoint vs. tip_growth_vector
            vec_tip_to_target = target_midpoint - term_gbo.pos
            if np.linalg.norm(tip_growth_vector) > constants.EPSILON and np.linalg.norm(vec_tip_to_target) > constants.EPSILON:
                cos_angle = np.dot(tip_growth_vector, vec_tip_to_target) / \
                            (np.linalg.norm(tip_growth_vector) * np.linalg.norm(vec_tip_to_target))
                angle_deg = np.degrees(np.arccos(np.clip(cos_angle, -1.0, 1.0)))
                if angle_deg >= min_angle_deg: # Tip should be "aiming away" or sideways relative to target for good fusion
                    min_dist_sq = dist_sq
                    best_target_seg_info = target_seg
    
    if best_target_seg_info:
        target_u = best_target_seg_info['u']
        target_v = best_target_seg_info['v']
        target_midpoint_pos = best_target_seg_info['pos'] # This will be the new anastomosis node

        logger.info(f"Anastomosis: Tip {term_gbo.id} (parent {term_gbo.parent_id}) fusing with segment {target_u}-{target_v} at {np.round(target_midpoint_pos,2)}.")

        # 1. Create new anastomosis node at target_midpoint_pos
        anastomosis_node_id = f"s_{next_synthetic_node_id_ref[0]}"; next_synthetic_node_id_ref[0] += 1
        # Radius of anastomosis node can be average or based on fusing vessels
        fused_radius = (term_gbo.radius + best_target_seg_info['radius']) / 2.0
        data_structures.add_node_to_graph(graph, anastomosis_node_id, pos=target_midpoint_pos, radius=fused_radius,
                                          type='anastomosis_point', is_tumor_vessel=True, vessel_origin_type='anastomosis')

        # 2. Remove old target segment (target_u, target_v)
        original_target_edge_data = graph.edges[target_u, target_v].copy() # Assuming directed u->v
        graph.remove_edge(target_u, target_v)

        # 3. Add new segments: target_u -> anastomosis_node, anastomosis_node -> target_v
        data_structures.add_edge_to_graph(graph, target_u, anastomosis_node_id, **original_target_edge_data) # Update length/radius
        graph.edges[target_u, anastomosis_node_id]['length'] = utils.distance(graph.nodes[target_u]['pos'], target_midpoint_pos)
        graph.edges[target_u, anastomosis_node_id]['radius'] = graph.nodes[target_u]['radius'] # Takes radius of upstream node

        data_structures.add_edge_to_graph(graph, anastomosis_node_id, target_v, **original_target_edge_data) # Update length/radius
        graph.edges[anastomosis_node_id, target_v]['length'] = utils.distance(target_midpoint_pos, graph.nodes[target_v]['pos'])
        graph.edges[anastomosis_node_id, target_v]['radius'] = fused_radius # Takes radius of new anastomosis node

        # 4. Connect the parent of the fusing tip to the anastomosis_node
        # The segment was (term_gbo.parent_id) -> term_gbo.id (which is at term_gbo.pos)
        # New segment is (term_gbo.parent_id) -> anastomosis_node_id
        tip_parent_node_id = term_gbo.parent_id
        data_structures.add_edge_to_graph(graph, tip_parent_node_id, anastomosis_node_id,
                                          length=utils.distance(graph.nodes[tip_parent_node_id]['pos'], target_midpoint_pos),
                                          radius=graph.nodes[tip_parent_node_id]['radius'], # Or fused_radius?
                                          type='angiogenic_segment', is_tumor_vessel=True,
                                          permeability_Lp_factor=graph.edges[tip_parent_node_id, term_gbo.id].get('permeability_Lp_factor'))


        # 5. Remove the old tip node (term_gbo.id) and its incoming segment
        graph.remove_edge(tip_parent_node_id, term_gbo.id)
        graph.remove_node(term_gbo.id)
        
        term_gbo.stop_growth = True # Mark this GBOIterationData as done
        return True
    return False


# --- Main Angiogenesis Orchestration ---
def simulate_tumor_angiogenesis_fixed_extent(
    config: dict,
    tissue_data: dict,
    base_vascular_tree: nx.DiGraph,
    output_dir: str,
    perfusion_solver_func: Callable[[nx.DiGraph, dict, Optional[float], Optional[Dict[str, float]]], Optional[nx.DiGraph]]
) -> nx.DiGraph:
    logger.info("--- Starting Tumor Angiogenesis Simulation (Growing within Fixed Extent) ---")
    
    main_params = config_manager.get_param(config, "tumor_angiogenesis", {})
    num_macro_iterations = main_params.get("num_macro_iterations", 20)
    tumor_growth_steps_per_macro = main_params.get("tumor_growth.steps_per_macro_iter", 1)
    angiogenesis_steps_per_macro = main_params.get("angiogenesis.steps_per_macro_iter", 3)
    flow_solve_interval_macro = main_params.get("flow_solve_interval_macro_iters", 5)
    save_interval_macro = main_params.get("save_intermediate_interval_macro_iters", 1)

    sprouting_params = main_params.get("sprouting", {})
    initial_sprout_radius = sprouting_params.get("initial_sprout_radius_mm", constants.MIN_VESSEL_RADIUS_MM * 1.1)
    initial_sprout_length = sprouting_params.get("initial_sprout_length_mm", initial_sprout_radius * 4)
    
    extension_params = main_params.get("extension", {})
    extension_step_length = extension_params.get("step_length_mm", initial_sprout_radius * 2)
    
    branching_params = main_params.get("angiogenic_branching", {})
    branch_probability_factor_vegf = branching_params.get("branch_probability_factor_vegf", 0.1) # Prob = factor * vegf_norm
    branch_angle_spread_deg = branching_params.get("branch_angle_spread_deg", 60.0)


    if not initialize_active_tumor_from_seed(tissue_data, config):
        logger.error("Failed to initialize active tumor seed. Aborting angiogenesis.")
        return base_vascular_tree.copy()

    angiogenic_graph = base_vascular_tree.copy()
    # Pass next_synthetic_node_id as a list so its modification is seen by caller
    max_id_num = 0
    for node_id_str_val in angiogenic_graph.nodes():
        if isinstance(node_id_str_val, str) and node_id_str_val.startswith('s_'):
            try: max_id_num = max(max_id_num, int(node_id_str_val.split('_')[1]))
            except (ValueError, IndexError): pass
    next_synthetic_node_id_ref = [max_id_num + 10000] # List to pass by reference
    
    active_angiogenic_terminals: List[GBOIterationData] = []

    for macro_iter in range(num_macro_iterations):
        logger.info(f"===== Macro Iteration {macro_iter + 1} / {num_macro_iterations} =====")

        any_tumor_growth_this_macro = False
        for _ in range(tumor_growth_steps_per_macro):
            update_tumor_rim_and_core(tissue_data, config)
            if grow_tumor_mass_within_defined_segmentation(tissue_data, config): any_tumor_growth_this_macro = True
            else: break 
        
        update_tumor_rim_and_core(tissue_data, config); update_metabolic_demand_for_tumor(tissue_data, config)
        update_vegf_field_rim_driven(tissue_data, config)
        coopt_and_modify_vessels(angiogenic_graph, tissue_data, config)

        for ag_step in range(angiogenesis_steps_per_macro):
            logger.debug(f"  Angiogenesis Step {ag_step + 1} (Active Tips Before Sprouting: {len(active_angiogenic_terminals)})")
            
            # --- 2a. Sprouting ---
            new_sprouts_info = find_angiogenic_sprouting_candidates(angiogenic_graph, tissue_data, config)
            if new_sprouts_info:
                logger.debug(f"    Found {len(new_sprouts_info)} new sprout candidates this AG step.")

            for parent_u, parent_v, sprout_origin, sprout_dir in new_sprouts_info:
                bif_node_id = f"s_{next_synthetic_node_id_ref[0]}"; next_synthetic_node_id_ref[0] += 1
                
                parent_u_data = angiogenic_graph.nodes[parent_u]
                parent_v_data = angiogenic_graph.nodes[parent_v] # Get parent_v data as well
                parent_u_radius = parent_u_data['radius']
                
                # Determine vessel_origin_type for the new bifurcation node
                # If parent_u was already a tumor vessel (coopted or angiogenic), the bif is too.
                # Otherwise, it's a bifurcation on a healthy vessel that's now leading to tumor growth.
                bif_origin_type = parent_u_data.get('vessel_origin_type', 'healthy_parent_of_sprout')
                if parent_u_data.get('is_tumor_vessel'):
                    bif_origin_type = parent_u_data.get('vessel_origin_type', 'coopted_healthy') # Default if type was missing

                data_structures.add_node_to_graph(
                    angiogenic_graph, bif_node_id,
                    pos=sprout_origin,
                    radius=parent_u_radius, # Bifurcation point takes radius of the parent segment it's on
                    type='angiogenic_bifurcation',
                    is_tumor_vessel=True, # The bifurcation itself is part of the tumor response
                    vessel_origin_type=bif_origin_type
                )
                
                # Get original edge data before removing
                # Important: Check if edge still exists, could have been modified by another sprout from same segment in same AG step (unlikely but good check)
                if not angiogenic_graph.has_edge(parent_u, parent_v):
                    logger.warning(f"Sprouting target edge {parent_u}-{parent_v} no longer exists. Skipping this sprout.")
                    # Rollback bif_node_id? Or just let it be an isolated node that might get pruned.
                    # For now, continue, but this indicates a potential complex interaction.
                    # To properly handle, would need to process sprouts sequentially and update graph immediately.
                    # Current find_angiogenic_sprouting_candidates finds all then processes.
                    if angiogenic_graph.has_node(bif_node_id): angiogenic_graph.remove_node(bif_node_id) # Clean up unused bif
                    next_synthetic_node_id_ref[0] -=1 # Decrement counter
                    continue

                edge_data_orig = angiogenic_graph.edges[parent_u, parent_v].copy()
                angiogenic_graph.remove_edge(parent_u, parent_v)

                # Add new segments: parent_u -> bif_node_id and bif_node_id -> parent_v
                # These new segments inherit properties and get updated lengths/radii
                data_structures.add_edge_to_graph(angiogenic_graph, parent_u, bif_node_id, **edge_data_orig)
                angiogenic_graph.edges[parent_u, bif_node_id]['length'] = utils.distance(parent_u_data['pos'], sprout_origin)
                angiogenic_graph.edges[parent_u, bif_node_id]['radius'] = parent_u_radius # Takes radius of parent_u

                data_structures.add_edge_to_graph(angiogenic_graph, bif_node_id, parent_v, **edge_data_orig)
                angiogenic_graph.edges[bif_node_id, parent_v]['length'] = utils.distance(sprout_origin, parent_v_data['pos'])
                angiogenic_graph.edges[bif_node_id, parent_v]['radius'] = parent_u_radius # New segment from bif also takes bif radius

                # Mark these split segments as tumor vessels if the original parent was, or if the bif is
                # The bifurcation node itself is marked is_tumor_vessel=True
                # Segments connected to it that are part of the original path should also be marked.
                perm_factor_to_set = default_permeability_factor # Default for new tumor-related segments
                if parent_u_data.get('is_tumor_vessel'):
                    # If parent_u was already a tumor vessel, its perm factor might be already set
                    perm_factor_to_set = edge_data_orig.get('permeability_Lp_factor', default_permeability_factor)

                for e_start, e_end in [(parent_u, bif_node_id), (bif_node_id, parent_v)]:
                    angiogenic_graph.edges[e_start, e_end]['is_tumor_vessel'] = True # Part of the angiogenic event path
                    angiogenic_graph.edges[e_start, e_end]['permeability_Lp_factor'] = perm_factor_to_set


                # Create the new angiogenic sprout (terminal node and its GBOIterationData)
                sprout_tip_id = f"s_{next_synthetic_node_id_ref[0]}"; next_synthetic_node_id_ref[0] += 1
                sprout_tip_pos = sprout_origin + sprout_dir * initial_sprout_length
                
                # Initial flow for angiogenic sprout can be very small or based on a minimal tumor demand
                sprout_initial_flow = DEFAULT_MIN_TUMOR_TERMINAL_DEMAND 
                
                sprout_gbo = GBOIterationData(
                    terminal_id=sprout_tip_id,
                    pos=sprout_tip_pos,
                    radius=initial_sprout_radius,
                    flow=sprout_initial_flow, 
                    parent_id=bif_node_id
                )
                sprout_gbo.length_from_parent = initial_sprout_length
                active_angiogenic_terminals.append(sprout_gbo)

                data_structures.add_node_to_graph(
                    angiogenic_graph, sprout_tip_id,
                    pos=sprout_tip_pos,
                    radius=initial_sprout_radius,
                    type='angiogenic_terminal',
                    is_tumor_vessel=True,
                    vessel_origin_type='angiogenic_sprout', # Clearly mark its origin
                    parent_id=bif_node_id, 
                    Q_flow=sprout_gbo.flow
                )
                data_structures.add_edge_to_graph(
                    angiogenic_graph, bif_node_id, sprout_tip_id,
                    length=initial_sprout_length,
                    radius=initial_sprout_radius, # Edge to new tip takes tip's radius
                    type='angiogenic_segment',
                    is_tumor_vessel=True,
                    permeability_Lp_factor=default_permeability_factor # New angiogenic segments are leaky
                )
                logger.debug(f"    Created new sprout: {sprout_tip_id} from new bif {bif_node_id} on original edge {parent_u}-{parent_v}.")
            
            
            # --- Growth of Active Angiogenic Terminals ---
            next_iter_active_terminals_this_ag_step = []
            
            # Prepare KDTree for anastomosis (only if there are terminals and potential targets)
            vessel_kdtree = None
            segment_midpoints_data = []
            if active_angiogenic_terminals and angiogenic_graph.number_of_edges() > 0:
                midpoints_pos_list = []
                for u, v, data in angiogenic_graph.edges(data=True):
                    # Exclude very new segments connected to active tips to avoid self-anastomosis with parent segment immediately
                    # This check might need refinement
                    is_parent_of_active_tip = any(term.parent_id == u and term.id == v for term in active_angiogenic_terminals)
                    if not is_parent_of_active_tip:
                        mid_pos = (angiogenic_graph.nodes[u]['pos'] + angiogenic_graph.nodes[v]['pos']) / 2.0
                        midpoints_pos_list.append(mid_pos)
                        segment_midpoints_data.append({'pos': mid_pos, 'u': u, 'v': v, 'radius': data.get('radius', constants.MIN_VESSEL_RADIUS_MM)})
                if midpoints_pos_list:
                    vessel_kdtree = KDTree(np.array(midpoints_pos_list))

            newly_branched_terminals_this_ag_step = [] # To hold children from branching
            for term_gbo in active_angiogenic_terminals:
                if term_gbo.stop_growth: continue
                
                # Attempt Anastomosis
                if attempt_anastomosis_tip_to_segment(term_gbo, angiogenic_graph, vessel_kdtree, segment_midpoints_data, config, next_synthetic_node_id_ref):
                    # term_gbo.stop_growth is set by the function
                    continue # Fused, so process next terminal

                # Attempt Branching (Simplified Stochastic)
                current_pos_vox_int = np.round(utils.world_to_voxel(term_gbo.pos, tissue_data['affine'])).astype(int)
                if not utils.is_voxel_in_bounds(current_pos_vox_int, tissue_data['VEGF_field'].shape):
                    term_gbo.stop_growth = True; continue
                
                vegf_at_tip = tissue_data['VEGF_field'][tuple(current_pos_vox_int)]
                normalized_vegf = vegf_at_tip / (np.max(tissue_data['VEGF_field']) + constants.EPSILON)
                prob_branch = branch_probability_factor_vegf * normalized_vegf
                
                if np.random.rand() < prob_branch:
                    logger.debug(f"Angiogenic terminal {term_gbo.id} branching (VEGF: {vegf_at_tip:.2f}, P_branch: {prob_branch:.2f})")
                    # Change current terminal to bifurcation
                    angiogenic_graph.nodes[term_gbo.id]['type'] = 'angiogenic_bifurcation'
                    # Create two new child GBOIterationData objects
                    parent_growth_dir = utils.normalize_vector(term_gbo.pos - angiogenic_graph.nodes[term_gbo.parent_id]['pos'])
                    
                    for i_child in range(2):
                        child_id = f"s_{next_synthetic_node_id_ref[0]}"; next_synthetic_node_id_ref[0] += 1
                        # Perturb direction slightly
                        angle_offset = np.deg2rad(np.random.uniform(-branch_angle_spread_deg/2, branch_angle_spread_deg/2))
                        # This is a 2D rotation logic, needs proper 3D random vector perturbation
                        # For simplicity, create a random perturbation and add to parent_growth_dir then renormalize
                        random_perturb = utils.normalize_vector(np.random.rand(3) - 0.5) * 0.5 # Scale of perturbation
                        child_dir = utils.normalize_vector(parent_growth_dir + random_perturb)
                        if np.linalg.norm(child_dir) < constants.EPSILON: child_dir = parent_growth_dir # Fallback

                        child_pos = term_gbo.pos + child_dir * extension_step_length # Initial small extension
                        child_radius = term_gbo.radius # Or slightly smaller
                        child_flow = term_gbo.flow / 2 # Split flow (very rough)

                        child_gbo = GBOIterationData(child_id, child_pos, child_radius, child_flow, parent_id=term_gbo.id)
                        child_gbo.length_from_parent = extension_step_length
                        newly_branched_terminals_this_ag_step.append(child_gbo)

                        data_structures.add_node_to_graph(angiogenic_graph, child_id, pos=child_pos, radius=child_radius,
                                                          type='angiogenic_terminal', is_tumor_vessel=True, vessel_origin_type='angiogenic_sprout',
                                                          parent_id=term_gbo.id, Q_flow=child_flow)
                        data_structures.add_edge_to_graph(angiogenic_graph, term_gbo.id, child_id, length=extension_step_length,
                                                          radius=child_radius, type='angiogenic_segment', is_tumor_vessel=True,
                                                          permeability_Lp_factor=cooption_params.get("permeability_Lp_factor_tumor", 10.0))
                    term_gbo.stop_growth = True # Parent tip stops, children take over
                    continue

                # Extension (if not anastomosed or branched)
                grad_ax0_f, grad_ax1_f, grad_ax2_f = np.gradient(tissue_data['VEGF_field'])
                g_ax0 = grad_ax0_f[tuple(current_pos_vox_int)]; g_ax1 = grad_ax1_f[tuple(current_pos_vox_int)]; g_ax2 = grad_ax2_f[tuple(current_pos_vox_int)]
                growth_dir_vox = np.array([g_ax0, g_ax1, g_ax2])
                growth_dir_world = utils.normalize_vector(tissue_data['affine'][:3,:3] @ growth_dir_vox)

                if np.linalg.norm(growth_dir_world) > constants.EPSILON:
                    new_pos = term_gbo.pos + growth_dir_world * extension_step_length
                    old_tip_id = term_gbo.id
                    angiogenic_graph.nodes[old_tip_id]['type'] = 'angiogenic_segment_point'
                    new_tip_id = f"s_{next_synthetic_node_id_ref[0]}"; next_synthetic_node_id_ref[0] += 1
                    
                    term_gbo.id = new_tip_id; term_gbo.pos = new_pos; term_gbo.parent_id = old_tip_id
                    term_gbo.length_from_parent = extension_step_length
                    
                    data_structures.add_node_to_graph(angiogenic_graph, new_tip_id, pos=new_pos, radius=term_gbo.radius,
                                                      type='angiogenic_terminal', is_tumor_vessel=True, vessel_origin_type='angiogenic_sprout',
                                                      parent_id=old_tip_id, Q_flow=term_gbo.flow)
                    data_structures.add_edge_to_graph(angiogenic_graph, old_tip_id, new_tip_id, length=extension_step_length,
                                                      radius=term_gbo.radius, type='angiogenic_segment', is_tumor_vessel=True,
                                                      permeability_Lp_factor=cooption_params.get("permeability_Lp_factor_tumor", 10.0))
                    next_iter_active_terminals_this_ag_step.append(term_gbo)
                else:
                    next_iter_active_terminals_this_ag_step.append(term_gbo) # Stalled, keep for next try
            
            active_angiogenic_terminals = [t for t in next_iter_active_terminals_this_ag_step if not t.stop_growth]
            active_angiogenic_terminals.extend(newly_branched_terminals_this_ag_step) # Add new children from branching

            if not active_angiogenic_terminals and not new_sprouts_info : break # from ag_steps
        
        # --- Flow Solve & Adaptation ---
        if (macro_iter + 1) % flow_solve_interval_macro == 0:
            logger.info(f"Running global flow solver and adaptation (Macro Iter {macro_iter + 1})...")
            # ... (Flow solve and differentiated radius adaptation logic - as in previous complete version) ...
            # This part needs careful Q_flow assignment to all terminals (healthy, coopted, angiogenic)
            all_terminals_in_graph = [nid for nid, data in angiogenic_graph.nodes(data=True) if angiogenic_graph.out_degree(nid) == 0 and angiogenic_graph.in_degree(nid) > 0]
            for term_id in all_terminals_in_graph:
                term_node_data = angiogenic_graph.nodes[term_id]
                term_pos_vox = np.round(utils.world_to_voxel(term_node_data['pos'], tissue_data['affine'])).astype(int)
                demand = term_node_data.get('Q_flow', 0.0) # Keep existing Q_flow if not overridden

                if utils.is_voxel_in_bounds(term_pos_vox, tissue_data['shape']):
                    if tissue_data.get('Tumor') is not None and tissue_data['Tumor'][tuple(term_pos_vox)]:
                        # TODO: Better demand based on local tumor voxel demand sum
                        demand = config_manager.get_param(config, "tumor_angiogenesis.min_tumor_terminal_demand", DEFAULT_MIN_TUMOR_TERMINAL_DEMAND)
                    elif not term_node_data.get('is_tumor_vessel'): # Healthy terminal in healthy tissue
                        # This demand should come from GBO's Voronoi refinement for healthy tissue
                        # For now, if not set, use a default. This part needs robust integration with healthy GBO state.
                        demand = term_node_data.get('Q_flow', constants.INITIAL_TERMINAL_FLOW_Q)
                term_node_data['Q_flow'] = demand
            
            temp_graph_for_solver = angiogenic_graph.copy()
            solved_graph = perfusion_solver_func(temp_graph_for_solver, config, None, None)

            if solved_graph:
                angiogenic_graph = solved_graph
                min_r_healthy = config_manager.get_param(config, "vascular_properties.min_radius")
                k_m = config_manager.get_param(config, "vascular_properties.k_murray_scaling_factor")
                m_exp = config_manager.get_param(config, "vascular_properties.murray_law_exponent")
                adapt_params = main_params.get("adaptation", {})
                tumor_radius_factor = adapt_params.get("tumor_radius_factor", 1.0)
                min_r_tumor = adapt_params.get("min_tumor_vessel_radius_mm", min_r_healthy * 1.1)

                for node_id, data in angiogenic_graph.nodes(data=True):
                    if data.get('type') == 'measured_root' or data.get('is_flow_root'): continue
                    
                    actual_node_flow = 0.0 # Recalculate based on solved edge flows
                    if angiogenic_graph.out_degree(node_id) == 0 and angiogenic_graph.in_degree(node_id) > 0: # Sink
                        for _, _, edge_data_in in angiogenic_graph.in_edges(node_id, data=True):
                            actual_node_flow += abs(edge_data_in.get('flow_solver', 0.0))
                    elif angiogenic_graph.out_degree(node_id) > 0: # Source-like or bifurcation
                        for _, _, edge_data_out in angiogenic_graph.out_edges(node_id, data=True):
                            actual_node_flow += abs(edge_data_out.get('flow_solver', 0.0))
                    
                    if abs(actual_node_flow) > constants.EPSILON:
                        target_r = k_m * (abs(actual_node_flow) ** (1.0 / m_exp))
                        if data.get('is_tumor_vessel'):
                            target_r *= tumor_radius_factor
                            data['radius'] = max(min_r_tumor, target_r)
                        else: data['radius'] = max(min_r_healthy, target_r)
                    else: data['radius'] = min_r_tumor if data.get('is_tumor_vessel') else min_r_healthy
                logger.info("Global flow solve and differentiated radius adaptation complete.")


        if (macro_iter + 1) % save_interval_macro == 0:
            # ... (saving logic as before) ...
            logger.info(f"Saving intermediate state for macro iteration {macro_iter + 1}...")
            io_utils.save_vascular_tree_vtp(angiogenic_graph, os.path.join(output_dir, f"angiogenesis_iter_{macro_iter+1}.vtp"))
            io_utils.save_nifti_image(tissue_data['Tumor'].astype(np.uint8), tissue_data['affine'], os.path.join(output_dir, f"active_tumor_mask_iter_{macro_iter+1}.nii.gz"))
            if 'VEGF_field' in tissue_data and tissue_data['VEGF_field'] is not None:
                 io_utils.save_nifti_image(tissue_data['VEGF_field'].astype(np.float32), tissue_data['affine'], os.path.join(output_dir, f"vegf_field_iter_{macro_iter+1}.nii.gz"))

        if np.all(tissue_data['Tumor'] == tissue_data['Tumor_Max_Extent']) and not any_tumor_growth_this_macro:
            logger.info(f"Tumor filled Tumor_Max_Extent. Stopping macro iterations at {macro_iter + 1}.")
            break

    logger.info(f"--- Tumor Angiogenesis (Fixed Extent) Finished. Final graph: {angiogenic_graph.number_of_nodes()} N, {angiogenic_graph.number_of_edges()} E ---")
    return angiogenic_graph
--- File: ./utils.py ---
# src/utils.py
import numpy as np
import random
import logging
import os
import shutil
from typing import Tuple 

logger = logging.getLogger(__name__)

def set_rng_seed(seed: int):
    """Sets the random seed for Python's random, NumPy, and potentially other libraries."""
    random.seed(seed)
    np.random.seed(seed)
    logger.info(f"Random Number Generator seed set to: {seed}")
    # Add other libraries like TensorFlow/PyTorch if used:
    # tf.random.set_seed(seed)
    # torch.manual_seed(seed)

def get_voxel_volume_from_affine(affine: np.ndarray) -> float:
    """
    Calculates the volume of a single voxel from the NIfTI affine matrix.
    Assumes the affine matrix maps voxel coordinates to physical coordinates.
    The volume is the absolute value of the determinant of the first 3x3 submatrix.

    Args:
        affine (np.ndarray): The 4x4 affine matrix.

    Returns:
        float: The volume of a single voxel.
    """
    return abs(np.linalg.det(affine[:3, :3]))

def voxel_to_world(voxel_coords: np.ndarray, affine: np.ndarray) -> np.ndarray:
    """
    Converts voxel coordinates to world (physical) coordinates.

    Args:
        voxel_coords (np.ndarray): A (N, 3) array of voxel coordinates (i, j, k).
        affine (np.ndarray): The 4x4 NIfTI affine matrix.

    Returns:
        np.ndarray: A (N, 3) array of world coordinates (x, y, z).
    """
    voxel_coords = np.asarray(voxel_coords)
    if voxel_coords.ndim == 1:
        voxel_coords = voxel_coords.reshape(1, -1)
    
    # Add homogeneous coordinate
    homogeneous_coords = np.hstack((voxel_coords, np.ones((voxel_coords.shape[0], 1))))
    
    # Apply affine transformation
    world_coords_homogeneous = homogeneous_coords @ affine.T
    
    return world_coords_homogeneous[:, :3]

def world_to_voxel(world_coords: np.ndarray, affine: np.ndarray) -> np.ndarray:
    """
    Converts world (physical) coordinates to voxel coordinates.
    Uses the inverse of the affine matrix. Resulting voxel coordinates might be fractional.

    Args:
        world_coords (np.ndarray): A (N, 3) array of world coordinates (x, y, z).
        affine (np.ndarray): The 4x4 NIfTI affine matrix.

    Returns:
        np.ndarray: A (N, 3) array of voxel coordinates (i, j, k).
    """
    world_coords = np.asarray(world_coords)
    if world_coords.ndim == 1:
        world_coords = world_coords.reshape(1, -1)

    # Add homogeneous coordinate
    homogeneous_coords = np.hstack((world_coords, np.ones((world_coords.shape[0], 1))))
    
    # Invert affine matrix
    inv_affine = np.linalg.inv(affine)
    
    # Apply inverse affine transformation
    voxel_coords_homogeneous = homogeneous_coords @ inv_affine.T
    
    return voxel_coords_homogeneous[:, :3]

def distance_squared(p1: np.ndarray, p2: np.ndarray) -> float:
    """Computes the squared Euclidean distance between two 3D points."""
    return np.sum((p1 - p2)**2)

def distance(p1: np.ndarray, p2: np.ndarray) -> float:
    """Computes the Euclidean distance between two 3D points."""
    return np.sqrt(np.sum((p1 - p2)**2))

def normalize_vector(v: np.ndarray) -> np.ndarray:
    """Normalizes a vector."""
    norm = np.linalg.norm(v)
    if norm == 0:
        return v
    return v / norm

def create_output_directory(base_dir: str, sim_name: str = "gbo_sim", timestamp: bool = True) -> str:
    """
    Creates a unique output directory.
    Example: base_dir/YYYYMMDD_HHMMSS_sim_name or base_dir/sim_name
    """
    from datetime import datetime
    if timestamp:
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        dir_name = f"{ts}_{sim_name}"
    else:
        dir_name = sim_name
    
    full_path = os.path.join(base_dir, dir_name)
    
    if os.path.exists(full_path):
        # Option 1: Overwrite (dangerous)
        # shutil.rmtree(full_path) 
        # Option 2: Add a suffix
        count = 1
        new_full_path = f"{full_path}_{count}"
        while os.path.exists(new_full_path):
            count += 1
            new_full_path = f"{full_path}_{count}"
        full_path = new_full_path
        logger.warning(f"Output directory {os.path.join(base_dir, dir_name)} existed. Using {full_path} instead.")

    os.makedirs(full_path, exist_ok=True)
    logger.info(f"Created output directory: {full_path}")
    return full_path

def is_voxel_in_bounds(voxel_coord: np.ndarray, shape: Tuple[int, ...]) -> bool:
    """Checks if a voxel coordinate is within the bounds of a given shape."""
    voxel_coord = np.asarray(voxel_coord) # Ensure it's a numpy array
    if voxel_coord.ndim == 0 or voxel_coord.shape[0] != len(shape): # Check for scalar or mismatched dimensions
        return False
    return all(0 <= voxel_coord[d] < shape[d] for d in range(len(shape)))



if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    # Test RNG seed
    set_rng_seed(123)
    print(f"Random float after seed 123: {random.random()}")
    set_rng_seed(123)
    print(f"Random float after seed 123 again: {random.random()}")
    print(f"Numpy random array after seed 123: {np.random.rand(3)}")
    set_rng_seed(123)
    print(f"Numpy random array after seed 123 again: {np.random.rand(3)}")

    # Test affine transformations
    # A typical NIfTI affine for 1mm isotropic voxels, origin at corner
    dummy_affine = np.array([
        [1.0, 0.0, 0.0, 0.0],
        [0.0, 1.0, 0.0, 0.0],
        [0.0, 0.0, 1.0, 0.0],
        [0.0, 0.0, 0.0, 1.0]
    ])
    # A more realistic affine (e.g. -1mm x, 1mm y, 1mm z, with an offset)
    # RAS orientation: X points Left to Right, Y Posterior to Anterior, Z Inferior to Superior
    # If voxel (0,0,0) is at world (-90, 90, -120) and voxels are 1mm:
    # This means i maps to -X, j maps to +Y, k maps to +Z (LPI orientation for data array)
    # If data array is stored radiological (i from R->L), then first column of affine is positive.
    # Assuming standard interpretation (voxel index increases, world coordinate increases along axis basis vector)
    # Let's use a simple affine for testing:
    test_affine = np.array([
        [-1.0, 0.0, 0.0, 100.0],  # Voxel i -> World -x direction; (0,0,0) maps to x=100
        [0.0, 1.0, 0.0, -50.0],  # Voxel j -> World +y direction; (0,0,0) maps to y=-50
        [0.0, 0.0, 2.0, -20.0],  # Voxel k -> World +z direction, 2mm thick; (0,0,0) maps to z=-20
        [0.0, 0.0, 0.0, 1.0]
    ])

    print(f"Voxel volume for test_affine: {get_voxel_volume_from_affine(test_affine)} mm^3 (expected 2)")

    voxel_pts = np.array([[0,0,0], [10,20,5]])
    world_pts = voxel_to_world(voxel_pts, test_affine)
    print(f"Voxel points:\n{voxel_pts}")
    print(f"Converted to World points:\n{world_pts}")
    # Expected for [0,0,0]: [100, -50, -20]
    # Expected for [10,20,5]: [-1*10+100, 1*20-50, 2*5-20] = [90, -30, -10]

    reconverted_voxel_pts = world_to_voxel(world_pts, test_affine)
    print(f"Reconverted to Voxel points:\n{reconverted_voxel_pts}")
    assert np.allclose(voxel_pts, reconverted_voxel_pts), "Voxel-World-Voxel conversion failed"

    # Test distance
    p1 = np.array([0,0,0])
    p2 = np.array([3,4,0])
    print(f"Distance squared between {p1} and {p2}: {distance_squared(p1, p2)} (expected 25)")
    print(f"Distance between {p1} and {p2}: {distance(p1, p2)} (expected 5)")

    # Test output directory
    base_output = "temp_test_output"
    os.makedirs(base_output, exist_ok=True)
    path1 = create_output_directory(base_output, "my_sim")
    path2 = create_output_directory(base_output, "my_sim") # Should create my_sim_1
    print(f"Path1: {path1}")
    print(f"Path2: {path2}")
    shutil.rmtree(base_output)
    print("Cleaned up temp_test_output directory.")
--- File: ./io_utils.py ---
# src/io_utils.py
import nibabel as nib
import numpy as np
import pyvista as pv
import networkx as nx
import os
import logging
import yaml
from typing import Any, Union, Dict, List, Tuple

logger = logging.getLogger(__name__)

def load_nifti_image(filepath: str) -> tuple[np.ndarray, np.ndarray, Any] | tuple[None, None, None]:
    """
    Loads a NIfTI image.

    Args:
        filepath (str): Path to the .nii or .nii.gz file.

    Returns:
        tuple: (data_array, affine_matrix, header) or (None, None, None) if loading fails.
               data_array is usually in (L,P,I) or (R,A,S) depending on how it was saved.
               Affine maps voxel indices to world space (often RAS).
    """
    if not os.path.exists(filepath):
        logger.warning(f"NIfTI file not found: {filepath}. Skipping.")
        return None, None, None
    try:
        img = nib.load(filepath)
        data = img.get_fdata()
        affine = img.affine
        header = img.header
        logger.info(f"Loaded NIfTI image: {filepath}, Shape: {data.shape}, Voxel size from affine: {np.diag(affine)[:3]}")
        return data.astype(np.float32), affine, header # Cast to float for calculations
    except Exception as e:
        logger.error(f"Error loading NIfTI file {filepath}: {e}")
        return None, None, None

def save_nifti_image(data_array: np.ndarray, affine: np.ndarray, filepath: str, header: nib.Nifti1Header = None):
    """
    Saves a NumPy array as a NIfTI image.

    Args:
        data_array (np.ndarray): The image data.
        affine (np.ndarray): The affine matrix for the image.
        filepath (str): Path to save the .nii or .nii.gz file.
        header (nib.Nifti1Header, optional): NIfTI header. If None, a minimal one is created.
    """
    try:
        # Ensure data type is compatible, e.g. float32 or int16
        # Nifti1Image constructor will handle appropriate dtype based on data.
        # If data is boolean, convert to int8 or uint8
        if data_array.dtype == bool:
            data_array = data_array.astype(np.uint8)
            
        img = nib.Nifti1Image(data_array, affine, header=header)
        nib.save(img, filepath)
        logger.info(f"Saved NIfTI image to: {filepath}")
    except Exception as e:
        logger.error(f"Error saving NIfTI file {filepath}: {e}")
        raise

def load_arterial_centerlines_vtp(filepath: str) -> pv.PolyData | None:
    """
    Loads arterial centerlines from a VTP file.
    Assumes the VTP file contains points and lines representing vessel segments.
    It should ideally have a 'radius' point data array.

    Args:
        filepath (str): Path to the .vtp file.

    Returns:
        pyvista.PolyData: The loaded PolyData object or None if loading fails.
    """
    if not os.path.exists(filepath):
        logger.warning(f"Arterial centerline file not found: {filepath}. Skipping.")
        return None
    try:
        mesh = pv.read(filepath)
        logger.info(f"Loaded arterial centerlines from VTP: {filepath}")
        if 'radius' not in mesh.point_data:
            logger.warning(f"VTP file {filepath} does not contain 'radius' point data. Defaulting or errors might occur.")
        # Could add more checks here, e.g., for line connectivity
        return mesh
    except Exception as e:
        logger.error(f"Error loading VTP file {filepath}: {e}")
        return None

def load_arterial_centerlines_txt(filepath: str, radius_default: float = 0.1) -> pv.PolyData | None:
    """
    Loads arterial centerlines from a TXT file and converts to PyVista PolyData.
    Expected TXT format:
    Each line: x y z [radius]
    If radius is not present, radius_default is used.
    Segments are assumed to connect consecutive points.
    A more robust format might specify connectivity explicitly. For now, assume polylines.

    Args:
        filepath (str): Path to the .txt file.
        radius_default (float): Default radius if not specified in the file.

    Returns:
        pyvista.PolyData: A PolyData object representing the centerlines, or None if loading fails.
    """
    if not os.path.exists(filepath):
        logger.warning(f"Arterial centerline TXT file not found: {filepath}. Skipping.")
        return None
    
    points = []
    radii = []
    try:
        with open(filepath, 'r') as f:
            for line_num, line in enumerate(f):
                line = line.strip()
                if not line or line.startswith('#'): # Skip empty lines or comments
                    continue
                parts = list(map(float, line.split()))
                if len(parts) == 3:
                    points.append(parts)
                    radii.append(radius_default)
                elif len(parts) == 4:
                    points.append(parts[:3])
                    radii.append(parts[3])
                else:
                    logger.warning(f"Skipping malformed line {line_num+1} in {filepath}: {line}")
        
        if not points:
            logger.error(f"No valid points found in TXT file: {filepath}")
            return None

        points_np = np.array(points)
        radii_np = np.array(radii)

        # Create PolyData: assumes a single polyline for simplicity
        # For multiple disconnected arteries, the TXT format would need to be richer or
        # processed to identify separate polylines.
        num_points = len(points_np)
        lines = np.empty((num_points - 1, 3), dtype=int)
        lines[:, 0] = 2  # Each line segment has 2 points
        lines[:, 1] = np.arange(num_points - 1)
        lines[:, 2] = np.arange(1, num_points)
        
        poly = pv.PolyData(points_np, lines=lines)
        poly.point_data['radius'] = radii_np
        
        logger.info(f"Loaded arterial centerlines from TXT: {filepath}, {num_points} points.")
        return poly

    except Exception as e:
        logger.error(f"Error loading TXT file {filepath}: {e}")
        return None


def save_vascular_tree_vtp(graph: nx.DiGraph, filepath: str,
                           pos_attr='pos', radius_attr='radius', pressure_attr='pressure', flow_attr='flow_solver'):
    """
    Saves a vascular tree (NetworkX graph) to a VTP file.
    Nodes store positions and radii. Edges define connectivity.
    """
    points = []
    point_radii = []
    point_pressures = []
    lines_connectivity = [] # Changed name for clarity, this is for pv.PolyData(points, lines=HERE)
    edge_flows = [] 

    node_to_idx = {node_id: i for i, node_id in enumerate(graph.nodes())}

    for node_id, data in graph.nodes(data=True):
        if pos_attr not in data:
            logger.warning(f"Node {node_id} missing '{pos_attr}' attribute. Skipping for point data.")
            continue
        points.append(data[pos_attr])
        point_radii.append(data.get(radius_attr, 0.0))
        point_pressures.append(data.get(pressure_attr, np.nan)) 

    if not points:
        logger.error("No points to save in the vascular tree. VTP file will be empty or invalid.")
        empty_poly = pv.PolyData()
        empty_poly.save(filepath)
        logger.error(f"Saved an empty VTP file to: {filepath} due to no valid points in the graph.")
        return

    # Build the lines array for PolyData constructor
    # Format: [n_points_in_line0, pt0_idx, pt1_idx, n_points_in_line1, ptA_idx, ptB_idx, ...]
    raw_lines_for_pv = []
    for u, v, data in graph.edges(data=True):
        if u in node_to_idx and v in node_to_idx:
            raw_lines_for_pv.extend([2, node_to_idx[u], node_to_idx[v]]) # Each line segment has 2 points
            edge_flows.append(data.get(flow_attr, np.nan)) 
        else:
            logger.warning(f"Edge ({u}-{v}) references missing node. Skipping this edge for line connectivity.")

    # Create PolyData object
    # If there are lines, pass them to the constructor.
    # Otherwise, it's just a point cloud.
    if raw_lines_for_pv:
        poly_data = pv.PolyData(np.array(points), lines=np.array(raw_lines_for_pv))
    else:
        poly_data = pv.PolyData(np.array(points)) # Will be a point cloud if no edges

    logger.debug(f"PolyData created. Number of points: {poly_data.n_points}, Number of cells (lines): {poly_data.n_cells}")
    logger.debug(f"Number of edge_flows collected: {len(edge_flows)}")
    
    # Add point data
    if points: # Check if points list is not empty before trying to assign
        poly_data.point_data[radius_attr] = np.array(point_radii)
        if any(not np.isnan(p) for p in point_pressures): 
            poly_data.point_data[pressure_attr] = np.array(point_pressures)
    
    # Add cell data (flow) only if there are cells and corresponding flow data
    if edge_flows and poly_data.n_cells > 0:
        if poly_data.n_cells == len(edge_flows):
            poly_data.cell_data[flow_attr] = np.array(edge_flows)
        else:
            # This case should ideally not be hit if graph processing and polydata creation are correct
            logger.error(
                f"Critical mismatch assigning cell data! "
                f"PolyData n_cells: {poly_data.n_cells}, "
                f"Number of flow values: {len(edge_flows)}. "
                f"Flow data will NOT be saved for cells."
            )
            # Decide: either don't add flow data, or pad/truncate (not ideal)
            # For now, we won't add it if there's a mismatch.
    
    try:
        poly_data.save(filepath)
        logger.info(f"Saved vascular tree to VTP: {filepath}")
    except Exception as e:
        logger.error(f"Error saving vascular tree to VTP {filepath}: {e}")
        raise

def save_simulation_parameters(config: dict, filepath: str):
    """Saves the simulation configuration to a YAML file."""
    try:
        with open(filepath, 'w') as f:
            yaml.dump(config, f, sort_keys=False, indent=4)
        logger.info(f"Saved simulation parameters to: {filepath}")
    except Exception as e:
        logger.error(f"Error saving simulation parameters to {filepath}: {e}")
        raise


if __name__ == '__main__':
    # Setup basic logging for testing
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # Create dummy data directory
    test_data_dir = "temp_io_test_data"
    os.makedirs(test_data_dir, exist_ok=True)

    # --- Test NIfTI I/O ---
    dummy_nifti_path = os.path.join(test_data_dir, "dummy.nii.gz")
    shape = (10, 10, 10)
    affine = np.eye(4)
    affine[0,0] = affine[1,1] = affine[2,2] = 0.5 # 0.5mm isotropic voxels
    data = np.random.rand(*shape).astype(np.float32)
    
    print(f"\n--- Testing NIfTI I/O ---")
    save_nifti_image(data, affine, dummy_nifti_path)
    loaded_data, loaded_affine, _ = load_nifti_image(dummy_nifti_path)
    
    if loaded_data is not None:
        assert np.allclose(data, loaded_data), "NIfTI data mismatch"
        assert np.allclose(affine, loaded_affine), "NIfTI affine mismatch"
        print("NIfTI I/O test successful.")
    else:
        print("NIfTI loading failed.")

    # Test loading non-existent NIfTI
    load_nifti_image("non_existent.nii.gz")


    # --- Test VTP I/O (arterial centerlines) ---
    print(f"\n--- Testing VTP I/O (arterial centerlines) ---")
    dummy_vtp_path = os.path.join(test_data_dir, "dummy_arteries.vtp")
    # Create a simple PyVista PolyData object
    points = np.array([[0,0,0], [1,1,0], [2,0,0]], dtype=float)
    lines = np.array([2, 0, 1, 2, 1, 2]) # Connect point 0-1, then 1-2
    poly = pv.PolyData(points, lines=lines)
    poly.point_data['radius'] = np.array([0.5, 0.4, 0.3])
    poly.save(dummy_vtp_path)
    
    loaded_poly = load_arterial_centerlines_vtp(dummy_vtp_path)
    if loaded_poly:
        assert loaded_poly.n_points == 3, "VTP point count mismatch"
        assert 'radius' in loaded_poly.point_data, "VTP radius data missing"
        print("VTP arterial centerline I/O test successful.")
    else:
        print("VTP loading failed.")
    
    # Test loading non-existent VTP
    load_arterial_centerlines_vtp("non_existent.vtp")

    # --- Test TXT I/O (arterial centerlines) ---
    print(f"\n--- Testing TXT I/O (arterial centerlines) ---")
    dummy_txt_path = os.path.join(test_data_dir, "dummy_arteries.txt")
    with open(dummy_txt_path, "w") as f:
        f.write("# Test TXT file\n")
        f.write("0 0 0 0.5\n")
        f.write("1 1 0 0.4\n")
        f.write("2 0 0\n") # Test with default radius
        f.write("3 1 1 0.2\n")
    
    loaded_poly_txt = load_arterial_centerlines_txt(dummy_txt_path, radius_default=0.1)
    if loaded_poly_txt:
        assert loaded_poly_txt.n_points == 4, "TXT point count mismatch"
        assert 'radius' in loaded_poly_txt.point_data, "TXT radius data missing"
        expected_radii = np.array([0.5, 0.4, 0.1, 0.2])
        assert np.allclose(loaded_poly_txt.point_data['radius'], expected_radii), "TXT radii mismatch"
        print(f"TXT loaded radii: {loaded_poly_txt.point_data['radius']}")
        print("TXT arterial centerline I/O test successful.")
    else:
        print("TXT loading failed.")

    # --- Test Vascular Tree (NetworkX to VTP) Save ---
    print(f"\n--- Testing Vascular Tree (NetworkX to VTP) Save ---")
    graph = nx.DiGraph()
    # Add nodes with positions and radii
    graph.add_node(0, pos=np.array([0,0,0]), radius=0.5, pressure=100.0)
    graph.add_node(1, pos=np.array([1,0,0]), radius=0.4, pressure=90.0)
    graph.add_node(2, pos=np.array([1,1,0]), radius=0.3, pressure=80.0)
    # Add edges with flow
    graph.add_edge(0, 1, flow=10.0)
    graph.add_edge(1, 2, flow=8.0)

    tree_vtp_path = os.path.join(test_data_dir, "vascular_tree.vtp")
    save_vascular_tree_vtp(graph, tree_vtp_path)
    
    # Verify by loading it back with PyVista
    if os.path.exists(tree_vtp_path):
        loaded_tree_poly = pv.read(tree_vtp_path)
        assert loaded_tree_poly.n_points == 3, "Saved tree VTP point count mismatch"
        assert 'radius' in loaded_tree_poly.point_data, "Saved tree VTP radius missing"
        assert 'pressure' in loaded_tree_poly.point_data, "Saved tree VTP pressure missing"
        # Check if flow is present as cell data
        if loaded_tree_poly.n_cells > 0 : # n_cells corresponds to number of lines/edges
             assert 'flow' in loaded_tree_poly.cell_data, "Saved tree VTP flow missing"
        print("Vascular tree (NetworkX to VTP) save test successful.")
    else:
        print("Vascular tree VTP save failed.")
        
    # Test saving an empty graph
    empty_graph = nx.DiGraph()
    empty_tree_vtp_path = os.path.join(test_data_dir, "empty_vascular_tree.vtp")
    save_vascular_tree_vtp(empty_graph, empty_tree_vtp_path)
    if os.path.exists(empty_tree_vtp_path):
        loaded_empty_tree_poly = pv.read(empty_tree_vtp_path)
        assert loaded_empty_tree_poly.n_points == 0, "Empty graph should result in VTP with 0 points."
        print("Saving empty graph to VTP test successful.")

    # --- Test Saving Simulation Parameters ---
    print(f"\n--- Testing Saving Simulation Parameters ---")
    dummy_params_path = os.path.join(test_data_dir, "sim_params.yaml")
    test_config = {"param1": 10, "nested": {"param2": "test"}}
    save_simulation_parameters(test_config, dummy_params_path)
    # Verify by loading
    with open(dummy_params_path, 'r') as f:
        loaded_params = yaml.safe_load(f)
    assert loaded_params["param1"] == 10, "Param save/load mismatch"
    print("Simulation parameter saving test successful.")

    # Clean up dummy data directory
    import shutil
    shutil.rmtree(test_data_dir)
    print(f"\nCleaned up temporary test directory: {test_data_dir}")
--- File: ./data_structures.py ---
# src/data_structures.py
import networkx as nx
import numpy as np
import logging

logger = logging.getLogger(__name__)

# --- Vascular Tree (NetworkX Graph) Conventions ---
# Nodes in the graph represent points in 3D space (e.g., bifurcations, terminals, points along a segment).
# Edges represent vessel segments connecting these points.

# Node Attributes:
# - 'id': (any, unique) Unique identifier for the node. Often the NetworkX node key itself.
# - 'pos': (np.ndarray, shape (3,)) 3D coordinates [x, y, z] in physical units (e.g., mm). REQUIRED.
# - 'radius': (float) Radius of the vessel at this node/point in physical units. REQUIRED for many operations.
# - 'type': (str) Type of node, e.g., 'root', 'bifurcation', 'terminal', 'segment_point'.
# - 'pressure': (float) Blood pressure at this node (computed during perfusion modeling).
# - 'flow_demand': (float) For terminal nodes, the flow Q_i required by its territory.
# - 'territory_voxels': (list or np.ndarray) Indices or coordinates of voxels supplied by this terminal.
# - 'parent_measured_terminal_id': (any) For synthetic terminals, ID of the measured artery terminal they originated from.
# - 'is_tumor_vessel': (bool) True if this node is part of a tumor-induced vessel.

# Edge Attributes (for edge u -> v):
# - 'length': (float) Length of the vessel segment in physical units. Can be calculated from node positions.
# - 'radius': (float) Radius of the segment. Can be average of u and v radii, or u's radius if flow is from u to v.
#           Consistency needed: often derived from flow and Murray's law.
# - 'flow': (float) Blood flow rate through the segment (computed during perfusion modeling).
# - 'resistance': (float) Hydraulic resistance of the segment (computed for perfusion modeling).
# - 'is_tumor_vessel': (bool) True if this segment is part of a tumor-induced vessel.


def create_empty_vascular_graph() -> nx.DiGraph:
    """Creates an empty directed graph for the vascular tree."""
    return nx.DiGraph()

def add_node_to_graph(graph: nx.DiGraph, node_id: any, pos: np.ndarray, radius: float, 
                      node_type: str = 'default', **kwargs):
    """
    Adds a node with standard attributes to the vascular graph.
    
    Args:
        graph (nx.DiGraph): The graph to add the node to.
        node_id (any): Unique ID for the node.
        pos (np.ndarray): 3D position [x,y,z].
        radius (float): Vessel radius at this node.
        node_type (str): Type of node.
        **kwargs: Additional attributes to set for the node.
    """
    if not isinstance(pos, np.ndarray) or pos.shape != (3,):
        raise ValueError("Position 'pos' must be a 3-element NumPy array.")
    if not isinstance(radius, (int, float)) or radius < 0:
        raise ValueError("Radius must be a non-negative number.")

    attrs = {
        'pos': pos,
        'radius': radius,
        'type': node_type,
    }
    attrs.update(kwargs) # Add any extra attributes
    graph.add_node(node_id, **attrs)
    # logger.debug(f"Added node {node_id} with attributes: {attrs}")

def add_edge_to_graph(graph: nx.DiGraph, u_id: any, v_id: any, **kwargs):
    """
    Adds an edge with standard attributes to the vascular graph.
    Length is automatically calculated if node positions exist.
    
    Args:
        graph (nx.DiGraph): The graph to add the edge to.
        u_id (any): ID of the source node.
        v_id (any): ID of the target node.
        **kwargs: Additional attributes to set for the edge.
    """
    if not graph.has_node(u_id) or not graph.has_node(v_id):
        logger.error(f"Cannot add edge ({u_id}-{v_id}): one or both nodes do not exist.")
        raise ValueError(f"Nodes {u_id} or {v_id} not in graph.")

    attrs = {}
    # Calculate length
    pos_u = graph.nodes[u_id].get('pos')
    pos_v = graph.nodes[v_id].get('pos')
    if pos_u is not None and pos_v is not None:
        length = np.linalg.norm(pos_u - pos_v)
        attrs['length'] = length
    else:
        logger.warning(f"Could not calculate length for edge ({u_id}-{v_id}) due to missing node positions.")

    # Example: Edge radius could be based on upstream node or average
    # For now, let's assume it might be set explicitly or derived later
    # radius_u = graph.nodes[u_id].get('radius')
    # if radius_u is not None:
    #    attrs['radius'] = radius_u 

    attrs.update(kwargs) # Add any extra attributes
    graph.add_edge(u_id, v_id, **attrs)
    # logger.debug(f"Added edge ({u_id}-{v_id}) with attributes: {attrs}")


# --- Tissue Data Structure ---
# Represented as a dictionary of NumPy arrays, plus affine and voxel volume.
# Example:
# tissue_data = {
#     'WM': wm_array,         # (X, Y, Z) binary or fractional mask
#     'GM': gm_array,         # (X, Y, Z)
#     'Tumor': tumor_array,   # (X, Y, Z)
#     'CSF': csf_array,       # (X, Y, Z)
#     'domain_mask': combined_mask, # (X, Y, Z) boolean array defining relevant voxels
#     'metabolic_demand_map': demand_map, # (X, Y, Z) float array of q_met per voxel
#     'affine': affine_matrix, # 4x4 np.ndarray
#     'voxel_volume': volume_per_voxel, # float (mm^3 or m^3)
#     'world_coords_flat': world_coords_of_domain_voxels # (N_domain_voxels, 3)
#     'voxel_indices_flat': voxel_indices_of_domain_voxels # (N_domain_voxels, 3)
# }

def get_metabolic_demand_map(tissue_segmentations: dict, config: dict, voxel_volume: float) -> np.ndarray:
    """
    Generates a metabolic demand map (q_met * dV) from tissue segmentations.
    
    Args:
        tissue_segmentations (dict): Dictionary of tissue type arrays (e.g., 'WM', 'GM', 'Tumor').
                                     Values are masks (0 or 1, or fractional 0-1).
        config (dict): Configuration dictionary with metabolic rates.
        voxel_volume (float): Volume of a single voxel (e.g., in mm^3).

    Returns:
        np.ndarray: A 3D array of the same shape as segmentations, where each voxel
                    contains the total metabolic demand (e.g., in mm^3_blood/s).
    """
    from src import config_manager as cfg_mgr # to use get_param

    # Get shape from one of the segmentations
    shape = None
    for seg_name, seg_array in tissue_segmentations.items():
        if seg_array is not None:
            shape = seg_array.shape
            break
    if shape is None:
        logger.error("No valid tissue segmentations provided to create metabolic map.")
        return None

    demand_map = np.zeros(shape, dtype=np.float32)
    
    q_rates = cfg_mgr.get_param(config, "tissue_properties.metabolic_rates")

    if 'GM' in tissue_segmentations and tissue_segmentations['GM'] is not None:
        demand_map += tissue_segmentations['GM'] * q_rates.get('gm', 0.0)
    if 'WM' in tissue_segmentations and tissue_segmentations['WM'] is not None:
        demand_map += tissue_segmentations['WM'] * q_rates.get('wm', 0.0)
    if 'CSF' in tissue_segmentations and tissue_segmentations['CSF'] is not None:
        demand_map += tissue_segmentations['CSF'] * q_rates.get('csf', 0.0) # usually 0
    
    # Tumor can have rim/core distinction if available, or a single tumor type
    if 'Tumor' in tissue_segmentations and tissue_segmentations['Tumor'] is not None:
        # Simple model: use 'tumor_rim' for all tumor voxels if 'tumor_core' isn't specified
        # or if the tumor segmentation isn't further divided.
        # A more complex model would require separate Tumor_Rim and Tumor_Core segmentations.
        tumor_rate = q_rates.get('tumor_rim', q_rates.get('tumor', 0.0)) # Fallback to 'tumor' if 'tumor_rim' not there
        demand_map += tissue_segmentations['Tumor'] * tumor_rate
    elif 'Tumor_Rim' in tissue_segmentations and tissue_segmentations['Tumor_Rim'] is not None:
         demand_map += tissue_segmentations['Tumor_Rim'] * q_rates.get('tumor_rim', 0.0)
         if 'Tumor_Core' in tissue_segmentations and tissue_segmentations['Tumor_Core'] is not None:
             demand_map += tissue_segmentations['Tumor_Core'] * q_rates.get('tumor_core', 0.0)
             
    return demand_map * voxel_volume # Now it's total demand per voxel (e.g. mm^3/s)

if __name__ == '__main__':
    logging.basicConfig(level=logging.DEBUG)

    # Test vascular graph functions
    g = create_empty_vascular_graph()
    add_node_to_graph(g, 0, pos=np.array([0.,0.,0.]), radius=0.5, node_type='root', pressure=100)
    add_node_to_graph(g, 1, pos=np.array([1.,0.,0.]), radius=0.4, node_type='bifurcation')
    add_node_to_graph(g, 2, pos=np.array([2.,1.,0.]), radius=0.3, node_type='terminal', flow_demand=5)
    add_node_to_graph(g, 3, pos=np.array([2.,-1.,0.]), radius=0.3, node_type='terminal', flow_demand=5)

    add_edge_to_graph(g, 0, 1, flow=10)
    add_edge_to_graph(g, 1, 2, flow=5)
    add_edge_to_graph(g, 1, 3, flow=5)

    print("\n--- Vascular Graph Test ---")
    print(f"Nodes: {g.nodes(data=True)}")
    print(f"Edges: {g.edges(data=True)}")
    assert np.isclose(g.edges[(0,1)]['length'], 1.0)
    assert g.nodes[2]['flow_demand'] == 5

    # Test metabolic demand map
    print("\n--- Metabolic Demand Map Test ---")
    dummy_config = {
        "tissue_properties": {
            "metabolic_rates": {
                "gm": 0.01, "wm": 0.003, "csf": 0.0, "tumor_rim": 0.02
            }
        }
    }
    gm_seg = np.zeros((3,3,3), dtype=np.uint8)
    gm_seg[1,1,1] = 1
    wm_seg = np.zeros((3,3,3), dtype=np.uint8)
    wm_seg[0,0,0] = 1
    
    tissue_segs = {'GM': gm_seg, 'WM': wm_seg}
    voxel_vol = 2.0 # mm^3

    demand_map = get_metabolic_demand_map(tissue_segs, dummy_config, voxel_vol)
    if demand_map is not None:
        print(f"Demand map at (1,1,1) (GM): {demand_map[1,1,1]} (Expected: 0.01 * 2.0 = 0.02)")
        assert np.isclose(demand_map[1,1,1], 0.01 * voxel_vol)
        print(f"Demand map at (0,0,0) (WM): {demand_map[0,0,0]} (Expected: 0.003 * 2.0 = 0.006)")
        assert np.isclose(demand_map[0,0,0], 0.003 * voxel_vol)
        print(f"Demand map at (2,2,2) (Background): {demand_map[2,2,2]} (Expected: 0.0)")
        assert np.isclose(demand_map[2,2,2], 0.0)
        print("Metabolic demand map test successful.")
    else:
        print("Metabolic demand map test failed.")


----main.py

# main.py
import argparse
import logging
import os
import time
import numpy as np
import networkx as nx # For type hinting and graph operations
from typing import Optional

# PyVista import for VTP parsing, ensure it's available (used by io_utils indirectly)
try:
    import pyvista as pv
    PYVISTA_AVAILABLE = True
except ImportError:
    PYVISTA_AVAILABLE = False
    pv = None

from src import config_manager, io_utils, utils
from src import data_structures
from src import vascular_growth, angiogenesis, perfusion_solver, visualization
from src.constants import DEFAULT_VOXEL_SIZE_MM, Q_MET_TUMOR_RIM_PER_ML, INITIAL_TERMINAL_FLOW_Q # Added more constants

logger = logging.getLogger(__name__) # Ensure logger is defined for this function's scope


def setup_logging(log_level_str: str, log_file: str):
    """Configures logging for the simulation."""
    numeric_level = getattr(logging, log_level_str.upper(), logging.INFO)
    if not isinstance(numeric_level, int): # Fallback if level is invalid
        print(f"Warning: Invalid log level '{log_level_str}'. Defaulting to INFO.")
        numeric_level = logging.INFO

    # Make sure log directory exists
    os.makedirs(os.path.dirname(log_file), exist_ok=True)
    
    logging.basicConfig(
        level=numeric_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, mode='w'), # Overwrite log file each run
            logging.StreamHandler() # Also print to console
        ]
    )
    # Suppress overly verbose logs if not in DEBUG
    if numeric_level > logging.DEBUG:
        logging.getLogger('pyvista').setLevel(logging.WARNING)
        logging.getLogger('matplotlib').setLevel(logging.WARNING)


def parse_arguments():
    """Parses command-line arguments."""
    parser = argparse.ArgumentParser(description="GBO Brain Vasculature Simulation Framework")
    parser.add_argument(
        "--config",
        type=str,
        default="config.yaml",
        help="Path to the YAML configuration file (default: config.yaml)"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default=None,
        help="Override output directory from config file."
    )
    return parser.parse_args()

# main.py
# ... (imports as before) ...

logger = logging.getLogger(__name__)

# ... (setup_logging, parse_arguments as before) ...

def load_initial_data(config: dict) -> tuple[dict, Optional[nx.DiGraph]]:
    logger.info("Loading initial data...")
    
    tissue_data = {
        'WM': None, 'GM': None, 'CSF': None, 
        'Tumor_Max_Extent': None, 'Tumor': None, 
        'tumor_rim_mask': None, 'tumor_core_mask': None,
        'VEGF_field': None, 'affine': None, 'voxel_volume': None, 
        'domain_mask': None, 
        'anatomical_domain_mask': None, 
        'gbo_growth_domain_mask': None, 
        'metabolic_demand_map': None,
        'world_coords_flat': None, 
        'voxel_indices_flat': None,  
        'shape': None
    }

    paths = config_manager.get_param(config, "paths", {})
    sim_params = config_manager.get_param(config, "simulation", {})
    use_sphere = sim_params.get("use_spherical_domain", False)

    if use_sphere:
        logger.info("--- Using SPHERICAL DOMAIN MASK for simulation ---")
        sph_shape_vox = np.array(sim_params.get("spherical_domain_shape_vox", [100, 100, 100]))
        sph_center_vox = np.array(sim_params.get("spherical_domain_center_vox", [s//2 for s in sph_shape_vox]))
        sph_radius_vox = sim_params.get("spherical_domain_radius_vox", min(sph_shape_vox)//3)
        sph_vox_size_mm = np.array(sim_params.get("spherical_domain_voxel_size_mm", [1.0, 1.0, 1.0]))

        tissue_data['shape'] = tuple(sph_shape_vox)
        
        # Create a default affine for the spherical domain
        # Assumes origin at (0,0,0) world coords for voxel (0,0,0) for simplicity
        # Adjust if your sphere needs to be in a specific world coordinate system
        affine_matrix = np.eye(4)
        affine_matrix[0,0] = sph_vox_size_mm[0]
        affine_matrix[1,1] = sph_vox_size_mm[1]
        affine_matrix[2,2] = sph_vox_size_mm[2]
        tissue_data['affine'] = affine_matrix
        logger.info(f"Spherical domain: Shape={tissue_data['shape']}, VoxelSize={sph_vox_size_mm}, Affine=\n{affine_matrix}")

        coords = np.ogrid[:sph_shape_vox[0], :sph_shape_vox[1], :sph_shape_vox[2]]
        distance_sq = ((coords[0] - sph_center_vox[0])**2 +
                       (coords[1] - sph_center_vox[1])**2 +
                       (coords[2] - sph_center_vox[2])**2)
        sphere_mask = distance_sq <= sph_radius_vox**2
        
        # Assign the sphere as Grey Matter for simplicity, or your primary tissue type
        tissue_data['GM'] = sphere_mask.astype(bool)
        tissue_data['WM'] = np.zeros(tissue_data['shape'], dtype=bool) # No WM
        tissue_data['CSF'] = np.zeros(tissue_data['shape'], dtype=bool) # No CSF
        tissue_data['Tumor_Max_Extent'] = np.zeros(tissue_data['shape'], dtype=bool) # No Tumor

        logger.info(f"Generated spherical GM mask with {np.sum(tissue_data['GM'])} voxels.")
        common_shape = tissue_data['shape'] # Already set

    else: # Original NIfTI loading logic
        logger.info("--- Using NIFTI MASKS for simulation domain ---")
        wm_data, affine_wm, _ = io_utils.load_nifti_image(paths.get("wm_nifti",""))
        gm_data, affine_gm, _ = io_utils.load_nifti_image(paths.get("gm_nifti",""))
        
        if affine_wm is not None:
            tissue_data['affine'] = affine_wm
        elif affine_gm is not None:
            tissue_data['affine'] = affine_gm
        
        common_shape = None
        if wm_data is not None:
            common_shape = wm_data.shape
            tissue_data['WM'] = wm_data.astype(bool)
        if gm_data is not None:
            if common_shape and gm_data.shape != common_shape:
                logger.error(f"GM shape {gm_data.shape} mismatch WM {common_shape}.")
            elif not common_shape: 
                common_shape = gm_data.shape
            tissue_data['GM'] = gm_data.astype(bool)

        if paths.get("tumor_nifti"):
            tumor_final_data, affine_tumor, _ = io_utils.load_nifti_image(paths["tumor_nifti"])
            if tumor_final_data is not None:
                if common_shape is None:
                    common_shape = tumor_final_data.shape
                elif tumor_final_data.shape != common_shape:
                    logger.error(f"Tumor_Max_Extent shape {tumor_final_data.shape} mismatch domain {common_shape}.")
                    tumor_final_data = None 
                if tissue_data['affine'] is None and affine_tumor is not None:
                    tissue_data['affine'] = affine_tumor
                if tumor_final_data is not None:
                     tissue_data['Tumor_Max_Extent'] = tumor_final_data.astype(bool)

        if tissue_data['affine'] is None: 
            logger.warning("No NIfTI found to determine affine. Using default identity affine and 1mm voxel size.")
            tissue_data['affine'] = np.eye(4)
            for i_ax in range(3): tissue_data['affine'][i_ax,i_ax] = constants.DEFAULT_VOXEL_SIZE_MM
            if common_shape is None:
                 raise ValueError("Cannot determine tissue domain shape AND no affine available. Critical error.")
        
        if common_shape is None: 
            raise ValueError("Critical: Could not determine a common shape for any tissue data.")
        tissue_data['shape'] = common_shape

        # Load optional CSF (only if not using sphere)
        if paths.get("csf_nifti"):
            csf_data, _, _ = io_utils.load_nifti_image(paths["csf_nifti"])
            if csf_data is not None and csf_data.shape == common_shape: 
                tissue_data['CSF'] = csf_data.astype(bool)
            elif csf_data is not None: 
                logger.warning(f"CSF shape {csf_data.shape} mismatch domain {common_shape}. Skipping CSF.")

    # ---- Common post-mask-definition steps ----
    tissue_data['voxel_volume'] = utils.get_voxel_volume_from_affine(tissue_data['affine'])

    for key_mask_init in ['Tumor', 'tumor_rim_mask', 'tumor_core_mask', 'VEGF_field', 
                          'anatomical_domain_mask', 'gbo_growth_domain_mask']:
        if key_mask_init not in tissue_data or tissue_data[key_mask_init] is None:
             tissue_data[key_mask_init] = np.zeros(tissue_data['shape'], dtype=float if key_mask_init == 'VEGF_field' else bool)
    
    if tissue_data.get('Tumor_Max_Extent') is None : # Ensure Tumor_Max_Extent always exists
        tissue_data['Tumor_Max_Extent'] = np.zeros(tissue_data['shape'], dtype=bool)
    # Ensure CSF is initialized if not loaded (e.g. in sphere mode)
    if tissue_data.get('CSF') is None:
        tissue_data['CSF'] = np.zeros(tissue_data['shape'], dtype=bool)


    anatomical_domain = np.zeros(tissue_data['shape'], dtype=bool)
    if tissue_data.get('GM') is not None: anatomical_domain = np.logical_or(anatomical_domain, tissue_data['GM'])
    if tissue_data.get('WM') is not None: anatomical_domain = np.logical_or(anatomical_domain, tissue_data['WM'])
    if tissue_data.get('CSF') is not None: anatomical_domain = np.logical_or(anatomical_domain, tissue_data['CSF'])
    if tissue_data.get('Tumor_Max_Extent') is not None: anatomical_domain = np.logical_or(anatomical_domain, tissue_data['Tumor_Max_Extent'])
    tissue_data['anatomical_domain_mask'] = anatomical_domain
    logger.info(f"Anatomical domain mask created with {np.sum(anatomical_domain)} voxels.")

    gbo_growth_domain = np.zeros(tissue_data['shape'], dtype=bool)
    if tissue_data.get('GM') is not None: gbo_growth_domain = np.logical_or(gbo_growth_domain, tissue_data['GM'])
    if tissue_data.get('WM') is not None: gbo_growth_domain = np.logical_or(gbo_growth_domain, tissue_data['WM'])
    tissue_data['gbo_growth_domain_mask'] = gbo_growth_domain
    tissue_data['domain_mask'] = gbo_growth_domain 
    logger.info(f"GBO growth domain_mask set with {np.sum(tissue_data['domain_mask'])} voxels.")

    voxel_indices_gbo_domain = np.array(np.where(tissue_data['domain_mask'])).T
    if voxel_indices_gbo_domain.size > 0:
        tissue_data['voxel_indices_flat'] = voxel_indices_gbo_domain
        tissue_data['world_coords_flat'] = utils.voxel_to_world(voxel_indices_gbo_domain, tissue_data['affine'])
    else:
        tissue_data['voxel_indices_flat'] = np.empty((0,3), dtype=int)
        tissue_data['world_coords_flat'] = np.empty((0,3), dtype=float)
        logger.warning("GBO growth domain_mask is empty. Healthy GBO might not find tissue to grow into.")

    # Initial metabolic demand map:
    # If sphere mode, only GM exists. If NIfTI mode, uses loaded GM/WM/CSF.
    segmentations_for_initial_demand = {
        k: tissue_data[k] for k in ['WM', 'GM', 'CSF'] 
        if tissue_data.get(k) is not None and np.any(tissue_data[k])
    }
    if not segmentations_for_initial_demand and use_sphere and tissue_data.get('GM') is not None:
        # If sphere mode and only GM is defined, make sure it's used for demand.
        segmentations_for_initial_demand['GM'] = tissue_data['GM']
        
    tissue_data['metabolic_demand_map'] = data_structures.get_metabolic_demand_map(
        segmentations_for_initial_demand, config, tissue_data['voxel_volume']
    )
    if tissue_data['metabolic_demand_map'] is None: 
        tissue_data['metabolic_demand_map'] = np.zeros(tissue_data['shape'], dtype=np.float32)

    # --- Arterial Centerline Loading (remains the same) ---
    initial_arterial_graph = None
    # ... (rest of your arterial centerline loading code from the previous version) ...
    # Make sure this part is robust to `use_sphere = True` (e.g. if no centerlines are expected with sphere)
    centerline_path_key = "arterial_centerlines"
    centerline_file_str = paths.get(centerline_path_key)
    
    if centerline_file_str:
        input_data_base_dir = paths.get("input_data_dir", ".") 
        if not os.path.isabs(centerline_file_str):
            full_centerline_path = os.path.join(input_data_base_dir, centerline_file_str)
        else:
            full_centerline_path = centerline_file_str
        
        logger.info(f"Attempting to load arterial centerlines from: {full_centerline_path}")
        poly_data = None 
        if full_centerline_path.endswith((".vtp", ".vtk")):
            poly_data = io_utils.load_arterial_centerlines_vtp(full_centerline_path)
        elif full_centerline_path.endswith(".txt"):
            default_radius_centerline = config_manager.get_param(config, "vascular_properties.centerline_default_radius", 0.1)
            poly_data = io_utils.load_arterial_centerlines_txt(full_centerline_path, radius_default=default_radius_centerline)
        else: 
            logger.warning(f"Unsupported arterial centerline file format: {full_centerline_path}")

        if poly_data and poly_data.n_points > 0:
            logger.info(f"Processing VTP/PolyData with {poly_data.n_points} points and {poly_data.n_cells} cells.")
            initial_arterial_graph = data_structures.create_empty_vascular_graph()
            pv_point_to_nx_node: Dict[int, str] = {} 
            node_id_counter = 0
            default_min_radius = config_manager.get_param(config, "vascular_properties.min_radius", 0.01)

            radii_array = poly_data.point_data.get('radius') 
            if radii_array is None: logger.warning("'Radius' point data array not found in VTP. Using default_min_radius.")
            elif len(radii_array) != poly_data.n_points:
                logger.warning(f"Mismatch in 'Radius' array length. Using default_min_radius."); radii_array = None

            for pt_idx in range(poly_data.n_points):
                pos = poly_data.points[pt_idx]
                radius = float(radii_array[pt_idx]) if radii_array is not None and pt_idx < len(radii_array) else default_min_radius
                current_node_id = f"m_{node_id_counter}"; node_id_counter += 1
                data_structures.add_node_to_graph(initial_arterial_graph, current_node_id,
                                                  pos=pos, radius=radius, type='measured_point')
                pv_point_to_nx_node[pt_idx] = current_node_id
            logger.debug(f"Added {initial_arterial_graph.number_of_nodes()} nodes from VTP points.")

            vtp_polyline_start_nodes: Set[str] = set()
            vtp_polyline_end_nodes: Set[str] = set()

            for i_cell in range(poly_data.n_cells):
                cell_point_indices = poly_data.get_cell(i_cell).point_ids
                if len(cell_point_indices) < 1: continue
                
                start_node_id_nx = pv_point_to_nx_node.get(cell_point_indices[0])
                if start_node_id_nx: vtp_polyline_start_nodes.add(start_node_id_nx)

                if len(cell_point_indices) >= 2:
                    end_node_id_nx = pv_point_to_nx_node.get(cell_point_indices[-1])
                    if end_node_id_nx: vtp_polyline_end_nodes.add(end_node_id_nx)
                    for k_edge in range(len(cell_point_indices) - 1):
                        node_u_id = pv_point_to_nx_node.get(cell_point_indices[k_edge])
                        node_v_id = pv_point_to_nx_node.get(cell_point_indices[k_edge + 1])
                        if node_u_id and node_v_id and node_u_id != node_v_id:
                            rad_u = initial_arterial_graph.nodes[node_u_id]['radius']
                            rad_v = initial_arterial_graph.nodes[node_v_id]['radius']
                            source_node, target_node = node_u_id, node_v_id
                            if (rad_u < rad_v and not np.isclose(rad_u, rad_v)): 
                                source_node, target_node = node_v_id, node_u_id
                            if not initial_arterial_graph.has_edge(source_node, target_node):
                                data_structures.add_edge_to_graph(initial_arterial_graph, source_node, target_node, type='measured_segment')
            
            logger.info(f"Added {initial_arterial_graph.number_of_edges()} edges from VTP cells.")
            logger.info(f"Identified {len(vtp_polyline_start_nodes)} VTP polyline start nodes and {len(vtp_polyline_end_nodes)} VTP polyline end nodes.")
            
            roi_mask_for_vtp_typing = tissue_data.get('anatomical_domain_mask')
            
            for node_id in list(initial_arterial_graph.nodes()):
                in_deg = initial_arterial_graph.in_degree(node_id)
                out_deg = initial_arterial_graph.out_degree(node_id)
                node_data = initial_arterial_graph.nodes[node_id]
                is_vtp_cell_end = node_id in vtp_polyline_end_nodes

                if in_deg == 0 and out_deg > 0 : node_data['type'] = 'measured_root'
                elif out_deg == 0 and in_deg > 0: 
                    if is_vtp_cell_end:
                        is_within_anatomical_domain = False
                        if roi_mask_for_vtp_typing is not None and tissue_data['affine'] is not None:
                            pos_world = node_data['pos']
                            pos_vox_int = np.round(utils.world_to_voxel(pos_world, tissue_data['affine'])).astype(int)
                            if utils.is_voxel_in_bounds(pos_vox_int, roi_mask_for_vtp_typing.shape) and \
                               roi_mask_for_vtp_typing[tuple(pos_vox_int)]:
                                is_within_anatomical_domain = True
                        
                        if is_within_anatomical_domain:
                            node_data['type'] = 'measured_terminal_in_anatomical_domain'
                        else:
                            node_data['type'] = 'measured_external_outlet'
                            ext_flow = config_manager.get_param(config, "vascular_properties.external_outlet_default_flow", 0.001)
                            node_data['Q_flow'] = -ext_flow 
                    else: 
                        node_data['type'] = 'measured_segment_point' 
                        logger.debug(f"Node {node_id} has out_deg=0 but not VTP end. Type: seg_point.")
                elif out_deg > 1: node_data['type'] = 'measured_bifurcation'
                elif in_deg > 1 and out_deg == 1: node_data['type'] = 'measured_convergence'
                elif in_deg == 1 and out_deg == 1: node_data['type'] = 'measured_segment_point'
                elif in_deg == 0 and out_deg == 0: node_data['type'] = 'measured_isolated_point'
                else: node_data['type'] = 'measured_complex_junction'

            num_roots = sum(1 for _, data in initial_arterial_graph.nodes(data=True) if data['type'] == 'measured_root')
            num_terminals_roi = sum(1 for _, data in initial_arterial_graph.nodes(data=True) if data['type'] == 'measured_terminal_in_anatomical_domain')
            num_terminals_ext = sum(1 for _, data in initial_arterial_graph.nodes(data=True) if data['type'] == 'measured_external_outlet')
            logger.info(f"Refined VTP node types: {num_roots} roots, {num_terminals_roi} ROI terminals, {num_terminals_ext} external outlets.")
    else: 
        logger.info("No 'arterial_centerlines' path specified in config. GBO will start from config seeds or fallback.")


    return tissue_data, initial_arterial_graph


# ... (main function definition as before, calling load_initial_data)
def main():
    args = parse_arguments()
    try:
        config = config_manager.load_config(args.config)
    except Exception as e:
        print(f"CRITICAL: Failed to load configuration file '{args.config}': {e}")
        try: # Attempt to set up basic logging for more details on config load failure
            os.makedirs("output/error_logs", exist_ok=True)
            setup_logging("ERROR", "output/error_logs/config_load_error.log") # Log to a fixed error file
            logging.getLogger(__name__).critical(f"Failed to load configuration file '{args.config}': {e}", exc_info=True)
        except Exception as log_e: print(f"Additionally, failed to set up error logging: {log_e}")
        return

    sim_name = config_manager.get_param(config, "simulation.simulation_name", "gbo_sim")
    base_output_dir_config = config_manager.get_param(config, "paths.output_dir", "output")
    base_output_dir = args.output_dir if args.output_dir else base_output_dir_config
    
    os.makedirs(base_output_dir, exist_ok=True) # Ensure base output dir exists
    output_dir = utils.create_output_directory(base_output_dir, sim_name, timestamp=True)
    
    log_level = config_manager.get_param(config, "simulation.log_level", "INFO")
    log_file_path = os.path.join(output_dir, f"{sim_name}.log")
    setup_logging(log_level, log_file_path)
    
    main_logger = logging.getLogger(__name__)
    main_logger.info(f"Simulation started. Output directory: {output_dir}")
    main_logger.info(f"Using configuration file: {os.path.abspath(args.config)}")

    try: io_utils.save_simulation_parameters(config, os.path.join(output_dir, "config_used.yaml"))
    except Exception as e_save_config: main_logger.error(f"Could not save used configuration file: {e_save_config}")

    seed_val = config_manager.get_param(config, "simulation.random_seed", None)
    if seed_val is not None:
        try: utils.set_rng_seed(int(seed_val))
        except ValueError: main_logger.warning(f"Invalid random_seed value '{seed_val}'. Using system default.")

    start_time = time.time()
    main_logger.info("--- Loading Initial Data ---")
    try:
        tissue_data, initial_arterial_graph = load_initial_data(config)
    except ValueError as ve:
        main_logger.critical(f"Critical error during data loading: {ve}", exc_info=True); return
    except Exception as e:
        main_logger.critical(f"Unexpected error during data loading: {e}", exc_info=True); return
    
    if config_manager.get_param(config, "visualization.plot_initial_setup", True):
        main_logger.info("--- Visualizing Initial Setup ---")
        try:
            visualization.visualize_initial_setup(config=config, output_dir=output_dir,
                                                  tissue_data=tissue_data, initial_arterial_graph=initial_arterial_graph)
        except Exception as e_viz_init: main_logger.error(f"Failed to generate initial setup visualization: {e_viz_init}", exc_info=True)
    
    if config_manager.get_param(config, "visualization.save_initial_masks", False):
        main_logger.info("--- Saving Initial Masks (as NIfTI) ---")
        for key in ['WM', 'GM', 'CSF', 'Tumor_Max_Extent', 'domain_mask', 'metabolic_demand_map', 'Tumor', 'tumor_rim_mask', 'tumor_core_mask', 'VEGF_field']:
            if key in tissue_data and isinstance(tissue_data[key], np.ndarray) and np.any(tissue_data[key]):
                arr_to_save = tissue_data[key]
                dtype_to_save = np.float32 if key in ['metabolic_demand_map', 'VEGF_field'] else np.uint8
                if arr_to_save.dtype == bool: arr_to_save = arr_to_save.astype(np.uint8)
                if tissue_data.get('affine') is None: main_logger.warning(f"Cannot save '{key}': Affine missing."); continue
                try: io_utils.save_nifti_image(arr_to_save.astype(dtype_to_save), tissue_data['affine'], os.path.join(output_dir, f"debug_initial_tissue_{key}.nii.gz"))
                except Exception as e_save: main_logger.error(f"Could not save initial mask {key}: {e_save}")
        if initial_arterial_graph and initial_arterial_graph.number_of_nodes() > 0 :
            try: io_utils.save_vascular_tree_vtp(initial_arterial_graph, os.path.join(output_dir, "debug_initial_arterial_graph_parsed.vtp"))
            except Exception as e_save_vtp: main_logger.error(f"Could not save initial parsed arterial graph: {e_save_vtp}")

    healthy_vascular_tree = None
    if config_manager.get_param(config, "gbo_growth.enabled", True):
        main_logger.info("--- Starting Healthy Vascular Development (GBO) ---")
        healthy_vascular_tree = vascular_growth.grow_healthy_vasculature(
            config=config, tissue_data=tissue_data, initial_graph=initial_arterial_graph, output_dir=output_dir
        )
        if healthy_vascular_tree:
            main_logger.info(f"Healthy GBO finished. Tree: {healthy_vascular_tree.number_of_nodes()} N, {healthy_vascular_tree.number_of_edges()} E.")
            io_utils.save_vascular_tree_vtp(healthy_vascular_tree, os.path.join(output_dir, "healthy_vascular_tree.vtp"))
        else: main_logger.error("Healthy GBO failed or returned no tree.")
    else:
        main_logger.info("Healthy GBO growth skipped by config.")
        healthy_vascular_tree = initial_arterial_graph if initial_arterial_graph else data_structures.create_empty_vascular_graph()
        if initial_arterial_graph: main_logger.info("Using provided initial arterial graph as base for subsequent steps.")
        else: main_logger.info("No initial arterial graph and GBO skipped. Starting with empty tree.")


    final_vascular_tree = healthy_vascular_tree if healthy_vascular_tree else data_structures.create_empty_vascular_graph()

    if config_manager.get_param(config, "tumor_angiogenesis.enabled", False):
        if tissue_data.get('Tumor_Max_Extent') is not None and np.any(tissue_data['Tumor_Max_Extent']):
            main_logger.info("--- Starting Tumor Growth and Angiogenesis Simulation ---")
            base_for_angiogenesis = final_vascular_tree.copy() # Use the result of GBO (or initial graph if GBO skipped)
            final_vascular_tree = angiogenesis.simulate_tumor_angiogenesis_fixed_extent(
                config=config, tissue_data=tissue_data,
                base_vascular_tree=base_for_angiogenesis,
                output_dir=output_dir,
                perfusion_solver_func=perfusion_solver.solve_1d_poiseuille_flow
            )
            if final_vascular_tree:
                main_logger.info(f"Tumor angiogenesis finished. Final tree: {final_vascular_tree.number_of_nodes()} N, {final_vascular_tree.number_of_edges()} E.")
                io_utils.save_vascular_tree_vtp(final_vascular_tree, os.path.join(output_dir, "final_tumor_vascular_tree.vtp"))
            else:
                main_logger.error("Tumor angiogenesis returned no tree. Using pre-angiogenesis tree.")
                final_vascular_tree = base_for_angiogenesis 
        else: main_logger.info("Tumor angiogenesis skipped (No Tumor_Max_Extent defined or empty).")
    else: main_logger.info("Tumor angiogenesis disabled in config.")

    perfusion_map_3d, pressure_map_3d_tissue = None, None
    if config_manager.get_param(config, "perfusion_solver.run_final_1d_flow_solve", True) and \
       final_vascular_tree and final_vascular_tree.number_of_nodes() > 0:
        main_logger.info("--- Running Final 1D Flow Solve ---")
        
        for node_id_f, data_f in final_vascular_tree.nodes(data=True):
            if final_vascular_tree.out_degree(node_id_f) == 0 and final_vascular_tree.in_degree(node_id_f) > 0:
                term_pos_vox = np.round(utils.world_to_voxel(data_f['pos'], tissue_data['affine'])).astype(int)
                demand = data_f.get('Q_flow', 0.0) 
                if utils.is_voxel_in_bounds(term_pos_vox, tissue_data['shape']):
                    if data_f.get('is_tumor_vessel') and tissue_data.get('Tumor') is not None and tissue_data['Tumor'][tuple(term_pos_vox)]:
                        demand = config_manager.get_param(config, "tumor_angiogenesis.min_tumor_terminal_demand", DEFAULT_MIN_TUMOR_TERMINAL_DEMAND)
                    elif not data_f.get('is_tumor_vessel') and tissue_data.get('metabolic_demand_map') is not None:
                        # For healthy terminals, try to get demand from the metabolic map at their location
                        # This is a simplification; proper territory demand is better.
                        demand = tissue_data['metabolic_demand_map'][tuple(term_pos_vox)]
                        if demand < constants.EPSILON: # If healthy tissue demand is zero here for some reason
                            demand = constants.INITIAL_TERMINAL_FLOW_Q # Fallback small flow
                data_f['Q_flow'] = demand
        
        final_tree_copy_for_solve = final_vascular_tree.copy()
        final_vascular_tree_with_flow = perfusion_solver.solve_1d_poiseuille_flow(
            final_tree_copy_for_solve, config, None, None
        )
        if final_vascular_tree_with_flow:
            final_vascular_tree = final_vascular_tree_with_flow
            io_utils.save_vascular_tree_vtp(final_vascular_tree, os.path.join(output_dir, "final_vascular_tree_with_flowdata.vtp"))
            main_logger.info("Final 1D flow solution computed and saved on tree.")
        else: main_logger.error("Final 1D flow solution failed.")
    else: main_logger.info("Final 1D flow solve skipped.")

    main_logger.info("--- Generating Final Visualizations ---")
    visualization.generate_final_visualizations(
        config=config, output_dir=output_dir, tissue_data=tissue_data,
        vascular_graph=final_vascular_tree,
        perfusion_map=perfusion_map_3d, 
        pressure_map_tissue=pressure_map_3d_tissue,
        plot_context_masks=config_manager.get_param(config, "visualization.plot_context_masks_final", True)
    )

    main_logger.info(f"Simulation finished. Total time: {time.time() - start_time:.2f}s. Output: {output_dir}")

if __name__ == "__main__":
    temp_config_path = "config.yaml"
    if not os.path.exists(temp_config_path):
        try:
            config_manager.create_default_config(temp_config_path)
            # print(f"Warning: {temp_config_path} not found. Attempting to run with default parameters where possible.")
            # print("Please create a config.yaml or provide one via --config argument.")
            # # Create a minimal dummy config if none exists, so get_param doesn't fail immediately
            # if not os.path.exists(temp_config_path):
            #      with open(temp_config_path, "w") as f_cfg:
            #         f_cfg.write("paths:\n  input_data_dir: \"data\"\n  output_dir: \"output/simulation_results\"\n")
            #      print(f"Created minimal dummy {temp_config_path}. Please customize it.")
        except Exception as e: print(f"Could not create dummy config: {e}")

    # Ensure data and output directories are attempted to be created based on a minimal config load
    loaded_temp_config = {}
    if os.path.exists(temp_config_path):
        try: loaded_temp_config = config_manager.load_config(temp_config_path)
        except: print(f"Could not load {temp_config_path} for directory creation.")
    
    os.makedirs(config_manager.get_param(loaded_temp_config, "paths.input_data_dir", "data"), exist_ok=True)
    os.makedirs(config_manager.get_param(loaded_temp_config, "paths.output_dir", "output"), exist_ok=True)
    
    main()